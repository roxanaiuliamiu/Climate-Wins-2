{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31ac2903",
   "metadata": {},
   "source": [
    "# Optimizing Hyperparameters - CNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8cf603",
   "metadata": {},
   "source": [
    "# Importing Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b272bbe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.12/site-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "import operator\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "from numpy import unique\n",
    "from numpy import reshape\n",
    "from keras.models import Sequential\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.layers import Conv1D, Conv2D, Dense, Dropout, BatchNormalization, Flatten, MaxPooling1D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.optimizers import Adam, SGD, RMSprop, Adadelta, Adagrad, Adamax, Nadam, Ftrl\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from math import floor\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.layers import LeakyReLU\n",
    "LeakyReLU = LeakyReLU(alpha=0.1)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acaf1f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a path\n",
    "\n",
    "path = r'/Users/roxanamiu/Documents/Climate Change project 2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f441852c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import cleaned weather observations data\n",
    "\n",
    "X = pd.read_csv(os.path.join(path, 'Prepared', 'X_cleaned_date.csv'), index_col = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04d0e70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import predictions data\n",
    "\n",
    "answers = pd.read_csv(os.path.join(path, 'Data', 'Dataset-Answers-Weather_Prediction_Pleasant_Weather.csv'), index_col = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d49309ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>BASEL_cloud_cover</th>\n",
       "      <th>BASEL_humidity</th>\n",
       "      <th>BASEL_pressure</th>\n",
       "      <th>BASEL_global_radiation</th>\n",
       "      <th>BASEL_precipitation</th>\n",
       "      <th>BASEL_sunshine</th>\n",
       "      <th>BASEL_temp_mean</th>\n",
       "      <th>BASEL_temp_min</th>\n",
       "      <th>BASEL_temp_max</th>\n",
       "      <th>BELGRADE_cloud_cover</th>\n",
       "      <th>BELGRADE_humidity</th>\n",
       "      <th>BELGRADE_pressure</th>\n",
       "      <th>BELGRADE_global_radiation</th>\n",
       "      <th>BELGRADE_precipitation</th>\n",
       "      <th>BELGRADE_sunshine</th>\n",
       "      <th>BELGRADE_temp_mean</th>\n",
       "      <th>BELGRADE_temp_min</th>\n",
       "      <th>BELGRADE_temp_max</th>\n",
       "      <th>BUDAPEST_cloud_cover</th>\n",
       "      <th>BUDAPEST_humidity</th>\n",
       "      <th>BUDAPEST_pressure</th>\n",
       "      <th>BUDAPEST_global_radiation</th>\n",
       "      <th>BUDAPEST_precipitation</th>\n",
       "      <th>BUDAPEST_sunshine</th>\n",
       "      <th>BUDAPEST_temp_mean</th>\n",
       "      <th>BUDAPEST_temp_min</th>\n",
       "      <th>BUDAPEST_temp_max</th>\n",
       "      <th>DEBILT_cloud_cover</th>\n",
       "      <th>DEBILT_humidity</th>\n",
       "      <th>DEBILT_pressure</th>\n",
       "      <th>DEBILT_global_radiation</th>\n",
       "      <th>DEBILT_precipitation</th>\n",
       "      <th>DEBILT_sunshine</th>\n",
       "      <th>DEBILT_temp_mean</th>\n",
       "      <th>DEBILT_temp_min</th>\n",
       "      <th>DEBILT_temp_max</th>\n",
       "      <th>DUSSELDORF_cloud_cover</th>\n",
       "      <th>DUSSELDORF_humidity</th>\n",
       "      <th>DUSSELDORF_pressure</th>\n",
       "      <th>DUSSELDORF_global_radiation</th>\n",
       "      <th>DUSSELDORF_precipitation</th>\n",
       "      <th>DUSSELDORF_sunshine</th>\n",
       "      <th>DUSSELDORF_temp_mean</th>\n",
       "      <th>DUSSELDORF_temp_min</th>\n",
       "      <th>DUSSELDORF_temp_max</th>\n",
       "      <th>HEATHROW_cloud_cover</th>\n",
       "      <th>HEATHROW_humidity</th>\n",
       "      <th>HEATHROW_pressure</th>\n",
       "      <th>HEATHROW_global_radiation</th>\n",
       "      <th>HEATHROW_precipitation</th>\n",
       "      <th>HEATHROW_sunshine</th>\n",
       "      <th>HEATHROW_temp_mean</th>\n",
       "      <th>HEATHROW_temp_min</th>\n",
       "      <th>HEATHROW_temp_max</th>\n",
       "      <th>KASSEL_cloud_cover</th>\n",
       "      <th>KASSEL_humidity</th>\n",
       "      <th>KASSEL_pressure</th>\n",
       "      <th>KASSEL_global_radiation</th>\n",
       "      <th>KASSEL_precipitation</th>\n",
       "      <th>KASSEL_sunshine</th>\n",
       "      <th>KASSEL_temp_mean</th>\n",
       "      <th>KASSEL_temp_min</th>\n",
       "      <th>KASSEL_temp_max</th>\n",
       "      <th>LJUBLJANA_cloud_cover</th>\n",
       "      <th>LJUBLJANA_humidity</th>\n",
       "      <th>LJUBLJANA_pressure</th>\n",
       "      <th>LJUBLJANA_global_radiation</th>\n",
       "      <th>LJUBLJANA_precipitation</th>\n",
       "      <th>LJUBLJANA_sunshine</th>\n",
       "      <th>LJUBLJANA_temp_mean</th>\n",
       "      <th>LJUBLJANA_temp_min</th>\n",
       "      <th>LJUBLJANA_temp_max</th>\n",
       "      <th>MAASTRICHT_cloud_cover</th>\n",
       "      <th>MAASTRICHT_humidity</th>\n",
       "      <th>MAASTRICHT_pressure</th>\n",
       "      <th>MAASTRICHT_global_radiation</th>\n",
       "      <th>MAASTRICHT_precipitation</th>\n",
       "      <th>MAASTRICHT_sunshine</th>\n",
       "      <th>MAASTRICHT_temp_mean</th>\n",
       "      <th>MAASTRICHT_temp_min</th>\n",
       "      <th>MAASTRICHT_temp_max</th>\n",
       "      <th>MADRID_cloud_cover</th>\n",
       "      <th>MADRID_humidity</th>\n",
       "      <th>MADRID_pressure</th>\n",
       "      <th>MADRID_global_radiation</th>\n",
       "      <th>MADRID_precipitation</th>\n",
       "      <th>MADRID_sunshine</th>\n",
       "      <th>MADRID_temp_mean</th>\n",
       "      <th>MADRID_temp_min</th>\n",
       "      <th>MADRID_temp_max</th>\n",
       "      <th>MUNCHENB_cloud_cover</th>\n",
       "      <th>MUNCHENB_humidity</th>\n",
       "      <th>MUNCHENB_pressure</th>\n",
       "      <th>MUNCHENB_global_radiation</th>\n",
       "      <th>MUNCHENB_precipitation</th>\n",
       "      <th>MUNCHENB_sunshine</th>\n",
       "      <th>MUNCHENB_temp_mean</th>\n",
       "      <th>MUNCHENB_temp_min</th>\n",
       "      <th>MUNCHENB_temp_max</th>\n",
       "      <th>OSLO_cloud_cover</th>\n",
       "      <th>OSLO_humidity</th>\n",
       "      <th>OSLO_pressure</th>\n",
       "      <th>OSLO_global_radiation</th>\n",
       "      <th>OSLO_precipitation</th>\n",
       "      <th>OSLO_sunshine</th>\n",
       "      <th>OSLO_temp_mean</th>\n",
       "      <th>OSLO_temp_min</th>\n",
       "      <th>OSLO_temp_max</th>\n",
       "      <th>SONNBLICK_cloud_cover</th>\n",
       "      <th>SONNBLICK_humidity</th>\n",
       "      <th>SONNBLICK_pressure</th>\n",
       "      <th>SONNBLICK_global_radiation</th>\n",
       "      <th>SONNBLICK_precipitation</th>\n",
       "      <th>SONNBLICK_sunshine</th>\n",
       "      <th>SONNBLICK_temp_mean</th>\n",
       "      <th>SONNBLICK_temp_min</th>\n",
       "      <th>SONNBLICK_temp_max</th>\n",
       "      <th>STOCKHOLM_cloud_cover</th>\n",
       "      <th>STOCKHOLM_humidity</th>\n",
       "      <th>STOCKHOLM_pressure</th>\n",
       "      <th>STOCKHOLM_global_radiation</th>\n",
       "      <th>STOCKHOLM_precipitation</th>\n",
       "      <th>STOCKHOLM_sunshine</th>\n",
       "      <th>STOCKHOLM_temp_mean</th>\n",
       "      <th>STOCKHOLM_temp_min</th>\n",
       "      <th>STOCKHOLM_temp_max</th>\n",
       "      <th>VALENTIA_cloud_cover</th>\n",
       "      <th>VALENTIA_humidity</th>\n",
       "      <th>VALENTIA_pressure</th>\n",
       "      <th>VALENTIA_global_radiation</th>\n",
       "      <th>VALENTIA_precipitation</th>\n",
       "      <th>VALENTIA_sunshine</th>\n",
       "      <th>VALENTIA_temp_mean</th>\n",
       "      <th>VALENTIA_temp_min</th>\n",
       "      <th>VALENTIA_temp_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19600101</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1.018</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.7</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>10.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.81</td>\n",
       "      <td>1.0195</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>7.9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.017</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.4</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>5.1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1.0032</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.3</td>\n",
       "      <td>7.4</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1.0161</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>7</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.6</td>\n",
       "      <td>9.4</td>\n",
       "      <td>8.3</td>\n",
       "      <td>8</td>\n",
       "      <td>0.82</td>\n",
       "      <td>1.0094</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.48</td>\n",
       "      <td>1.6</td>\n",
       "      <td>7.9</td>\n",
       "      <td>3.9</td>\n",
       "      <td>9.4</td>\n",
       "      <td>8</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0173</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>-1.9</td>\n",
       "      <td>0.5</td>\n",
       "      <td>7</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1.0063</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>8.5</td>\n",
       "      <td>11.1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.0260</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>7.6</td>\n",
       "      <td>4.4</td>\n",
       "      <td>10.8</td>\n",
       "      <td>5</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.018</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>1.1</td>\n",
       "      <td>10.4</td>\n",
       "      <td>8</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.8</td>\n",
       "      <td>5.9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.73</td>\n",
       "      <td>1.0304</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.3</td>\n",
       "      <td>-5.9</td>\n",
       "      <td>-8.5</td>\n",
       "      <td>-3.2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.0114</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>5</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1.0003</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.34</td>\n",
       "      <td>4.7</td>\n",
       "      <td>8.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19600102</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1.018</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.05</td>\n",
       "      <td>1.1</td>\n",
       "      <td>6.1</td>\n",
       "      <td>3.3</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1.0172</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.2</td>\n",
       "      <td>4.4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.017</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.0056</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.1</td>\n",
       "      <td>7.7</td>\n",
       "      <td>6.4</td>\n",
       "      <td>8.3</td>\n",
       "      <td>8</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1.0161</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.5</td>\n",
       "      <td>8.2</td>\n",
       "      <td>7.4</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.0051</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>3.9</td>\n",
       "      <td>10.6</td>\n",
       "      <td>8</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1.0086</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>6.8</td>\n",
       "      <td>9.1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1.0173</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.13</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2.1</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>5.5</td>\n",
       "      <td>8</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.0062</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.34</td>\n",
       "      <td>0.4</td>\n",
       "      <td>8.6</td>\n",
       "      <td>7.5</td>\n",
       "      <td>9.9</td>\n",
       "      <td>7</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1.0254</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>9.8</td>\n",
       "      <td>7.4</td>\n",
       "      <td>12.2</td>\n",
       "      <td>6</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1.018</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.30</td>\n",
       "      <td>5.1</td>\n",
       "      <td>6.2</td>\n",
       "      <td>4.2</td>\n",
       "      <td>10.2</td>\n",
       "      <td>8</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1.0139</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.9</td>\n",
       "      <td>6</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.0292</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.5</td>\n",
       "      <td>-10.5</td>\n",
       "      <td>-8.5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1.0114</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.0007</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.7</td>\n",
       "      <td>8.9</td>\n",
       "      <td>5.6</td>\n",
       "      <td>12.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19600103</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.018</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>5.1</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.0179</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.1</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>6.4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.017</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.7</td>\n",
       "      <td>1.7</td>\n",
       "      <td>5.3</td>\n",
       "      <td>6</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.0165</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>4.6</td>\n",
       "      <td>9.9</td>\n",
       "      <td>7</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.0161</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>6.9</td>\n",
       "      <td>9.1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.0166</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.1</td>\n",
       "      <td>8.4</td>\n",
       "      <td>6.1</td>\n",
       "      <td>12.2</td>\n",
       "      <td>7</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.0129</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.0173</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>6.3</td>\n",
       "      <td>7</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.0167</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>5.5</td>\n",
       "      <td>9.9</td>\n",
       "      <td>5</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.0287</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>8.6</td>\n",
       "      <td>6.4</td>\n",
       "      <td>10.8</td>\n",
       "      <td>6</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.018</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.69</td>\n",
       "      <td>1.0234</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1.0320</td>\n",
       "      <td>0.21</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.5</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-8.9</td>\n",
       "      <td>5</td>\n",
       "      <td>0.69</td>\n",
       "      <td>1.0114</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>4.1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.0096</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.5</td>\n",
       "      <td>8.1</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19600104</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.018</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.1</td>\n",
       "      <td>6.3</td>\n",
       "      <td>3.8</td>\n",
       "      <td>10.6</td>\n",
       "      <td>8</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1.0268</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.017</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4.4</td>\n",
       "      <td>8</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.0265</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3.6</td>\n",
       "      <td>10.1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1.0161</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.6</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.0230</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6.7</td>\n",
       "      <td>8.9</td>\n",
       "      <td>8</td>\n",
       "      <td>0.87</td>\n",
       "      <td>1.0290</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>5.2</td>\n",
       "      <td>6.5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1.0173</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1.0277</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0281</td>\n",
       "      <td>1.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.7</td>\n",
       "      <td>10.3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>16.1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.018</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.4</td>\n",
       "      <td>8</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.0244</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4.9</td>\n",
       "      <td>5</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1.0443</td>\n",
       "      <td>0.22</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-11.5</td>\n",
       "      <td>-12.9</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.0114</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>7</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1.0184</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>7.3</td>\n",
       "      <td>10.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19600105</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.018</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.14</td>\n",
       "      <td>5.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.0286</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.017</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.1</td>\n",
       "      <td>5.3</td>\n",
       "      <td>6</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.0243</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>11.2</td>\n",
       "      <td>7</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.0161</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>6.2</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1.0275</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.1</td>\n",
       "      <td>8.9</td>\n",
       "      <td>8.9</td>\n",
       "      <td>7.2</td>\n",
       "      <td>7</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1.0262</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1.0173</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4.8</td>\n",
       "      <td>7</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.0259</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>11.1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.0269</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.8</td>\n",
       "      <td>12.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1.018</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.96</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.0092</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0430</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.01</td>\n",
       "      <td>6.1</td>\n",
       "      <td>-9.3</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>-6.5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.0114</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>4.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.0328</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.7</td>\n",
       "      <td>5.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       DATE  MONTH  BASEL_cloud_cover  BASEL_humidity  BASEL_pressure  \\\n",
       "0  19600101      1                  7            0.85           1.018   \n",
       "1  19600102      1                  6            0.84           1.018   \n",
       "2  19600103      1                  8            0.90           1.018   \n",
       "3  19600104      1                  3            0.92           1.018   \n",
       "4  19600105      1                  6            0.95           1.018   \n",
       "\n",
       "   BASEL_global_radiation  BASEL_precipitation  BASEL_sunshine  \\\n",
       "0                    0.32                 0.09             0.7   \n",
       "1                    0.36                 1.05             1.1   \n",
       "2                    0.18                 0.30             0.0   \n",
       "3                    0.58                 0.00             4.1   \n",
       "4                    0.65                 0.14             5.4   \n",
       "\n",
       "   BASEL_temp_mean  BASEL_temp_min  BASEL_temp_max  BELGRADE_cloud_cover  \\\n",
       "0              6.5             0.8            10.9                     1   \n",
       "1              6.1             3.3            10.1                     6   \n",
       "2              8.5             5.1             9.9                     6   \n",
       "3              6.3             3.8            10.6                     8   \n",
       "4              3.0            -0.7             6.0                     8   \n",
       "\n",
       "   BELGRADE_humidity  BELGRADE_pressure  BELGRADE_global_radiation  \\\n",
       "0               0.81             1.0195                       0.88   \n",
       "1               0.84             1.0172                       0.25   \n",
       "2               0.77             1.0179                       0.67   \n",
       "3               0.93             1.0268                       0.25   \n",
       "4               0.99             1.0286                       0.25   \n",
       "\n",
       "   BELGRADE_precipitation  BELGRADE_sunshine  BELGRADE_temp_mean  \\\n",
       "0                    0.00                7.0                 3.7   \n",
       "1                    0.00                0.0                 2.9   \n",
       "2                    0.00                3.5                 3.1   \n",
       "3                    0.00                0.0                 2.0   \n",
       "4                    0.06                0.0                 2.0   \n",
       "\n",
       "   BELGRADE_temp_min  BELGRADE_temp_max  BUDAPEST_cloud_cover  \\\n",
       "0               -0.9                7.9                     4   \n",
       "1                2.2                4.4                     4   \n",
       "2               -0.5                6.4                     4   \n",
       "3               -2.0                3.0                     4   \n",
       "4                0.7                2.8                     4   \n",
       "\n",
       "   BUDAPEST_humidity  BUDAPEST_pressure  BUDAPEST_global_radiation  \\\n",
       "0               0.67              1.017                       0.44   \n",
       "1               0.67              1.017                       0.18   \n",
       "2               0.67              1.017                       0.30   \n",
       "3               0.67              1.017                       0.19   \n",
       "4               0.67              1.017                       0.19   \n",
       "\n",
       "   BUDAPEST_precipitation  BUDAPEST_sunshine  BUDAPEST_temp_mean  \\\n",
       "0                    0.01                2.3                 2.4   \n",
       "1                    0.31                0.0                 2.3   \n",
       "2                    0.00                0.6                 2.7   \n",
       "3                    0.00                0.0                 2.0   \n",
       "4                    0.00                0.0                 2.5   \n",
       "\n",
       "   BUDAPEST_temp_min  BUDAPEST_temp_max  DEBILT_cloud_cover  DEBILT_humidity  \\\n",
       "0               -0.4                5.1                   7             0.85   \n",
       "1                1.4                3.1                   8             0.90   \n",
       "2                1.7                5.3                   6             0.92   \n",
       "3                0.4                4.4                   8             0.95   \n",
       "4                1.1                5.3                   6             0.90   \n",
       "\n",
       "   DEBILT_pressure  DEBILT_global_radiation  DEBILT_precipitation  \\\n",
       "0           1.0032                     0.07                  0.25   \n",
       "1           1.0056                     0.14                  0.06   \n",
       "2           1.0165                     0.28                  0.01   \n",
       "3           1.0265                     0.08                  0.09   \n",
       "4           1.0243                     0.04                  0.39   \n",
       "\n",
       "   DEBILT_sunshine  DEBILT_temp_mean  DEBILT_temp_min  DEBILT_temp_max  \\\n",
       "0              0.0               9.3              7.4             11.0   \n",
       "1              0.1               7.7              6.4              8.3   \n",
       "2              3.0               6.8              4.6              9.9   \n",
       "3              0.0               6.7              3.6             10.1   \n",
       "4              0.0               8.0              2.4             11.2   \n",
       "\n",
       "   DUSSELDORF_cloud_cover  DUSSELDORF_humidity  DUSSELDORF_pressure  \\\n",
       "0                       8                 0.83               1.0161   \n",
       "1                       8                 0.89               1.0161   \n",
       "2                       7                 0.95               1.0161   \n",
       "3                       8                 0.86               1.0161   \n",
       "4                       7                 0.92               1.0161   \n",
       "\n",
       "   DUSSELDORF_global_radiation  DUSSELDORF_precipitation  DUSSELDORF_sunshine  \\\n",
       "0                         0.12                      0.08                  0.0   \n",
       "1                         0.18                      0.66                  0.5   \n",
       "2                         0.12                      0.07                  0.0   \n",
       "3                         0.12                      0.02                  0.0   \n",
       "4                         0.12                      0.62                  0.0   \n",
       "\n",
       "   DUSSELDORF_temp_mean  DUSSELDORF_temp_min  DUSSELDORF_temp_max  \\\n",
       "0                  10.0                  7.0                 11.5   \n",
       "1                   8.2                  7.4                 11.0   \n",
       "2                   7.1                  6.9                  9.1   \n",
       "3                   6.8                  3.6                  8.0   \n",
       "4                   7.7                  6.2                 11.0   \n",
       "\n",
       "   HEATHROW_cloud_cover  HEATHROW_humidity  HEATHROW_pressure  \\\n",
       "0                     7               0.91             1.0010   \n",
       "1                     7               0.98             1.0051   \n",
       "2                     8               0.96             1.0166   \n",
       "3                     8               0.98             1.0230   \n",
       "4                     5               0.84             1.0275   \n",
       "\n",
       "   HEATHROW_global_radiation  HEATHROW_precipitation  HEATHROW_sunshine  \\\n",
       "0                       0.13                    0.22                0.0   \n",
       "1                       0.13                    0.23                0.0   \n",
       "2                       0.15                    0.07                0.1   \n",
       "3                       0.13                    0.00                0.0   \n",
       "4                       0.30                    0.00                2.1   \n",
       "\n",
       "   HEATHROW_temp_mean  HEATHROW_temp_min  HEATHROW_temp_max  \\\n",
       "0                10.6                9.4                8.3   \n",
       "1                 6.1                3.9               10.6   \n",
       "2                 8.4                6.1               12.2   \n",
       "3                 9.4                6.7                8.9   \n",
       "4                 8.9                8.9                7.2   \n",
       "\n",
       "   KASSEL_cloud_cover  KASSEL_humidity  KASSEL_pressure  \\\n",
       "0                   8             0.82           1.0094   \n",
       "1                   8             0.86           1.0086   \n",
       "2                   7             0.91           1.0129   \n",
       "3                   8             0.87           1.0290   \n",
       "4                   7             0.86           1.0262   \n",
       "\n",
       "   KASSEL_global_radiation  KASSEL_precipitation  KASSEL_sunshine  \\\n",
       "0                     0.28                  0.48              1.6   \n",
       "1                     0.12                  0.27              0.0   \n",
       "2                     0.12                  0.60              0.0   \n",
       "3                     0.12                  0.00              0.0   \n",
       "4                     0.13                  0.71              0.0   \n",
       "\n",
       "   KASSEL_temp_mean  KASSEL_temp_min  KASSEL_temp_max  LJUBLJANA_cloud_cover  \\\n",
       "0               7.9              3.9              9.4                      8   \n",
       "1               7.7              6.8              9.1                      6   \n",
       "2               6.5              6.0              8.0                      8   \n",
       "3               5.8              5.2              6.5                      6   \n",
       "4               5.4              3.7              6.0                      7   \n",
       "\n",
       "   LJUBLJANA_humidity  LJUBLJANA_pressure  LJUBLJANA_global_radiation  \\\n",
       "0                1.00              1.0173                        0.20   \n",
       "1                0.94              1.0173                        0.56   \n",
       "2                0.96              1.0173                        0.20   \n",
       "3                0.94              1.0173                        0.49   \n",
       "4                0.94              1.0173                        0.20   \n",
       "\n",
       "   LJUBLJANA_precipitation  LJUBLJANA_sunshine  LJUBLJANA_temp_mean  \\\n",
       "0                     0.00                 0.0                 -0.6   \n",
       "1                     0.13                 3.2                  2.1   \n",
       "2                     0.12                 0.0                  4.6   \n",
       "3                     0.00                 2.2                  3.2   \n",
       "4                     0.00                 0.0                  3.6   \n",
       "\n",
       "   LJUBLJANA_temp_min  LJUBLJANA_temp_max  MAASTRICHT_cloud_cover  \\\n",
       "0                -1.9                 0.5                       7   \n",
       "1                -1.3                 5.5                       8   \n",
       "2                 0.9                 6.3                       7   \n",
       "3                 1.0                 7.0                       7   \n",
       "4                 0.4                 4.8                       7   \n",
       "\n",
       "   MAASTRICHT_humidity  MAASTRICHT_pressure  MAASTRICHT_global_radiation  \\\n",
       "0                 0.83               1.0063                         0.22   \n",
       "1                 0.92               1.0062                         0.17   \n",
       "2                 0.97               1.0167                         0.12   \n",
       "3                 0.89               1.0277                         0.16   \n",
       "4                 0.92               1.0259                         0.12   \n",
       "\n",
       "   MAASTRICHT_precipitation  MAASTRICHT_sunshine  MAASTRICHT_temp_mean  \\\n",
       "0                      0.32                  1.0                   9.5   \n",
       "1                      1.34                  0.4                   8.6   \n",
       "2                      0.46                  0.0                   6.9   \n",
       "3                      0.00                  0.3                   7.0   \n",
       "4                      0.56                  0.0                   8.1   \n",
       "\n",
       "   MAASTRICHT_temp_min  MAASTRICHT_temp_max  MADRID_cloud_cover  \\\n",
       "0                  8.5                 11.1                   6   \n",
       "1                  7.5                  9.9                   7   \n",
       "2                  5.5                  9.9                   5   \n",
       "3                  3.0                 10.0                   0   \n",
       "4                  2.5                 11.1                   2   \n",
       "\n",
       "   MADRID_humidity  MADRID_pressure  MADRID_global_radiation  \\\n",
       "0             0.92           1.0260                     0.53   \n",
       "1             0.86           1.0254                     0.46   \n",
       "2             0.90           1.0287                     0.63   \n",
       "3             0.75           1.0281                     1.16   \n",
       "4             0.64           1.0269                     1.10   \n",
       "\n",
       "   MADRID_precipitation  MADRID_sunshine  MADRID_temp_mean  MADRID_temp_min  \\\n",
       "0                   0.0              1.4               7.6              4.4   \n",
       "1                   0.0              0.9               9.8              7.4   \n",
       "2                   0.0              2.3               8.6              6.4   \n",
       "3                   0.0              8.7              10.3              4.5   \n",
       "4                   0.0              7.8              12.1              8.2   \n",
       "\n",
       "   MADRID_temp_max  MUNCHENB_cloud_cover  MUNCHENB_humidity  \\\n",
       "0             10.8                     5               0.67   \n",
       "1             12.2                     6               0.72   \n",
       "2             10.8                     6               0.91   \n",
       "3             16.1                     6               0.90   \n",
       "4             16.0                     5               0.85   \n",
       "\n",
       "   MUNCHENB_pressure  MUNCHENB_global_radiation  MUNCHENB_precipitation  \\\n",
       "0              1.018                       0.20                    0.10   \n",
       "1              1.018                       0.61                    0.30   \n",
       "2              1.018                       0.20                    0.30   \n",
       "3              1.018                       0.20                    0.01   \n",
       "4              1.018                       0.65                    0.96   \n",
       "\n",
       "   MUNCHENB_sunshine  MUNCHENB_temp_mean  MUNCHENB_temp_min  \\\n",
       "0                0.0                 6.9                1.1   \n",
       "1                5.1                 6.2                4.2   \n",
       "2                0.0                 5.8                4.0   \n",
       "3                0.0                 3.9                3.2   \n",
       "4                5.6                 1.8               -3.0   \n",
       "\n",
       "   MUNCHENB_temp_max  OSLO_cloud_cover  OSLO_humidity  OSLO_pressure  \\\n",
       "0               10.4                 8           0.98         0.9978   \n",
       "1               10.2                 8           0.62         1.0139   \n",
       "2                8.0                 8           0.69         1.0234   \n",
       "3                5.4                 8           0.98         1.0244   \n",
       "4                6.0                 8           0.96         1.0092   \n",
       "\n",
       "   OSLO_global_radiation  OSLO_precipitation  OSLO_sunshine  OSLO_temp_mean  \\\n",
       "0                   0.04                1.14            0.0             4.9   \n",
       "1                   0.04                0.00            0.0             3.4   \n",
       "2                   0.04                0.08            0.0             1.9   \n",
       "3                   0.04                0.35            0.0             3.0   \n",
       "4                   0.05                0.26            0.0             3.7   \n",
       "\n",
       "   OSLO_temp_min  OSLO_temp_max  SONNBLICK_cloud_cover  SONNBLICK_humidity  \\\n",
       "0            3.8            5.9                      4                0.73   \n",
       "1            2.8            4.9                      6                0.97   \n",
       "2            0.6            3.1                      8                0.93   \n",
       "3            0.4            4.9                      5                0.93   \n",
       "4            2.9            4.9                      2                0.75   \n",
       "\n",
       "   SONNBLICK_pressure  SONNBLICK_global_radiation  SONNBLICK_precipitation  \\\n",
       "0              1.0304                        0.48                     0.01   \n",
       "1              1.0292                        0.21                     0.61   \n",
       "2              1.0320                        0.21                     3.20   \n",
       "3              1.0443                        0.22                     1.10   \n",
       "4              1.0430                        0.72                     0.01   \n",
       "\n",
       "   SONNBLICK_sunshine  SONNBLICK_temp_mean  SONNBLICK_temp_min  \\\n",
       "0                 2.3                 -5.9                -8.5   \n",
       "1                 0.0                 -9.5               -10.5   \n",
       "2                 0.0                 -9.5               -10.0   \n",
       "3                 0.0                -11.5               -12.9   \n",
       "4                 6.1                 -9.3               -12.0   \n",
       "\n",
       "   SONNBLICK_temp_max  STOCKHOLM_cloud_cover  STOCKHOLM_humidity  \\\n",
       "0                -3.2                      5                0.98   \n",
       "1                -8.5                      5                0.62   \n",
       "2                -8.9                      5                0.69   \n",
       "3               -10.0                      5                0.98   \n",
       "4                -6.5                      5                0.96   \n",
       "\n",
       "   STOCKHOLM_pressure  STOCKHOLM_global_radiation  STOCKHOLM_precipitation  \\\n",
       "0              1.0114                        0.05                     0.32   \n",
       "1              1.0114                        0.05                     0.06   \n",
       "2              1.0114                        0.05                     0.02   \n",
       "3              1.0114                        0.05                     0.00   \n",
       "4              1.0114                        0.05                     1.32   \n",
       "\n",
       "   STOCKHOLM_sunshine  STOCKHOLM_temp_mean  STOCKHOLM_temp_min  \\\n",
       "0                 0.0                  4.2                 2.2   \n",
       "1                 0.0                  4.0                 3.0   \n",
       "2                 0.0                  2.4                 1.3   \n",
       "3                 0.0                  1.2                 0.4   \n",
       "4                 0.0                  3.3                 0.8   \n",
       "\n",
       "   STOCKHOLM_temp_max  VALENTIA_cloud_cover  VALENTIA_humidity  \\\n",
       "0                 4.9                     5               0.88   \n",
       "1                 5.0                     7               0.91   \n",
       "2                 4.1                     7               0.91   \n",
       "3                 2.3                     7               0.86   \n",
       "4                 4.3                     3               0.80   \n",
       "\n",
       "   VALENTIA_pressure  VALENTIA_global_radiation  VALENTIA_precipitation  \\\n",
       "0             1.0003                       0.45                    0.34   \n",
       "1             1.0007                       0.25                    0.84   \n",
       "2             1.0096                       0.17                    0.08   \n",
       "3             1.0184                       0.13                    0.98   \n",
       "4             1.0328                       0.46                    0.00   \n",
       "\n",
       "   VALENTIA_sunshine  VALENTIA_temp_mean  VALENTIA_temp_min  VALENTIA_temp_max  \n",
       "0                4.7                 8.5                6.0               10.9  \n",
       "1                0.7                 8.9                5.6               12.1  \n",
       "2                0.1                10.5                8.1               12.9  \n",
       "3                0.0                 7.4                7.3               10.6  \n",
       "4                5.7                 5.7                3.0                8.4  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac103755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22950, 137)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2a5225d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>BASEL_pleasant_weather</th>\n",
       "      <th>BELGRADE_pleasant_weather</th>\n",
       "      <th>BUDAPEST_pleasant_weather</th>\n",
       "      <th>DEBILT_pleasant_weather</th>\n",
       "      <th>DUSSELDORF_pleasant_weather</th>\n",
       "      <th>HEATHROW_pleasant_weather</th>\n",
       "      <th>KASSEL_pleasant_weather</th>\n",
       "      <th>LJUBLJANA_pleasant_weather</th>\n",
       "      <th>MAASTRICHT_pleasant_weather</th>\n",
       "      <th>MADRID_pleasant_weather</th>\n",
       "      <th>MUNCHENB_pleasant_weather</th>\n",
       "      <th>OSLO_pleasant_weather</th>\n",
       "      <th>SONNBLICK_pleasant_weather</th>\n",
       "      <th>STOCKHOLM_pleasant_weather</th>\n",
       "      <th>VALENTIA_pleasant_weather</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19600101</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19600102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19600103</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19600104</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19600105</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       DATE  BASEL_pleasant_weather  BELGRADE_pleasant_weather  \\\n",
       "0  19600101                       0                          0   \n",
       "1  19600102                       0                          0   \n",
       "2  19600103                       0                          0   \n",
       "3  19600104                       0                          0   \n",
       "4  19600105                       0                          0   \n",
       "\n",
       "   BUDAPEST_pleasant_weather  DEBILT_pleasant_weather  \\\n",
       "0                          0                        0   \n",
       "1                          0                        0   \n",
       "2                          0                        0   \n",
       "3                          0                        0   \n",
       "4                          0                        0   \n",
       "\n",
       "   DUSSELDORF_pleasant_weather  HEATHROW_pleasant_weather  \\\n",
       "0                            0                          0   \n",
       "1                            0                          0   \n",
       "2                            0                          0   \n",
       "3                            0                          0   \n",
       "4                            0                          0   \n",
       "\n",
       "   KASSEL_pleasant_weather  LJUBLJANA_pleasant_weather  \\\n",
       "0                        0                           0   \n",
       "1                        0                           0   \n",
       "2                        0                           0   \n",
       "3                        0                           0   \n",
       "4                        0                           0   \n",
       "\n",
       "   MAASTRICHT_pleasant_weather  MADRID_pleasant_weather  \\\n",
       "0                            0                        0   \n",
       "1                            0                        0   \n",
       "2                            0                        0   \n",
       "3                            0                        0   \n",
       "4                            0                        0   \n",
       "\n",
       "   MUNCHENB_pleasant_weather  OSLO_pleasant_weather  \\\n",
       "0                          0                      0   \n",
       "1                          0                      0   \n",
       "2                          0                      0   \n",
       "3                          0                      0   \n",
       "4                          0                      0   \n",
       "\n",
       "   SONNBLICK_pleasant_weather  STOCKHOLM_pleasant_weather  \\\n",
       "0                           0                           0   \n",
       "1                           0                           0   \n",
       "2                           0                           0   \n",
       "3                           0                           0   \n",
       "4                           0                           0   \n",
       "\n",
       "   VALENTIA_pleasant_weather  \n",
       "0                          0  \n",
       "1                          0  \n",
       "2                          0  \n",
       "3                          0  \n",
       "4                          0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6f5eba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22950, 16)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aaec0cf",
   "metadata": {},
   "source": [
    "# Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0775cdc3-7858-4b14-b2a0-b6dd35564eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "\n",
    "X.drop(['DATE', 'MONTH'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d658986c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22950, 135)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape # observations dataset has the correct shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b21097a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers.drop(columns = 'DATE', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4fb612fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22950, 15)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers.shape # predictions dataset has the correct shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa00807b",
   "metadata": {},
   "source": [
    "# Reshaping for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98ffe3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn X and answers from a df to arrays\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc14e1ae-2c2a-406f-8396-07ce412f9b79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22950, 135)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6fbc1bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape(-1,15,9) #X has the form (22950, 15, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a0e3944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22950, 15, 9)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify shape\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5cd12373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use argmax to transform y\n",
    "\n",
    "y =  np.argmax(y, axis = 1)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c3842442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22950,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape #y has the right form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "240fc6f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'multiclass'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check y layout\n",
    "\n",
    "from sklearn.utils.multiclass import type_of_target\n",
    "type_of_target(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa97ec78",
   "metadata": {},
   "source": [
    "#### The Bayesian optimization function only accepts y data in multiclass and binary layouts but not in multilabel-indicator."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3190e56f",
   "metadata": {},
   "source": [
    "# Data Split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e4464d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "511dee2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17212, 15, 9) (17212,)\n",
      "(5738, 15, 9) (5738,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e64ef01",
   "metadata": {},
   "source": [
    "# Bayesian Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "234c9996",
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = len(X_train[0])\n",
    "input_dim = len(X_train[0][0])\n",
    "n_classes = 15 # Number of weather stations\n",
    "# Make scorer accuracy\n",
    "score_acc = make_scorer(accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f4c7b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function\n",
    "\n",
    "def bay_area(neurons, activation, kernel, optimizer, learning_rate, batch_size, epochs,\n",
    "              layers1, layers2, normalization, dropout, dropout_rate): \n",
    "    optimizerL = ['SGD', 'Adam', 'RMSprop', 'Adadelta', 'Adagrad', 'Adamax', 'Nadam', 'Ftrl','SGD']\n",
    "    #optimizerD= {'Adam':Adam(lr=learning_rate), 'SGD':SGD(lr=learning_rate),\n",
    "                 #'RMSprop':RMSprop(lr=learning_rate), 'Adadelta':Adadelta(lr=learning_rate),\n",
    "                 #'Adagrad':Adagrad(lr=learning_rate), 'Adamax':Adamax(lr=learning_rate),\n",
    "                 #'Nadam':Nadam(lr=learning_rate), 'Ftrl':Ftrl(lr=learning_rate)}\n",
    "    activationL = ['relu', 'sigmoid', 'softplus', 'softsign', 'tanh', 'selu',\n",
    "                   'elu', 'exponential', LeakyReLU,'relu']\n",
    "    \n",
    "    neurons = round(neurons)\n",
    "    kernel = round(kernel)\n",
    "    activation = activationL[round(activation)]  #optimizerD[optimizerL[round(optimizer)]]\n",
    "    optimizer = optimizerL[round(optimizer)]\n",
    "    batch_size = round(batch_size)\n",
    "    \n",
    "    epochs = round(epochs)\n",
    "    layers1 = round(layers1)\n",
    "    layers2 = round(layers2)\n",
    "    \n",
    "    def cnn_model():\n",
    "        model = Sequential()\n",
    "        model.add(Conv1D(neurons, kernel_size=kernel,activation=activation, input_shape=(timesteps, input_dim)))\n",
    "        #model.add(Conv1D(32, kernel_size=1,activation='relu', input_shape=(timesteps, input_dim)))\n",
    "        \n",
    "        if normalization > 0.5:\n",
    "            model.add(BatchNormalization())\n",
    "        for i in range(layers1):\n",
    "            model.add(Dense(neurons, activation=activation)) #(neurons, activation=activation))\n",
    "        if dropout > 0.5:\n",
    "            model.add(Dropout(dropout_rate, seed=123))\n",
    "        for i in range(layers2):\n",
    "            model.add(Dense(neurons, activation=activation))\n",
    "        model.add(MaxPooling1D())\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(n_classes, activation='softmax')) #sigmoid softmax\n",
    "        #model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy']) #categorical_crossentropy\n",
    "        model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy']) #categorical_crossentropy\n",
    "        return model\n",
    "    es = EarlyStopping(monitor='accuracy', mode='max', verbose=2, patience=20)\n",
    "    nn = KerasClassifier(build_fn=cnn_model, epochs=epochs, batch_size=batch_size, verbose=2)\n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=123)\n",
    "    score = cross_val_score(nn, X_train, y_train, scoring=score_acc, cv=kfold, fit_params={'callbacks':[es]}).mean()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3eb249e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | activa... | batch_... |  dropout  | dropou... |  epochs   |  kernel   |  layers1  |  layers2  | learni... |  neurons  | normal... | optimizer |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch 1/15\n",
      "48/48 - 1s - 23ms/step - accuracy: 0.6322 - loss: 2.7003\n",
      "Epoch 2/15\n",
      "48/48 - 1s - 11ms/step - accuracy: 0.6440 - loss: 2.6908\n",
      "Epoch 3/15\n",
      "48/48 - 1s - 11ms/step - accuracy: 0.6440 - loss: 2.6840\n",
      "Epoch 4/15\n",
      "48/48 - 1s - 11ms/step - accuracy: 0.6440 - loss: 2.6781\n",
      "Epoch 5/15\n",
      "48/48 - 1s - 11ms/step - accuracy: 0.6440 - loss: 2.6728\n",
      "Epoch 6/15\n",
      "48/48 - 1s - 11ms/step - accuracy: 0.6440 - loss: 2.6675\n",
      "Epoch 7/15\n",
      "48/48 - 1s - 11ms/step - accuracy: 0.6440 - loss: 2.6621\n",
      "Epoch 8/15\n",
      "48/48 - 1s - 11ms/step - accuracy: 0.6440 - loss: 2.6563\n",
      "Epoch 9/15\n",
      "48/48 - 1s - 11ms/step - accuracy: 0.6440 - loss: 2.6497\n",
      "Epoch 10/15\n",
      "48/48 - 1s - 12ms/step - accuracy: 0.6440 - loss: 2.6419\n",
      "Epoch 11/15\n",
      "48/48 - 1s - 11ms/step - accuracy: 0.6440 - loss: 2.6326\n",
      "Epoch 12/15\n",
      "48/48 - 1s - 11ms/step - accuracy: 0.6440 - loss: 2.6213\n",
      "Epoch 13/15\n",
      "48/48 - 1s - 11ms/step - accuracy: 0.6440 - loss: 2.6075\n",
      "Epoch 14/15\n",
      "48/48 - 1s - 13ms/step - accuracy: 0.6440 - loss: 2.5908\n",
      "Epoch 15/15\n",
      "48/48 - 1s - 12ms/step - accuracy: 0.6440 - loss: 2.5707\n",
      "12/12 - 0s - 8ms/step\n",
      "Epoch 1/15\n",
      "48/48 - 1s - 21ms/step - accuracy: 0.6350 - loss: 2.7031\n",
      "Epoch 2/15\n",
      "48/48 - 1s - 11ms/step - accuracy: 0.6440 - loss: 2.6909\n",
      "Epoch 3/15\n",
      "48/48 - 1s - 11ms/step - accuracy: 0.6440 - loss: 2.6841\n",
      "Epoch 4/15\n",
      "48/48 - 1s - 11ms/step - accuracy: 0.6440 - loss: 2.6784\n",
      "Epoch 5/15\n",
      "48/48 - 1s - 11ms/step - accuracy: 0.6440 - loss: 2.6733\n",
      "Epoch 6/15\n",
      "48/48 - 1s - 11ms/step - accuracy: 0.6440 - loss: 2.6683\n",
      "Epoch 7/15\n",
      "48/48 - 1s - 11ms/step - accuracy: 0.6440 - loss: 2.6633\n",
      "Epoch 8/15\n",
      "48/48 - 1s - 11ms/step - accuracy: 0.6440 - loss: 2.6580\n",
      "Epoch 9/15\n",
      "48/48 - 1s - 12ms/step - accuracy: 0.6440 - loss: 2.6522\n",
      "Epoch 10/15\n",
      "48/48 - 1s - 11ms/step - accuracy: 0.6440 - loss: 2.6456\n",
      "Epoch 11/15\n",
      "48/48 - 1s - 11ms/step - accuracy: 0.6440 - loss: 2.6377\n",
      "Epoch 12/15\n",
      "48/48 - 1s - 11ms/step - accuracy: 0.6440 - loss: 2.6282\n",
      "Epoch 13/15\n",
      "48/48 - 1s - 12ms/step - accuracy: 0.6440 - loss: 2.6167\n",
      "Epoch 14/15\n",
      "48/48 - 1s - 11ms/step - accuracy: 0.6440 - loss: 2.6026\n",
      "Epoch 15/15\n",
      "48/48 - 1s - 11ms/step - accuracy: 0.6440 - loss: 2.5856\n",
      "12/12 - 0s - 8ms/step\n",
      "Epoch 1/15\n",
      "48/48 - 1s - 20ms/step - accuracy: 0.6296 - loss: 2.7017\n",
      "Epoch 2/15\n",
      "48/48 - 1s - 11ms/step - accuracy: 0.6439 - loss: 2.6908\n",
      "Epoch 3/15\n",
      "48/48 - 1s - 11ms/step - accuracy: 0.6439 - loss: 2.6839\n",
      "Epoch 4/15\n",
      "48/48 - 1s - 11ms/step - accuracy: 0.6439 - loss: 2.6780\n",
      "Epoch 5/15\n",
      "48/48 - 1s - 11ms/step - accuracy: 0.6439 - loss: 2.6727\n",
      "Epoch 6/15\n",
      "48/48 - 1s - 11ms/step - accuracy: 0.6439 - loss: 2.6675\n",
      "Epoch 7/15\n",
      "48/48 - 1s - 11ms/step - accuracy: 0.6439 - loss: 2.6622\n",
      "Epoch 8/15\n",
      "48/48 - 1s - 12ms/step - accuracy: 0.6439 - loss: 2.6567\n",
      "Epoch 9/15\n",
      "48/48 - 1s - 11ms/step - accuracy: 0.6439 - loss: 2.6507\n",
      "Epoch 10/15\n",
      "48/48 - 1s - 11ms/step - accuracy: 0.6439 - loss: 2.6439\n",
      "Epoch 11/15\n",
      "48/48 - 1s - 11ms/step - accuracy: 0.6439 - loss: 2.6360\n",
      "Epoch 12/15\n",
      "48/48 - 1s - 11ms/step - accuracy: 0.6439 - loss: 2.6265\n",
      "Epoch 13/15\n",
      "48/48 - 1s - 11ms/step - accuracy: 0.6439 - loss: 2.6152\n",
      "Epoch 14/15\n",
      "48/48 - 1s - 11ms/step - accuracy: 0.6439 - loss: 2.6015\n",
      "Epoch 15/15\n",
      "48/48 - 1s - 11ms/step - accuracy: 0.6439 - loss: 2.5850\n",
      "12/12 - 0s - 8ms/step\n",
      "Epoch 1/15\n",
      "48/48 - 1s - 20ms/step - accuracy: 0.6305 - loss: 2.7023\n",
      "Epoch 2/15\n",
      "48/48 - 1s - 11ms/step - accuracy: 0.6440 - loss: 2.6909\n",
      "Epoch 3/15\n",
      "48/48 - 1s - 12ms/step - accuracy: 0.6440 - loss: 2.6841\n",
      "Epoch 4/15\n",
      "48/48 - 1s - 11ms/step - accuracy: 0.6440 - loss: 2.6783\n",
      "Epoch 5/15\n",
      "48/48 - 1s - 11ms/step - accuracy: 0.6440 - loss: 2.6731\n",
      "Epoch 6/15\n",
      "48/48 - 1s - 12ms/step - accuracy: 0.6440 - loss: 2.6680\n",
      "Epoch 7/15\n",
      "48/48 - 1s - 12ms/step - accuracy: 0.6440 - loss: 2.6629\n",
      "Epoch 8/15\n",
      "48/48 - 1s - 11ms/step - accuracy: 0.6440 - loss: 2.6574\n",
      "Epoch 9/15\n",
      "48/48 - 1s - 11ms/step - accuracy: 0.6440 - loss: 2.6514\n",
      "Epoch 10/15\n",
      "48/48 - 1s - 11ms/step - accuracy: 0.6440 - loss: 2.6445\n",
      "Epoch 11/15\n",
      "48/48 - 1s - 11ms/step - accuracy: 0.6440 - loss: 2.6363\n",
      "Epoch 12/15\n",
      "48/48 - 1s - 11ms/step - accuracy: 0.6440 - loss: 2.6264\n",
      "Epoch 13/15\n",
      "48/48 - 1s - 11ms/step - accuracy: 0.6440 - loss: 2.6145\n",
      "Epoch 14/15\n",
      "48/48 - 1s - 12ms/step - accuracy: 0.6440 - loss: 2.6002\n",
      "Epoch 15/15\n",
      "48/48 - 1s - 11ms/step - accuracy: 0.6440 - loss: 2.5831\n",
      "12/12 - 0s - 8ms/step\n",
      "Epoch 1/15\n",
      "48/48 - 1s - 21ms/step - accuracy: 0.6310 - loss: 2.7029\n",
      "Epoch 2/15\n",
      "48/48 - 1s - 12ms/step - accuracy: 0.6439 - loss: 2.6911\n",
      "Epoch 3/15\n",
      "48/48 - 1s - 11ms/step - accuracy: 0.6439 - loss: 2.6844\n",
      "Epoch 4/15\n",
      "48/48 - 1s - 11ms/step - accuracy: 0.6439 - loss: 2.6788\n",
      "Epoch 5/15\n",
      "48/48 - 1s - 11ms/step - accuracy: 0.6439 - loss: 2.6738\n",
      "Epoch 6/15\n",
      "48/48 - 1s - 11ms/step - accuracy: 0.6439 - loss: 2.6691\n",
      "Epoch 7/15\n",
      "48/48 - 1s - 11ms/step - accuracy: 0.6439 - loss: 2.6646\n",
      "Epoch 8/15\n",
      "48/48 - 1s - 11ms/step - accuracy: 0.6439 - loss: 2.6599\n",
      "Epoch 9/15\n",
      "48/48 - 1s - 11ms/step - accuracy: 0.6439 - loss: 2.6548\n",
      "Epoch 10/15\n",
      "48/48 - 1s - 13ms/step - accuracy: 0.6439 - loss: 2.6492\n",
      "Epoch 11/15\n",
      "48/48 - 1s - 11ms/step - accuracy: 0.6439 - loss: 2.6427\n",
      "Epoch 12/15\n",
      "48/48 - 1s - 11ms/step - accuracy: 0.6439 - loss: 2.6349\n",
      "Epoch 13/15\n",
      "48/48 - 1s - 11ms/step - accuracy: 0.6439 - loss: 2.6254\n",
      "Epoch 14/15\n",
      "48/48 - 1s - 11ms/step - accuracy: 0.6439 - loss: 2.6137\n",
      "Epoch 15/15\n",
      "48/48 - 1s - 11ms/step - accuracy: 0.6439 - loss: 2.5993\n",
      "12/12 - 0s - 8ms/step\n",
      "| \u001b[39m1        \u001b[39m | \u001b[39m0.644    \u001b[39m | \u001b[39m3.371    \u001b[39m | \u001b[39m290.1    \u001b[39m | \u001b[39m0.732    \u001b[39m | \u001b[39m0.4197   \u001b[39m | \u001b[39m14.68    \u001b[39m | \u001b[39m1.312    \u001b[39m | \u001b[39m1.058    \u001b[39m | \u001b[39m1.866    \u001b[39m | \u001b[39m0.6015   \u001b[39m | \u001b[39m73.73    \u001b[39m | \u001b[39m0.02058  \u001b[39m | \u001b[39m6.789    \u001b[39m |\n",
      "Epoch 1/19\n",
      "97/97 - 1s - 6ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 2/19\n",
      "97/97 - 0s - 1ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 3/19\n",
      "97/97 - 0s - 1ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 4/19\n",
      "97/97 - 0s - 1ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 5/19\n",
      "97/97 - 0s - 1ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 6/19\n",
      "97/97 - 0s - 1ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 7/19\n",
      "97/97 - 0s - 1ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 8/19\n",
      "97/97 - 0s - 1ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 9/19\n",
      "97/97 - 0s - 1ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 10/19\n",
      "97/97 - 0s - 1ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 11/19\n",
      "97/97 - 0s - 1ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 12/19\n",
      "97/97 - 0s - 1ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 13/19\n",
      "97/97 - 0s - 1ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 14/19\n",
      "97/97 - 0s - 1ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 15/19\n",
      "97/97 - 0s - 1ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 16/19\n",
      "97/97 - 0s - 1ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 17/19\n",
      "97/97 - 0s - 1ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 18/19\n",
      "97/97 - 0s - 1ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 19/19\n",
      "97/97 - 0s - 1ms/step - accuracy: 0.6440 - loss: nan\n",
      "25/25 - 0s - 2ms/step\n",
      "Epoch 1/19\n",
      "97/97 - 0s - 4ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 2/19\n",
      "97/97 - 0s - 1ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 3/19\n",
      "97/97 - 0s - 1ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 4/19\n",
      "97/97 - 0s - 1ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 5/19\n",
      "97/97 - 0s - 1ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 6/19\n",
      "97/97 - 0s - 1ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 7/19\n",
      "97/97 - 0s - 1ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 8/19\n",
      "97/97 - 0s - 2ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 9/19\n",
      "97/97 - 0s - 1ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 10/19\n",
      "97/97 - 0s - 1ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 11/19\n",
      "97/97 - 0s - 1ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 12/19\n",
      "97/97 - 0s - 1ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 13/19\n",
      "97/97 - 0s - 1ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 14/19\n",
      "97/97 - 0s - 1ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 15/19\n",
      "97/97 - 0s - 1ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 16/19\n",
      "97/97 - 0s - 1ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 17/19\n",
      "97/97 - 0s - 1ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 18/19\n",
      "97/97 - 0s - 1ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 19/19\n",
      "97/97 - 0s - 1ms/step - accuracy: 0.6440 - loss: nan\n",
      "25/25 - 0s - 2ms/step\n",
      "Epoch 1/19\n",
      "97/97 - 0s - 4ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 2/19\n",
      "97/97 - 0s - 1ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 3/19\n",
      "97/97 - 0s - 1ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 4/19\n",
      "97/97 - 0s - 1ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 5/19\n",
      "97/97 - 0s - 1ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 6/19\n",
      "97/97 - 0s - 1ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 7/19\n",
      "97/97 - 0s - 1ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 8/19\n",
      "97/97 - 0s - 1ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 9/19\n",
      "97/97 - 0s - 1ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 10/19\n",
      "97/97 - 0s - 1ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 11/19\n",
      "97/97 - 0s - 1ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 12/19\n",
      "97/97 - 0s - 1ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 13/19\n",
      "97/97 - 0s - 1ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 14/19\n",
      "97/97 - 0s - 2ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 15/19\n",
      "97/97 - 0s - 1ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 16/19\n",
      "97/97 - 0s - 1ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 17/19\n",
      "97/97 - 0s - 1ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 18/19\n",
      "97/97 - 0s - 1ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 19/19\n",
      "97/97 - 0s - 1ms/step - accuracy: 0.6439 - loss: nan\n",
      "25/25 - 0s - 2ms/step\n",
      "Epoch 1/19\n",
      "97/97 - 0s - 4ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 2/19\n",
      "97/97 - 0s - 1ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 3/19\n",
      "97/97 - 0s - 1ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 4/19\n",
      "97/97 - 0s - 1ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 5/19\n",
      "97/97 - 0s - 1ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 6/19\n",
      "97/97 - 0s - 1ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 7/19\n",
      "97/97 - 0s - 1ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 8/19\n",
      "97/97 - 0s - 1ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 9/19\n",
      "97/97 - 0s - 1ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 10/19\n",
      "97/97 - 0s - 1ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 11/19\n",
      "97/97 - 0s - 1ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 12/19\n",
      "97/97 - 0s - 1ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 13/19\n",
      "97/97 - 0s - 1ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 14/19\n",
      "97/97 - 0s - 1ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 15/19\n",
      "97/97 - 0s - 1ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 16/19\n",
      "97/97 - 0s - 2ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 17/19\n",
      "97/97 - 0s - 1ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 18/19\n",
      "97/97 - 0s - 1ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 19/19\n",
      "97/97 - 0s - 1ms/step - accuracy: 0.6440 - loss: nan\n",
      "25/25 - 0s - 2ms/step\n",
      "Epoch 1/19\n",
      "97/97 - 0s - 4ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 2/19\n",
      "97/97 - 0s - 1ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 3/19\n",
      "97/97 - 0s - 1ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 4/19\n",
      "97/97 - 0s - 1ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 5/19\n",
      "97/97 - 0s - 1ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 6/19\n",
      "97/97 - 0s - 1ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 7/19\n",
      "97/97 - 0s - 1ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 8/19\n",
      "97/97 - 0s - 1ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 9/19\n",
      "97/97 - 0s - 1ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 10/19\n",
      "97/97 - 0s - 1ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 11/19\n",
      "97/97 - 0s - 1ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 12/19\n",
      "97/97 - 0s - 1ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 13/19\n",
      "97/97 - 0s - 1ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 14/19\n",
      "97/97 - 0s - 1ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 15/19\n",
      "97/97 - 0s - 1ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 16/19\n",
      "97/97 - 0s - 2ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 17/19\n",
      "97/97 - 0s - 1ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 18/19\n",
      "97/97 - 0s - 1ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 19/19\n",
      "97/97 - 0s - 1ms/step - accuracy: 0.6439 - loss: nan\n",
      "25/25 - 0s - 2ms/step\n",
      "| \u001b[39m2        \u001b[39m | \u001b[39m0.644    \u001b[39m | \u001b[39m7.492    \u001b[39m | \u001b[39m142.5    \u001b[39m | \u001b[39m0.1818   \u001b[39m | \u001b[39m0.3367   \u001b[39m | \u001b[39m19.13    \u001b[39m | \u001b[39m2.05     \u001b[39m | \u001b[39m1.432    \u001b[39m | \u001b[39m1.291    \u001b[39m | \u001b[39m0.6122   \u001b[39m | \u001b[39m22.55    \u001b[39m | \u001b[39m0.2921   \u001b[39m | \u001b[39m2.565    \u001b[39m |\n",
      "Epoch 1/28\n",
      "54/54 - 1s - 28ms/step - accuracy: 0.6608 - loss: 1.0559\n",
      "Epoch 2/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.7572 - loss: 0.7254\n",
      "Epoch 3/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.7913 - loss: 0.6142\n",
      "Epoch 4/28\n",
      "54/54 - 1s - 17ms/step - accuracy: 0.8176 - loss: 0.5281\n",
      "Epoch 5/28\n",
      "54/54 - 1s - 18ms/step - accuracy: 0.8422 - loss: 0.4590\n",
      "Epoch 6/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.8564 - loss: 0.4080\n",
      "Epoch 7/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.8674 - loss: 0.3762\n",
      "Epoch 8/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.8776 - loss: 0.3491\n",
      "Epoch 9/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.8863 - loss: 0.3254\n",
      "Epoch 10/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.8931 - loss: 0.3081\n",
      "Epoch 11/28\n",
      "54/54 - 1s - 17ms/step - accuracy: 0.9010 - loss: 0.2916\n",
      "Epoch 12/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.9049 - loss: 0.2758\n",
      "Epoch 13/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.9041 - loss: 0.2756\n",
      "Epoch 14/28\n",
      "54/54 - 1s - 17ms/step - accuracy: 0.9125 - loss: 0.2603\n",
      "Epoch 15/28\n",
      "54/54 - 1s - 17ms/step - accuracy: 0.9195 - loss: 0.2390\n",
      "Epoch 16/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.9190 - loss: 0.2373\n",
      "Epoch 17/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.9203 - loss: 0.2361\n",
      "Epoch 18/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.9240 - loss: 0.2213\n",
      "Epoch 19/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.9250 - loss: 0.2140\n",
      "Epoch 20/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.9277 - loss: 0.2105\n",
      "Epoch 21/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.9274 - loss: 0.2113\n",
      "Epoch 22/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.9354 - loss: 0.1911\n",
      "Epoch 23/28\n",
      "54/54 - 1s - 17ms/step - accuracy: 0.9344 - loss: 0.1926\n",
      "Epoch 24/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.9330 - loss: 0.1868\n",
      "Epoch 25/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.9371 - loss: 0.1845\n",
      "Epoch 26/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.9428 - loss: 0.1682\n",
      "Epoch 27/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.9416 - loss: 0.1713\n",
      "Epoch 28/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.9394 - loss: 0.1745\n",
      "14/14 - 0s - 10ms/step\n",
      "Epoch 1/28\n",
      "54/54 - 1s - 27ms/step - accuracy: 0.6647 - loss: 1.0644\n",
      "Epoch 2/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.7599 - loss: 0.7244\n",
      "Epoch 3/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.7911 - loss: 0.6083\n",
      "Epoch 4/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.8175 - loss: 0.5265\n",
      "Epoch 5/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.8378 - loss: 0.4685\n",
      "Epoch 6/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.8569 - loss: 0.4193\n",
      "Epoch 7/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.8672 - loss: 0.3843\n",
      "Epoch 8/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.8733 - loss: 0.3631\n",
      "Epoch 9/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.8860 - loss: 0.3298\n",
      "Epoch 10/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.8920 - loss: 0.3126\n",
      "Epoch 11/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.8965 - loss: 0.2973\n",
      "Epoch 12/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.8952 - loss: 0.2976\n",
      "Epoch 13/28\n",
      "54/54 - 1s - 17ms/step - accuracy: 0.9026 - loss: 0.2741\n",
      "Epoch 14/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.9100 - loss: 0.2596\n",
      "Epoch 15/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.9128 - loss: 0.2503\n",
      "Epoch 16/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.9136 - loss: 0.2509\n",
      "Epoch 17/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.9211 - loss: 0.2338\n",
      "Epoch 18/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.9259 - loss: 0.2183\n",
      "Epoch 19/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.9203 - loss: 0.2270\n",
      "Epoch 20/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.9248 - loss: 0.2122\n",
      "Epoch 21/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.9311 - loss: 0.2027\n",
      "Epoch 22/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.9338 - loss: 0.1951\n",
      "Epoch 23/28\n",
      "54/54 - 1s - 17ms/step - accuracy: 0.9351 - loss: 0.1870\n",
      "Epoch 24/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.9382 - loss: 0.1816\n",
      "Epoch 25/28\n",
      "54/54 - 1s - 17ms/step - accuracy: 0.9384 - loss: 0.1773\n",
      "Epoch 26/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.9349 - loss: 0.1876\n",
      "Epoch 27/28\n",
      "54/54 - 1s - 17ms/step - accuracy: 0.9410 - loss: 0.1738\n",
      "Epoch 28/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.9452 - loss: 0.1587\n",
      "14/14 - 0s - 10ms/step\n",
      "Epoch 1/28\n",
      "54/54 - 2s - 31ms/step - accuracy: 0.6675 - loss: 1.0349\n",
      "Epoch 2/28\n",
      "54/54 - 1s - 17ms/step - accuracy: 0.7574 - loss: 0.7194\n",
      "Epoch 3/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.7890 - loss: 0.6184\n",
      "Epoch 4/28\n",
      "54/54 - 1s - 17ms/step - accuracy: 0.8077 - loss: 0.5448\n",
      "Epoch 5/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.8275 - loss: 0.4890\n",
      "Epoch 6/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.8438 - loss: 0.4436\n",
      "Epoch 7/28\n",
      "54/54 - 1s - 17ms/step - accuracy: 0.8584 - loss: 0.4014\n",
      "Epoch 8/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.8719 - loss: 0.3724\n",
      "Epoch 9/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.8852 - loss: 0.3441\n",
      "Epoch 10/28\n",
      "54/54 - 1s - 17ms/step - accuracy: 0.8874 - loss: 0.3247\n",
      "Epoch 11/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.8946 - loss: 0.3080\n",
      "Epoch 12/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.9001 - loss: 0.2871\n",
      "Epoch 13/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.9084 - loss: 0.2727\n",
      "Epoch 14/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.9133 - loss: 0.2561\n",
      "Epoch 15/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.9141 - loss: 0.2503\n",
      "Epoch 16/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.9137 - loss: 0.2453\n",
      "Epoch 17/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.9230 - loss: 0.2318\n",
      "Epoch 18/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.9269 - loss: 0.2171\n",
      "Epoch 19/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.9271 - loss: 0.2150\n",
      "Epoch 20/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.9307 - loss: 0.2076\n",
      "Epoch 21/28\n",
      "54/54 - 1s - 17ms/step - accuracy: 0.9313 - loss: 0.2013\n",
      "Epoch 22/28\n",
      "54/54 - 1s - 17ms/step - accuracy: 0.9307 - loss: 0.1964\n",
      "Epoch 23/28\n",
      "54/54 - 1s - 17ms/step - accuracy: 0.9376 - loss: 0.1832\n",
      "Epoch 24/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.9404 - loss: 0.1752\n",
      "Epoch 25/28\n",
      "54/54 - 1s - 17ms/step - accuracy: 0.9409 - loss: 0.1736\n",
      "Epoch 26/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.9421 - loss: 0.1690\n",
      "Epoch 27/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.9484 - loss: 0.1545\n",
      "Epoch 28/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.9471 - loss: 0.1549\n",
      "14/14 - 0s - 10ms/step\n",
      "Epoch 1/28\n",
      "54/54 - 1s - 27ms/step - accuracy: 0.6684 - loss: 1.0387\n",
      "Epoch 2/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.7653 - loss: 0.7013\n",
      "Epoch 3/28\n",
      "54/54 - 1s - 18ms/step - accuracy: 0.7962 - loss: 0.5843\n",
      "Epoch 4/28\n",
      "54/54 - 1s - 17ms/step - accuracy: 0.8224 - loss: 0.5034\n",
      "Epoch 5/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.8435 - loss: 0.4475\n",
      "Epoch 6/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.8614 - loss: 0.3974\n",
      "Epoch 7/28\n",
      "54/54 - 1s - 17ms/step - accuracy: 0.8793 - loss: 0.3590\n",
      "Epoch 8/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.8855 - loss: 0.3327\n",
      "Epoch 9/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.8957 - loss: 0.3068\n",
      "Epoch 10/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.8959 - loss: 0.2941\n",
      "Epoch 11/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.9093 - loss: 0.2674\n",
      "Epoch 12/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.9113 - loss: 0.2572\n",
      "Epoch 13/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.9178 - loss: 0.2449\n",
      "Epoch 14/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.9174 - loss: 0.2401\n",
      "Epoch 15/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.9253 - loss: 0.2210\n",
      "Epoch 16/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.9274 - loss: 0.2129\n",
      "Epoch 17/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.9296 - loss: 0.2067\n",
      "Epoch 18/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.9369 - loss: 0.1922\n",
      "Epoch 19/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.9343 - loss: 0.1905\n",
      "Epoch 20/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.9394 - loss: 0.1790\n",
      "Epoch 21/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.9375 - loss: 0.1827\n",
      "Epoch 22/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.9407 - loss: 0.1733\n",
      "Epoch 23/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.9368 - loss: 0.1817\n",
      "Epoch 24/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.9473 - loss: 0.1557\n",
      "Epoch 25/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.9469 - loss: 0.1539\n",
      "Epoch 26/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.9481 - loss: 0.1519\n",
      "Epoch 27/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.9489 - loss: 0.1469\n",
      "Epoch 28/28\n",
      "54/54 - 1s - 17ms/step - accuracy: 0.9530 - loss: 0.1389\n",
      "14/14 - 0s - 10ms/step\n",
      "Epoch 1/28\n",
      "54/54 - 1s - 27ms/step - accuracy: 0.6296 - loss: 1.1433\n",
      "Epoch 2/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.7554 - loss: 0.7327\n",
      "Epoch 3/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.7863 - loss: 0.6225\n",
      "Epoch 4/28\n",
      "54/54 - 1s - 17ms/step - accuracy: 0.8124 - loss: 0.5414\n",
      "Epoch 5/28\n",
      "54/54 - 1s - 17ms/step - accuracy: 0.8360 - loss: 0.4751\n",
      "Epoch 6/28\n",
      "54/54 - 1s - 17ms/step - accuracy: 0.8547 - loss: 0.4198\n",
      "Epoch 7/28\n",
      "54/54 - 1s - 17ms/step - accuracy: 0.8664 - loss: 0.3821\n",
      "Epoch 8/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.8768 - loss: 0.3526\n",
      "Epoch 9/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.8849 - loss: 0.3303\n",
      "Epoch 10/28\n",
      "54/54 - 1s - 17ms/step - accuracy: 0.8882 - loss: 0.3114\n",
      "Epoch 11/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.8994 - loss: 0.2868\n",
      "Epoch 12/28\n",
      "54/54 - 1s - 17ms/step - accuracy: 0.9044 - loss: 0.2767\n",
      "Epoch 13/28\n",
      "54/54 - 1s - 17ms/step - accuracy: 0.9078 - loss: 0.2655\n",
      "Epoch 14/28\n",
      "54/54 - 1s - 17ms/step - accuracy: 0.9155 - loss: 0.2454\n",
      "Epoch 15/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.9210 - loss: 0.2310\n",
      "Epoch 16/28\n",
      "54/54 - 1s - 17ms/step - accuracy: 0.9189 - loss: 0.2300\n",
      "Epoch 17/28\n",
      "54/54 - 1s - 17ms/step - accuracy: 0.9272 - loss: 0.2128\n",
      "Epoch 18/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.9284 - loss: 0.2048\n",
      "Epoch 19/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.9261 - loss: 0.2114\n",
      "Epoch 20/28\n",
      "54/54 - 1s - 17ms/step - accuracy: 0.9304 - loss: 0.2011\n",
      "Epoch 21/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.9351 - loss: 0.1861\n",
      "Epoch 22/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.9361 - loss: 0.1838\n",
      "Epoch 23/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.9418 - loss: 0.1675\n",
      "Epoch 24/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.9396 - loss: 0.1717\n",
      "Epoch 25/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.9469 - loss: 0.1578\n",
      "Epoch 26/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.9500 - loss: 0.1479\n",
      "Epoch 27/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.9492 - loss: 0.1518\n",
      "Epoch 28/28\n",
      "54/54 - 1s - 16ms/step - accuracy: 0.9474 - loss: 0.1575\n",
      "14/14 - 0s - 10ms/step\n",
      "| \u001b[35m3        \u001b[39m | \u001b[35m0.8633   \u001b[39m | \u001b[35m4.105    \u001b[39m | \u001b[35m257.0    \u001b[39m | \u001b[35m0.1997   \u001b[39m | \u001b[35m0.4028   \u001b[39m | \u001b[35m27.77    \u001b[39m | \u001b[35m1.093    \u001b[39m | \u001b[35m1.608    \u001b[39m | \u001b[35m1.171    \u001b[39m | \u001b[35m0.06599  \u001b[39m | \u001b[35m95.4     \u001b[39m | \u001b[35m0.9656   \u001b[39m | \u001b[35m5.659    \u001b[39m |\n",
      "Epoch 1/14\n",
      "115/115 - 1s - 7ms/step - accuracy: 0.4727 - loss: 2.1257\n",
      "Epoch 2/14\n",
      "115/115 - 1s - 5ms/step - accuracy: 0.6427 - loss: 1.4656\n",
      "Epoch 3/14\n",
      "115/115 - 1s - 5ms/step - accuracy: 0.6439 - loss: 1.2840\n",
      "Epoch 4/14\n",
      "115/115 - 1s - 5ms/step - accuracy: 0.6440 - loss: 1.2155\n",
      "Epoch 5/14\n",
      "115/115 - 1s - 5ms/step - accuracy: 0.6438 - loss: 1.1762\n",
      "Epoch 6/14\n",
      "115/115 - 1s - 5ms/step - accuracy: 0.6439 - loss: 1.1487\n",
      "Epoch 7/14\n",
      "115/115 - 1s - 5ms/step - accuracy: 0.6430 - loss: 1.1293\n",
      "Epoch 8/14\n",
      "115/115 - 1s - 5ms/step - accuracy: 0.6438 - loss: 1.1146\n",
      "Epoch 9/14\n",
      "115/115 - 1s - 5ms/step - accuracy: 0.6441 - loss: 1.1033\n",
      "Epoch 10/14\n",
      "115/115 - 1s - 5ms/step - accuracy: 0.6433 - loss: 1.0933\n",
      "Epoch 11/14\n",
      "115/115 - 1s - 6ms/step - accuracy: 0.6449 - loss: 1.0841\n",
      "Epoch 12/14\n",
      "115/115 - 1s - 5ms/step - accuracy: 0.6470 - loss: 1.0756\n",
      "Epoch 13/14\n",
      "115/115 - 1s - 5ms/step - accuracy: 0.6498 - loss: 1.0685\n",
      "Epoch 14/14\n",
      "115/115 - 1s - 5ms/step - accuracy: 0.6461 - loss: 1.0641\n",
      "29/29 - 0s - 3ms/step\n",
      "Epoch 1/14\n",
      "115/115 - 1s - 7ms/step - accuracy: 0.6227 - loss: 1.8404\n",
      "Epoch 2/14\n",
      "115/115 - 1s - 5ms/step - accuracy: 0.6436 - loss: 1.3542\n",
      "Epoch 3/14\n",
      "115/115 - 1s - 5ms/step - accuracy: 0.6438 - loss: 1.2285\n",
      "Epoch 4/14\n",
      "115/115 - 1s - 5ms/step - accuracy: 0.6437 - loss: 1.1743\n",
      "Epoch 5/14\n",
      "115/115 - 1s - 5ms/step - accuracy: 0.6440 - loss: 1.1403\n",
      "Epoch 6/14\n",
      "115/115 - 1s - 5ms/step - accuracy: 0.6445 - loss: 1.1196\n",
      "Epoch 7/14\n",
      "115/115 - 1s - 5ms/step - accuracy: 0.6429 - loss: 1.1056\n",
      "Epoch 8/14\n",
      "115/115 - 1s - 5ms/step - accuracy: 0.6430 - loss: 1.0956\n",
      "Epoch 9/14\n",
      "115/115 - 1s - 5ms/step - accuracy: 0.6440 - loss: 1.0855\n",
      "Epoch 10/14\n",
      "115/115 - 1s - 5ms/step - accuracy: 0.6427 - loss: 1.0790\n",
      "Epoch 11/14\n",
      "115/115 - 1s - 5ms/step - accuracy: 0.6462 - loss: 1.0702\n",
      "Epoch 12/14\n",
      "115/115 - 1s - 5ms/step - accuracy: 0.6457 - loss: 1.0666\n",
      "Epoch 13/14\n",
      "115/115 - 1s - 5ms/step - accuracy: 0.6423 - loss: 1.0620\n",
      "Epoch 14/14\n",
      "115/115 - 1s - 5ms/step - accuracy: 0.6457 - loss: 1.0574\n",
      "29/29 - 0s - 3ms/step\n",
      "Epoch 1/14\n",
      "115/115 - 1s - 7ms/step - accuracy: 0.5488 - loss: 1.9688\n",
      "Epoch 2/14\n",
      "115/115 - 1s - 5ms/step - accuracy: 0.6349 - loss: 1.4084\n",
      "Epoch 3/14\n",
      "115/115 - 1s - 5ms/step - accuracy: 0.6407 - loss: 1.2615\n",
      "Epoch 4/14\n",
      "115/115 - 1s - 5ms/step - accuracy: 0.6433 - loss: 1.1992\n",
      "Epoch 5/14\n",
      "115/115 - 1s - 4ms/step - accuracy: 0.6438 - loss: 1.1617\n",
      "Epoch 6/14\n",
      "115/115 - 1s - 4ms/step - accuracy: 0.6432 - loss: 1.1367\n",
      "Epoch 7/14\n",
      "115/115 - 1s - 5ms/step - accuracy: 0.6441 - loss: 1.1200\n",
      "Epoch 8/14\n",
      "115/115 - 1s - 5ms/step - accuracy: 0.6442 - loss: 1.1065\n",
      "Epoch 9/14\n",
      "115/115 - 1s - 5ms/step - accuracy: 0.6444 - loss: 1.0969\n",
      "Epoch 10/14\n",
      "115/115 - 1s - 5ms/step - accuracy: 0.6445 - loss: 1.0891\n",
      "Epoch 11/14\n",
      "115/115 - 1s - 5ms/step - accuracy: 0.6456 - loss: 1.0818\n",
      "Epoch 12/14\n",
      "115/115 - 1s - 4ms/step - accuracy: 0.6457 - loss: 1.0742\n",
      "Epoch 13/14\n",
      "115/115 - 1s - 5ms/step - accuracy: 0.6439 - loss: 1.0699\n",
      "Epoch 14/14\n",
      "115/115 - 1s - 5ms/step - accuracy: 0.6466 - loss: 1.0643\n",
      "29/29 - 0s - 3ms/step\n",
      "Epoch 1/14\n",
      "115/115 - 1s - 7ms/step - accuracy: 0.5004 - loss: 2.0901\n",
      "Epoch 2/14\n",
      "115/115 - 1s - 5ms/step - accuracy: 0.6396 - loss: 1.4583\n",
      "Epoch 3/14\n",
      "115/115 - 1s - 5ms/step - accuracy: 0.6433 - loss: 1.2849\n",
      "Epoch 4/14\n",
      "115/115 - 1s - 5ms/step - accuracy: 0.6440 - loss: 1.2116\n",
      "Epoch 5/14\n",
      "115/115 - 1s - 5ms/step - accuracy: 0.6437 - loss: 1.1704\n",
      "Epoch 6/14\n",
      "115/115 - 1s - 5ms/step - accuracy: 0.6438 - loss: 1.1450\n",
      "Epoch 7/14\n",
      "115/115 - 1s - 5ms/step - accuracy: 0.6437 - loss: 1.1249\n",
      "Epoch 8/14\n",
      "115/115 - 1s - 5ms/step - accuracy: 0.6439 - loss: 1.1108\n",
      "Epoch 9/14\n",
      "115/115 - 1s - 5ms/step - accuracy: 0.6438 - loss: 1.1012\n",
      "Epoch 10/14\n",
      "115/115 - 1s - 5ms/step - accuracy: 0.6451 - loss: 1.0926\n",
      "Epoch 11/14\n",
      "115/115 - 1s - 5ms/step - accuracy: 0.6447 - loss: 1.0836\n",
      "Epoch 12/14\n",
      "115/115 - 1s - 5ms/step - accuracy: 0.6444 - loss: 1.0793\n",
      "Epoch 13/14\n",
      "115/115 - 1s - 5ms/step - accuracy: 0.6437 - loss: 1.0747\n",
      "Epoch 14/14\n",
      "115/115 - 1s - 4ms/step - accuracy: 0.6454 - loss: 1.0680\n",
      "29/29 - 0s - 3ms/step\n",
      "Epoch 1/14\n",
      "115/115 - 1s - 9ms/step - accuracy: 0.4898 - loss: 2.0620\n",
      "Epoch 2/14\n",
      "115/115 - 1s - 4ms/step - accuracy: 0.6371 - loss: 1.4220\n",
      "Epoch 3/14\n",
      "115/115 - 1s - 4ms/step - accuracy: 0.6415 - loss: 1.2670\n",
      "Epoch 4/14\n",
      "115/115 - 1s - 4ms/step - accuracy: 0.6430 - loss: 1.1961\n",
      "Epoch 5/14\n",
      "115/115 - 1s - 4ms/step - accuracy: 0.6440 - loss: 1.1576\n",
      "Epoch 6/14\n",
      "115/115 - 1s - 5ms/step - accuracy: 0.6437 - loss: 1.1333\n",
      "Epoch 7/14\n",
      "115/115 - 1s - 5ms/step - accuracy: 0.6434 - loss: 1.1150\n",
      "Epoch 8/14\n",
      "115/115 - 1s - 5ms/step - accuracy: 0.6444 - loss: 1.1016\n",
      "Epoch 9/14\n",
      "115/115 - 1s - 5ms/step - accuracy: 0.6436 - loss: 1.0896\n",
      "Epoch 10/14\n",
      "115/115 - 1s - 5ms/step - accuracy: 0.6455 - loss: 1.0813\n",
      "Epoch 11/14\n",
      "115/115 - 1s - 5ms/step - accuracy: 0.6451 - loss: 1.0762\n",
      "Epoch 12/14\n",
      "115/115 - 1s - 5ms/step - accuracy: 0.6466 - loss: 1.0689\n",
      "Epoch 13/14\n",
      "115/115 - 1s - 5ms/step - accuracy: 0.6448 - loss: 1.0658\n",
      "Epoch 14/14\n",
      "115/115 - 1s - 4ms/step - accuracy: 0.6457 - loss: 1.0618\n",
      "29/29 - 0s - 4ms/step\n",
      "| \u001b[39m4        \u001b[39m | \u001b[39m0.6486   \u001b[39m | \u001b[39m2.742    \u001b[39m | \u001b[39m119.5    \u001b[39m | \u001b[39m0.6842   \u001b[39m | \u001b[39m0.388    \u001b[39m | \u001b[39m13.66    \u001b[39m | \u001b[39m1.99     \u001b[39m | \u001b[39m1.034    \u001b[39m | \u001b[39m1.909    \u001b[39m | \u001b[39m0.2595   \u001b[39m | \u001b[39m69.63    \u001b[39m | \u001b[39m0.3117   \u001b[39m | \u001b[39m3.64     \u001b[39m |\n",
      "Epoch 1/38\n",
      "101/101 - 1s - 5ms/step - accuracy: 0.6104 - loss: 1.3004\n",
      "Epoch 2/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.6765 - loss: 0.9373\n",
      "Epoch 3/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.7100 - loss: 0.8396\n",
      "Epoch 4/38\n",
      "101/101 - 0s - 3ms/step - accuracy: 0.7298 - loss: 0.7715\n",
      "Epoch 5/38\n",
      "101/101 - 0s - 3ms/step - accuracy: 0.7412 - loss: 0.7356\n",
      "Epoch 6/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.7497 - loss: 0.7062\n",
      "Epoch 7/38\n",
      "101/101 - 0s - 3ms/step - accuracy: 0.7591 - loss: 0.6769\n",
      "Epoch 8/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.7633 - loss: 0.6562\n",
      "Epoch 9/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.7674 - loss: 0.6457\n",
      "Epoch 10/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.7732 - loss: 0.6319\n",
      "Epoch 11/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.7778 - loss: 0.6185\n",
      "Epoch 12/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.7838 - loss: 0.6095\n",
      "Epoch 13/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.7908 - loss: 0.5865\n",
      "Epoch 14/38\n",
      "101/101 - 0s - 3ms/step - accuracy: 0.7892 - loss: 0.5845\n",
      "Epoch 15/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.7942 - loss: 0.5706\n",
      "Epoch 16/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.7978 - loss: 0.5566\n",
      "Epoch 17/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.7991 - loss: 0.5506\n",
      "Epoch 18/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8014 - loss: 0.5511\n",
      "Epoch 19/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8075 - loss: 0.5307\n",
      "Epoch 20/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8141 - loss: 0.5212\n",
      "Epoch 21/38\n",
      "101/101 - 0s - 3ms/step - accuracy: 0.8131 - loss: 0.5193\n",
      "Epoch 22/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8134 - loss: 0.5135\n",
      "Epoch 23/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8187 - loss: 0.4992\n",
      "Epoch 24/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8190 - loss: 0.5020\n",
      "Epoch 25/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8250 - loss: 0.4915\n",
      "Epoch 26/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8203 - loss: 0.4844\n",
      "Epoch 27/38\n",
      "101/101 - 0s - 3ms/step - accuracy: 0.8295 - loss: 0.4739\n",
      "Epoch 28/38\n",
      "101/101 - 0s - 3ms/step - accuracy: 0.8308 - loss: 0.4682\n",
      "Epoch 29/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8324 - loss: 0.4624\n",
      "Epoch 30/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8340 - loss: 0.4611\n",
      "Epoch 31/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8420 - loss: 0.4468\n",
      "Epoch 32/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8416 - loss: 0.4475\n",
      "Epoch 33/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8394 - loss: 0.4432\n",
      "Epoch 34/38\n",
      "101/101 - 0s - 3ms/step - accuracy: 0.8441 - loss: 0.4325\n",
      "Epoch 35/38\n",
      "101/101 - 0s - 4ms/step - accuracy: 0.8411 - loss: 0.4352\n",
      "Epoch 36/38\n",
      "101/101 - 0s - 3ms/step - accuracy: 0.8469 - loss: 0.4236\n",
      "Epoch 37/38\n",
      "101/101 - 0s - 3ms/step - accuracy: 0.8463 - loss: 0.4223\n",
      "Epoch 38/38\n",
      "101/101 - 0s - 3ms/step - accuracy: 0.8508 - loss: 0.4155\n",
      "26/26 - 0s - 3ms/step\n",
      "Epoch 1/38\n",
      "101/101 - 1s - 6ms/step - accuracy: 0.6069 - loss: 1.3412\n",
      "Epoch 2/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.6874 - loss: 0.9460\n",
      "Epoch 3/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.7213 - loss: 0.8248\n",
      "Epoch 4/38\n",
      "101/101 - 0s - 3ms/step - accuracy: 0.7417 - loss: 0.7464\n",
      "Epoch 5/38\n",
      "101/101 - 0s - 3ms/step - accuracy: 0.7544 - loss: 0.7122\n",
      "Epoch 6/38\n",
      "101/101 - 0s - 3ms/step - accuracy: 0.7621 - loss: 0.6731\n",
      "Epoch 7/38\n",
      "101/101 - 0s - 3ms/step - accuracy: 0.7698 - loss: 0.6477\n",
      "Epoch 8/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.7767 - loss: 0.6313\n",
      "Epoch 9/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.7822 - loss: 0.6119\n",
      "Epoch 10/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.7853 - loss: 0.5997\n",
      "Epoch 11/38\n",
      "101/101 - 0s - 3ms/step - accuracy: 0.7919 - loss: 0.5815\n",
      "Epoch 12/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.7934 - loss: 0.5738\n",
      "Epoch 13/38\n",
      "101/101 - 0s - 3ms/step - accuracy: 0.7967 - loss: 0.5584\n",
      "Epoch 14/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8012 - loss: 0.5534\n",
      "Epoch 15/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8072 - loss: 0.5369\n",
      "Epoch 16/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8088 - loss: 0.5325\n",
      "Epoch 17/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8134 - loss: 0.5148\n",
      "Epoch 18/38\n",
      "101/101 - 0s - 3ms/step - accuracy: 0.8145 - loss: 0.5132\n",
      "Epoch 19/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8180 - loss: 0.5035\n",
      "Epoch 20/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8185 - loss: 0.4937\n",
      "Epoch 21/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8242 - loss: 0.4839\n",
      "Epoch 22/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8288 - loss: 0.4719\n",
      "Epoch 23/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8303 - loss: 0.4683\n",
      "Epoch 24/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8331 - loss: 0.4629\n",
      "Epoch 25/38\n",
      "101/101 - 0s - 3ms/step - accuracy: 0.8314 - loss: 0.4569\n",
      "Epoch 26/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8351 - loss: 0.4521\n",
      "Epoch 27/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8371 - loss: 0.4474\n",
      "Epoch 28/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8415 - loss: 0.4365\n",
      "Epoch 29/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8418 - loss: 0.4361\n",
      "Epoch 30/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8484 - loss: 0.4215\n",
      "Epoch 31/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8484 - loss: 0.4159\n",
      "Epoch 32/38\n",
      "101/101 - 0s - 3ms/step - accuracy: 0.8506 - loss: 0.4167\n",
      "Epoch 33/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8532 - loss: 0.4098\n",
      "Epoch 34/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8540 - loss: 0.4064\n",
      "Epoch 35/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8563 - loss: 0.3994\n",
      "Epoch 36/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8572 - loss: 0.3922\n",
      "Epoch 37/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8591 - loss: 0.3902\n",
      "Epoch 38/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8624 - loss: 0.3888\n",
      "26/26 - 0s - 4ms/step\n",
      "Epoch 1/38\n",
      "101/101 - 1s - 5ms/step - accuracy: 0.5901 - loss: 1.3763\n",
      "Epoch 2/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.6762 - loss: 0.9408\n",
      "Epoch 3/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.7115 - loss: 0.8483\n",
      "Epoch 4/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.7320 - loss: 0.7823\n",
      "Epoch 5/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.7447 - loss: 0.7387\n",
      "Epoch 6/38\n",
      "101/101 - 0s - 3ms/step - accuracy: 0.7554 - loss: 0.7078\n",
      "Epoch 7/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.7628 - loss: 0.6869\n",
      "Epoch 8/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.7696 - loss: 0.6635\n",
      "Epoch 9/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.7721 - loss: 0.6454\n",
      "Epoch 10/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.7789 - loss: 0.6277\n",
      "Epoch 11/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.7867 - loss: 0.6079\n",
      "Epoch 12/38\n",
      "101/101 - 0s - 3ms/step - accuracy: 0.7890 - loss: 0.6019\n",
      "Epoch 13/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.7911 - loss: 0.5896\n",
      "Epoch 14/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.7936 - loss: 0.5762\n",
      "Epoch 15/38\n",
      "101/101 - 0s - 3ms/step - accuracy: 0.8000 - loss: 0.5621\n",
      "Epoch 16/38\n",
      "101/101 - 0s - 3ms/step - accuracy: 0.7992 - loss: 0.5658\n",
      "Epoch 17/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8051 - loss: 0.5532\n",
      "Epoch 18/38\n",
      "101/101 - 0s - 3ms/step - accuracy: 0.8078 - loss: 0.5448\n",
      "Epoch 19/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8099 - loss: 0.5338\n",
      "Epoch 20/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8110 - loss: 0.5287\n",
      "Epoch 21/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8129 - loss: 0.5235\n",
      "Epoch 22/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8176 - loss: 0.5119\n",
      "Epoch 23/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8174 - loss: 0.5097\n",
      "Epoch 24/38\n",
      "101/101 - 0s - 3ms/step - accuracy: 0.8216 - loss: 0.5005\n",
      "Epoch 25/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8211 - loss: 0.4925\n",
      "Epoch 26/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8272 - loss: 0.4886\n",
      "Epoch 27/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8251 - loss: 0.4813\n",
      "Epoch 28/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8253 - loss: 0.4765\n",
      "Epoch 29/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8323 - loss: 0.4737\n",
      "Epoch 30/38\n",
      "101/101 - 0s - 3ms/step - accuracy: 0.8373 - loss: 0.4595\n",
      "Epoch 31/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8349 - loss: 0.4619\n",
      "Epoch 32/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8373 - loss: 0.4524\n",
      "Epoch 33/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8383 - loss: 0.4456\n",
      "Epoch 34/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8373 - loss: 0.4430\n",
      "Epoch 35/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8411 - loss: 0.4381\n",
      "Epoch 36/38\n",
      "101/101 - 0s - 3ms/step - accuracy: 0.8447 - loss: 0.4315\n",
      "Epoch 37/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8438 - loss: 0.4323\n",
      "Epoch 38/38\n",
      "101/101 - 0s - 3ms/step - accuracy: 0.8468 - loss: 0.4235\n",
      "26/26 - 0s - 3ms/step\n",
      "Epoch 1/38\n",
      "101/101 - 1s - 6ms/step - accuracy: 0.5633 - loss: 1.9081\n",
      "Epoch 2/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.6821 - loss: 0.9377\n",
      "Epoch 3/38\n",
      "101/101 - 0s - 3ms/step - accuracy: 0.7146 - loss: 0.8169\n",
      "Epoch 4/38\n",
      "101/101 - 0s - 3ms/step - accuracy: 0.7389 - loss: 0.7516\n",
      "Epoch 5/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.7443 - loss: 0.7192\n",
      "Epoch 6/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.7524 - loss: 0.6924\n",
      "Epoch 7/38\n",
      "101/101 - 0s - 3ms/step - accuracy: 0.7651 - loss: 0.6668\n",
      "Epoch 8/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.7712 - loss: 0.6405\n",
      "Epoch 9/38\n",
      "101/101 - 0s - 3ms/step - accuracy: 0.7736 - loss: 0.6283\n",
      "Epoch 10/38\n",
      "101/101 - 0s - 3ms/step - accuracy: 0.7757 - loss: 0.6155\n",
      "Epoch 11/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.7847 - loss: 0.6008\n",
      "Epoch 12/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.7875 - loss: 0.5942\n",
      "Epoch 13/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.7908 - loss: 0.5835\n",
      "Epoch 14/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.7930 - loss: 0.5727\n",
      "Epoch 15/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.7968 - loss: 0.5607\n",
      "Epoch 16/38\n",
      "101/101 - 0s - 3ms/step - accuracy: 0.7993 - loss: 0.5501\n",
      "Epoch 17/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8046 - loss: 0.5459\n",
      "Epoch 18/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8028 - loss: 0.5354\n",
      "Epoch 19/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8073 - loss: 0.5243\n",
      "Epoch 20/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8129 - loss: 0.5178\n",
      "Epoch 21/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8208 - loss: 0.5019\n",
      "Epoch 22/38\n",
      "101/101 - 0s - 3ms/step - accuracy: 0.8209 - loss: 0.4983\n",
      "Epoch 23/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8232 - loss: 0.4952\n",
      "Epoch 24/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8271 - loss: 0.4836\n",
      "Epoch 25/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8273 - loss: 0.4732\n",
      "Epoch 26/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8322 - loss: 0.4672\n",
      "Epoch 27/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8317 - loss: 0.4650\n",
      "Epoch 28/38\n",
      "101/101 - 0s - 3ms/step - accuracy: 0.8331 - loss: 0.4557\n",
      "Epoch 29/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8371 - loss: 0.4441\n",
      "Epoch 30/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8431 - loss: 0.4345\n",
      "Epoch 31/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8426 - loss: 0.4319\n",
      "Epoch 32/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8458 - loss: 0.4267\n",
      "Epoch 33/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8440 - loss: 0.4235\n",
      "Epoch 34/38\n",
      "101/101 - 0s - 3ms/step - accuracy: 0.8509 - loss: 0.4181\n",
      "Epoch 35/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8545 - loss: 0.4030\n",
      "Epoch 36/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8531 - loss: 0.4063\n",
      "Epoch 37/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8550 - loss: 0.4010\n",
      "Epoch 38/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8612 - loss: 0.3966\n",
      "26/26 - 0s - 3ms/step\n",
      "Epoch 1/38\n",
      "101/101 - 1s - 6ms/step - accuracy: 0.6040 - loss: 1.3375\n",
      "Epoch 2/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.6970 - loss: 0.9033\n",
      "Epoch 3/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.7283 - loss: 0.8046\n",
      "Epoch 4/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.7439 - loss: 0.7478\n",
      "Epoch 5/38\n",
      "101/101 - 0s - 3ms/step - accuracy: 0.7489 - loss: 0.7089\n",
      "Epoch 6/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.7610 - loss: 0.6832\n",
      "Epoch 7/38\n",
      "101/101 - 0s - 3ms/step - accuracy: 0.7689 - loss: 0.6552\n",
      "Epoch 8/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.7805 - loss: 0.6357\n",
      "Epoch 9/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.7824 - loss: 0.6192\n",
      "Epoch 10/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.7865 - loss: 0.6017\n",
      "Epoch 11/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.7957 - loss: 0.5803\n",
      "Epoch 12/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.7935 - loss: 0.5700\n",
      "Epoch 13/38\n",
      "101/101 - 0s - 3ms/step - accuracy: 0.7983 - loss: 0.5635\n",
      "Epoch 14/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8026 - loss: 0.5471\n",
      "Epoch 15/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8098 - loss: 0.5398\n",
      "Epoch 16/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8110 - loss: 0.5265\n",
      "Epoch 17/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8118 - loss: 0.5223\n",
      "Epoch 18/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8175 - loss: 0.5072\n",
      "Epoch 19/38\n",
      "101/101 - 0s - 3ms/step - accuracy: 0.8203 - loss: 0.4989\n",
      "Epoch 20/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8225 - loss: 0.4964\n",
      "Epoch 21/38\n",
      "101/101 - 0s - 3ms/step - accuracy: 0.8282 - loss: 0.4850\n",
      "Epoch 22/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8263 - loss: 0.4852\n",
      "Epoch 23/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8314 - loss: 0.4684\n",
      "Epoch 24/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8339 - loss: 0.4636\n",
      "Epoch 25/38\n",
      "101/101 - 0s - 3ms/step - accuracy: 0.8379 - loss: 0.4560\n",
      "Epoch 26/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8376 - loss: 0.4546\n",
      "Epoch 27/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8402 - loss: 0.4426\n",
      "Epoch 28/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8413 - loss: 0.4360\n",
      "Epoch 29/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8451 - loss: 0.4272\n",
      "Epoch 30/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8467 - loss: 0.4281\n",
      "Epoch 31/38\n",
      "101/101 - 0s - 3ms/step - accuracy: 0.8472 - loss: 0.4196\n",
      "Epoch 32/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8495 - loss: 0.4209\n",
      "Epoch 33/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8550 - loss: 0.4124\n",
      "Epoch 34/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8570 - loss: 0.4016\n",
      "Epoch 35/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8597 - loss: 0.4022\n",
      "Epoch 36/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8542 - loss: 0.3985\n",
      "Epoch 37/38\n",
      "101/101 - 0s - 3ms/step - accuracy: 0.8588 - loss: 0.3917\n",
      "Epoch 38/38\n",
      "101/101 - 0s - 2ms/step - accuracy: 0.8622 - loss: 0.3903\n",
      "26/26 - 0s - 3ms/step\n",
      "| \u001b[39m5        \u001b[39m | \u001b[39m0.8444   \u001b[39m | \u001b[39m4.92     \u001b[39m | \u001b[39m137.0    \u001b[39m | \u001b[39m0.9696   \u001b[39m | \u001b[39m0.455    \u001b[39m | \u001b[39m38.18    \u001b[39m | \u001b[39m2.79     \u001b[39m | \u001b[39m1.598    \u001b[39m | \u001b[39m1.922    \u001b[39m | \u001b[39m0.0894   \u001b[39m | \u001b[39m27.64    \u001b[39m | \u001b[39m0.04523  \u001b[39m | \u001b[39m2.277    \u001b[39m |\n",
      "Epoch 1/18\n",
      "90/90 - 1s - 16ms/step - accuracy: 0.6738 - loss: 1.0197\n",
      "Epoch 2/18\n",
      "90/90 - 1s - 10ms/step - accuracy: 0.7521 - loss: 0.7287\n",
      "Epoch 3/18\n",
      "90/90 - 1s - 10ms/step - accuracy: 0.7786 - loss: 0.6384\n",
      "Epoch 4/18\n",
      "90/90 - 1s - 11ms/step - accuracy: 0.8034 - loss: 0.5730\n",
      "Epoch 5/18\n",
      "90/90 - 1s - 10ms/step - accuracy: 0.8179 - loss: 0.5213\n",
      "Epoch 6/18\n",
      "90/90 - 1s - 10ms/step - accuracy: 0.8298 - loss: 0.4909\n",
      "Epoch 7/18\n",
      "90/90 - 1s - 10ms/step - accuracy: 0.8359 - loss: 0.4647\n",
      "Epoch 8/18\n",
      "90/90 - 1s - 10ms/step - accuracy: 0.8454 - loss: 0.4364\n",
      "Epoch 9/18\n",
      "90/90 - 1s - 10ms/step - accuracy: 0.8547 - loss: 0.4136\n",
      "Epoch 10/18\n",
      "90/90 - 1s - 11ms/step - accuracy: 0.8599 - loss: 0.3939\n",
      "Epoch 11/18\n",
      "90/90 - 1s - 10ms/step - accuracy: 0.8646 - loss: 0.3776\n",
      "Epoch 12/18\n",
      "90/90 - 1s - 11ms/step - accuracy: 0.8705 - loss: 0.3667\n",
      "Epoch 13/18\n",
      "90/90 - 1s - 10ms/step - accuracy: 0.8760 - loss: 0.3532\n",
      "Epoch 14/18\n",
      "90/90 - 1s - 10ms/step - accuracy: 0.8825 - loss: 0.3333\n",
      "Epoch 15/18\n",
      "90/90 - 1s - 10ms/step - accuracy: 0.8803 - loss: 0.3326\n",
      "Epoch 16/18\n",
      "90/90 - 1s - 11ms/step - accuracy: 0.8903 - loss: 0.3108\n",
      "Epoch 17/18\n",
      "90/90 - 1s - 10ms/step - accuracy: 0.8932 - loss: 0.3058\n",
      "Epoch 18/18\n",
      "90/90 - 1s - 10ms/step - accuracy: 0.8961 - loss: 0.2955\n",
      "23/23 - 0s - 6ms/step\n",
      "Epoch 1/18\n",
      "90/90 - 1s - 16ms/step - accuracy: 0.6756 - loss: 1.0213\n",
      "Epoch 2/18\n",
      "90/90 - 1s - 11ms/step - accuracy: 0.7511 - loss: 0.7271\n",
      "Epoch 3/18\n",
      "90/90 - 1s - 11ms/step - accuracy: 0.7834 - loss: 0.6299\n",
      "Epoch 4/18\n",
      "90/90 - 1s - 11ms/step - accuracy: 0.8035 - loss: 0.5646\n",
      "Epoch 5/18\n",
      "90/90 - 1s - 11ms/step - accuracy: 0.8155 - loss: 0.5147\n",
      "Epoch 6/18\n",
      "90/90 - 1s - 11ms/step - accuracy: 0.8290 - loss: 0.4818\n",
      "Epoch 7/18\n",
      "90/90 - 1s - 11ms/step - accuracy: 0.8383 - loss: 0.4497\n",
      "Epoch 8/18\n",
      "90/90 - 1s - 11ms/step - accuracy: 0.8504 - loss: 0.4308\n",
      "Epoch 9/18\n",
      "90/90 - 1s - 11ms/step - accuracy: 0.8610 - loss: 0.3946\n",
      "Epoch 10/18\n",
      "90/90 - 1s - 11ms/step - accuracy: 0.8619 - loss: 0.3839\n",
      "Epoch 11/18\n",
      "90/90 - 1s - 11ms/step - accuracy: 0.8738 - loss: 0.3625\n",
      "Epoch 12/18\n",
      "90/90 - 1s - 11ms/step - accuracy: 0.8725 - loss: 0.3592\n",
      "Epoch 13/18\n",
      "90/90 - 1s - 11ms/step - accuracy: 0.8780 - loss: 0.3361\n",
      "Epoch 14/18\n",
      "90/90 - 1s - 11ms/step - accuracy: 0.8884 - loss: 0.3159\n",
      "Epoch 15/18\n",
      "90/90 - 1s - 11ms/step - accuracy: 0.8914 - loss: 0.3074\n",
      "Epoch 16/18\n",
      "90/90 - 1s - 11ms/step - accuracy: 0.8943 - loss: 0.3064\n",
      "Epoch 17/18\n",
      "90/90 - 1s - 11ms/step - accuracy: 0.8929 - loss: 0.2979\n",
      "Epoch 18/18\n",
      "90/90 - 1s - 11ms/step - accuracy: 0.9006 - loss: 0.2793\n",
      "23/23 - 0s - 6ms/step\n",
      "Epoch 1/18\n",
      "90/90 - 1s - 16ms/step - accuracy: 0.6748 - loss: 1.0403\n",
      "Epoch 2/18\n",
      "90/90 - 1s - 10ms/step - accuracy: 0.7455 - loss: 0.7424\n",
      "Epoch 3/18\n",
      "90/90 - 1s - 11ms/step - accuracy: 0.7771 - loss: 0.6490\n",
      "Epoch 4/18\n",
      "90/90 - 1s - 10ms/step - accuracy: 0.7985 - loss: 0.5851\n",
      "Epoch 5/18\n",
      "90/90 - 1s - 11ms/step - accuracy: 0.8146 - loss: 0.5290\n",
      "Epoch 6/18\n",
      "90/90 - 1s - 11ms/step - accuracy: 0.8247 - loss: 0.4958\n",
      "Epoch 7/18\n",
      "90/90 - 1s - 11ms/step - accuracy: 0.8362 - loss: 0.4610\n",
      "Epoch 8/18\n",
      "90/90 - 1s - 11ms/step - accuracy: 0.8457 - loss: 0.4303\n",
      "Epoch 9/18\n",
      "90/90 - 1s - 11ms/step - accuracy: 0.8535 - loss: 0.4070\n",
      "Epoch 10/18\n",
      "90/90 - 1s - 11ms/step - accuracy: 0.8581 - loss: 0.3979\n",
      "Epoch 11/18\n",
      "90/90 - 1s - 11ms/step - accuracy: 0.8601 - loss: 0.3855\n",
      "Epoch 12/18\n",
      "90/90 - 1s - 11ms/step - accuracy: 0.8680 - loss: 0.3656\n",
      "Epoch 13/18\n",
      "90/90 - 1s - 11ms/step - accuracy: 0.8783 - loss: 0.3419\n",
      "Epoch 14/18\n",
      "90/90 - 1s - 11ms/step - accuracy: 0.8821 - loss: 0.3308\n",
      "Epoch 15/18\n",
      "90/90 - 1s - 11ms/step - accuracy: 0.8842 - loss: 0.3307\n",
      "Epoch 16/18\n",
      "90/90 - 1s - 10ms/step - accuracy: 0.8853 - loss: 0.3175\n",
      "Epoch 17/18\n",
      "90/90 - 1s - 13ms/step - accuracy: 0.8868 - loss: 0.3151\n",
      "Epoch 18/18\n",
      "90/90 - 1s - 12ms/step - accuracy: 0.8956 - loss: 0.2933\n",
      "23/23 - 0s - 6ms/step\n",
      "Epoch 1/18\n",
      "90/90 - 2s - 22ms/step - accuracy: 0.6684 - loss: 1.0173\n",
      "Epoch 2/18\n",
      "90/90 - 1s - 11ms/step - accuracy: 0.7554 - loss: 0.7154\n",
      "Epoch 3/18\n",
      "90/90 - 1s - 11ms/step - accuracy: 0.7808 - loss: 0.6281\n",
      "Epoch 4/18\n",
      "90/90 - 1s - 12ms/step - accuracy: 0.8012 - loss: 0.5707\n",
      "Epoch 5/18\n",
      "90/90 - 1s - 11ms/step - accuracy: 0.8179 - loss: 0.5223\n",
      "Epoch 6/18\n",
      "90/90 - 1s - 11ms/step - accuracy: 0.8277 - loss: 0.4870\n",
      "Epoch 7/18\n",
      "90/90 - 1s - 11ms/step - accuracy: 0.8401 - loss: 0.4550\n",
      "Epoch 8/18\n",
      "90/90 - 1s - 11ms/step - accuracy: 0.8452 - loss: 0.4308\n",
      "Epoch 9/18\n",
      "90/90 - 1s - 11ms/step - accuracy: 0.8552 - loss: 0.4063\n",
      "Epoch 10/18\n",
      "90/90 - 1s - 11ms/step - accuracy: 0.8606 - loss: 0.3882\n",
      "Epoch 11/18\n",
      "90/90 - 1s - 11ms/step - accuracy: 0.8629 - loss: 0.3867\n",
      "Epoch 12/18\n",
      "90/90 - 1s - 11ms/step - accuracy: 0.8733 - loss: 0.3544\n",
      "Epoch 13/18\n",
      "90/90 - 1s - 11ms/step - accuracy: 0.8783 - loss: 0.3425\n",
      "Epoch 14/18\n",
      "90/90 - 1s - 11ms/step - accuracy: 0.8840 - loss: 0.3322\n",
      "Epoch 15/18\n",
      "90/90 - 1s - 11ms/step - accuracy: 0.8893 - loss: 0.3162\n",
      "Epoch 16/18\n",
      "90/90 - 1s - 11ms/step - accuracy: 0.8877 - loss: 0.3162\n",
      "Epoch 17/18\n",
      "90/90 - 1s - 11ms/step - accuracy: 0.8946 - loss: 0.2992\n",
      "Epoch 18/18\n",
      "90/90 - 1s - 11ms/step - accuracy: 0.8936 - loss: 0.3000\n",
      "23/23 - 0s - 6ms/step\n",
      "Epoch 1/18\n",
      "90/90 - 1s - 16ms/step - accuracy: 0.6786 - loss: 1.0238\n",
      "Epoch 2/18\n",
      "90/90 - 1s - 11ms/step - accuracy: 0.7455 - loss: 0.7334\n",
      "Epoch 3/18\n",
      "90/90 - 1s - 12ms/step - accuracy: 0.7782 - loss: 0.6369\n",
      "Epoch 4/18\n",
      "90/90 - 1s - 11ms/step - accuracy: 0.7983 - loss: 0.5763\n",
      "Epoch 5/18\n",
      "90/90 - 1s - 11ms/step - accuracy: 0.8169 - loss: 0.5269\n",
      "Epoch 6/18\n",
      "90/90 - 1s - 11ms/step - accuracy: 0.8233 - loss: 0.4948\n",
      "Epoch 7/18\n",
      "90/90 - 1s - 11ms/step - accuracy: 0.8341 - loss: 0.4641\n",
      "Epoch 8/18\n",
      "90/90 - 1s - 11ms/step - accuracy: 0.8434 - loss: 0.4439\n",
      "Epoch 9/18\n",
      "90/90 - 1s - 11ms/step - accuracy: 0.8529 - loss: 0.4152\n",
      "Epoch 10/18\n",
      "90/90 - 1s - 11ms/step - accuracy: 0.8611 - loss: 0.3947\n",
      "Epoch 11/18\n",
      "90/90 - 1s - 11ms/step - accuracy: 0.8692 - loss: 0.3739\n",
      "Epoch 12/18\n",
      "90/90 - 1s - 11ms/step - accuracy: 0.8769 - loss: 0.3524\n",
      "Epoch 13/18\n",
      "90/90 - 1s - 11ms/step - accuracy: 0.8798 - loss: 0.3474\n",
      "Epoch 14/18\n",
      "90/90 - 1s - 11ms/step - accuracy: 0.8852 - loss: 0.3247\n",
      "Epoch 15/18\n",
      "90/90 - 1s - 11ms/step - accuracy: 0.8860 - loss: 0.3187\n",
      "Epoch 16/18\n",
      "90/90 - 1s - 11ms/step - accuracy: 0.8887 - loss: 0.3090\n",
      "Epoch 17/18\n",
      "90/90 - 1s - 11ms/step - accuracy: 0.8927 - loss: 0.3096\n",
      "Epoch 18/18\n",
      "90/90 - 1s - 11ms/step - accuracy: 0.9001 - loss: 0.2864\n",
      "23/23 - 0s - 6ms/step\n",
      "| \u001b[39m6        \u001b[39m | \u001b[39m0.8564   \u001b[39m | \u001b[39m3.498    \u001b[39m | \u001b[39m154.3    \u001b[39m | \u001b[39m0.8287   \u001b[39m | \u001b[39m0.3714   \u001b[39m | \u001b[39m18.43    \u001b[39m | \u001b[39m2.085    \u001b[39m | \u001b[39m1.141    \u001b[39m | \u001b[39m1.802    \u001b[39m | \u001b[39m0.07548  \u001b[39m | \u001b[39m98.82    \u001b[39m | \u001b[39m0.7722   \u001b[39m | \u001b[39m1.391    \u001b[39m |\n",
      "Epoch 1/33\n",
      "53/53 - 1s - 10ms/step - accuracy: 0.6144 - loss: 1.3205\n",
      "Epoch 2/33\n",
      "53/53 - 0s - 6ms/step - accuracy: 0.6491 - loss: 1.0513\n",
      "Epoch 3/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.6549 - loss: 1.0082\n",
      "Epoch 4/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.6629 - loss: 0.9746\n",
      "Epoch 5/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.6696 - loss: 0.9551\n",
      "Epoch 6/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.6735 - loss: 0.9392\n",
      "Epoch 7/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.6794 - loss: 0.9194\n",
      "Epoch 8/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.6786 - loss: 0.9107\n",
      "Epoch 9/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.6814 - loss: 0.9032\n",
      "Epoch 10/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.6897 - loss: 0.8915\n",
      "Epoch 11/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.6940 - loss: 0.8828\n",
      "Epoch 12/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.6891 - loss: 0.8749\n",
      "Epoch 13/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.6983 - loss: 0.8728\n",
      "Epoch 14/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.6984 - loss: 0.8653\n",
      "Epoch 15/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.6995 - loss: 0.8621\n",
      "Epoch 16/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.6985 - loss: 0.8564\n",
      "Epoch 17/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.7002 - loss: 0.8550\n",
      "Epoch 18/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.7056 - loss: 0.8453\n",
      "Epoch 19/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.7041 - loss: 0.8452\n",
      "Epoch 20/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.7080 - loss: 0.8436\n",
      "Epoch 21/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.7062 - loss: 0.8404\n",
      "Epoch 22/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.7079 - loss: 0.8381\n",
      "Epoch 23/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.7077 - loss: 0.8330\n",
      "Epoch 24/33\n",
      "53/53 - 0s - 8ms/step - accuracy: 0.7123 - loss: 0.8302\n",
      "Epoch 25/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.7091 - loss: 0.8251\n",
      "Epoch 26/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.7137 - loss: 0.8202\n",
      "Epoch 27/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.7112 - loss: 0.8217\n",
      "Epoch 28/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.7125 - loss: 0.8179\n",
      "Epoch 29/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.7116 - loss: 0.8185\n",
      "Epoch 30/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.7180 - loss: 0.8121\n",
      "Epoch 31/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.7132 - loss: 0.8140\n",
      "Epoch 32/33\n",
      "53/53 - 0s - 6ms/step - accuracy: 0.7172 - loss: 0.8083\n",
      "Epoch 33/33\n",
      "53/53 - 0s - 6ms/step - accuracy: 0.7168 - loss: 0.8079\n",
      "14/14 - 0s - 7ms/step\n",
      "Epoch 1/33\n",
      "53/53 - 1s - 10ms/step - accuracy: 0.6158 - loss: 1.3572\n",
      "Epoch 2/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.6608 - loss: 1.0133\n",
      "Epoch 3/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.6705 - loss: 0.9642\n",
      "Epoch 4/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.6780 - loss: 0.9365\n",
      "Epoch 5/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.6849 - loss: 0.9205\n",
      "Epoch 6/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.6883 - loss: 0.8978\n",
      "Epoch 7/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.6949 - loss: 0.8912\n",
      "Epoch 8/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.6990 - loss: 0.8795\n",
      "Epoch 9/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.6969 - loss: 0.8711\n",
      "Epoch 10/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.7043 - loss: 0.8626\n",
      "Epoch 11/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.7060 - loss: 0.8626\n",
      "Epoch 12/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.6989 - loss: 0.8533\n",
      "Epoch 13/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.7071 - loss: 0.8459\n",
      "Epoch 14/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.7054 - loss: 0.8470\n",
      "Epoch 15/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.7064 - loss: 0.8421\n",
      "Epoch 16/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.7107 - loss: 0.8362\n",
      "Epoch 17/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.7108 - loss: 0.8397\n",
      "Epoch 18/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.7115 - loss: 0.8319\n",
      "Epoch 19/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.7101 - loss: 0.8286\n",
      "Epoch 20/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.7124 - loss: 0.8258\n",
      "Epoch 21/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.7207 - loss: 0.8164\n",
      "Epoch 22/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.7137 - loss: 0.8149\n",
      "Epoch 23/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.7181 - loss: 0.8182\n",
      "Epoch 24/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.7193 - loss: 0.8119\n",
      "Epoch 25/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.7168 - loss: 0.8102\n",
      "Epoch 26/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.7180 - loss: 0.8096\n",
      "Epoch 27/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.7197 - loss: 0.8052\n",
      "Epoch 28/33\n",
      "53/53 - 0s - 8ms/step - accuracy: 0.7191 - loss: 0.8049\n",
      "Epoch 29/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.7200 - loss: 0.8017\n",
      "Epoch 30/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.7226 - loss: 0.7957\n",
      "Epoch 31/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.7223 - loss: 0.7973\n",
      "Epoch 32/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.7216 - loss: 0.7956\n",
      "Epoch 33/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.7279 - loss: 0.7880\n",
      "14/14 - 0s - 5ms/step\n",
      "Epoch 1/33\n",
      "53/53 - 1s - 10ms/step - accuracy: 0.6118 - loss: 1.3710\n",
      "Epoch 2/33\n",
      "53/53 - 0s - 6ms/step - accuracy: 0.6500 - loss: 1.0512\n",
      "Epoch 3/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.6615 - loss: 0.9900\n",
      "Epoch 4/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.6674 - loss: 0.9575\n",
      "Epoch 5/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.6757 - loss: 0.9362\n",
      "Epoch 6/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.6789 - loss: 0.9262\n",
      "Epoch 7/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.6821 - loss: 0.9095\n",
      "Epoch 8/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.6841 - loss: 0.9031\n",
      "Epoch 9/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.6840 - loss: 0.8927\n",
      "Epoch 10/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.6912 - loss: 0.8848\n",
      "Epoch 11/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.6954 - loss: 0.8787\n",
      "Epoch 12/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.6963 - loss: 0.8742\n",
      "Epoch 13/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.7002 - loss: 0.8666\n",
      "Epoch 14/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.7017 - loss: 0.8596\n",
      "Epoch 15/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.7005 - loss: 0.8533\n",
      "Epoch 16/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.7017 - loss: 0.8526\n",
      "Epoch 17/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.7078 - loss: 0.8498\n",
      "Epoch 18/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.7059 - loss: 0.8448\n",
      "Epoch 19/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.7092 - loss: 0.8331\n",
      "Epoch 20/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.7121 - loss: 0.8368\n",
      "Epoch 21/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.7103 - loss: 0.8351\n",
      "Epoch 22/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.7118 - loss: 0.8263\n",
      "Epoch 23/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.7151 - loss: 0.8205\n",
      "Epoch 24/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.7095 - loss: 0.8270\n",
      "Epoch 25/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.7156 - loss: 0.8149\n",
      "Epoch 26/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.7178 - loss: 0.8123\n",
      "Epoch 27/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.7189 - loss: 0.8092\n",
      "Epoch 28/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.7200 - loss: 0.8074\n",
      "Epoch 29/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.7158 - loss: 0.8131\n",
      "Epoch 30/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.7160 - loss: 0.8057\n",
      "Epoch 31/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.7206 - loss: 0.7983\n",
      "Epoch 32/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.7207 - loss: 0.8020\n",
      "Epoch 33/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.7228 - loss: 0.7967\n",
      "14/14 - 0s - 5ms/step\n",
      "Epoch 1/33\n",
      "53/53 - 1s - 10ms/step - accuracy: 0.6105 - loss: 1.3482\n",
      "Epoch 2/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.6471 - loss: 1.0562\n",
      "Epoch 3/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.6671 - loss: 1.0033\n",
      "Epoch 4/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.6715 - loss: 0.9768\n",
      "Epoch 5/33\n",
      "53/53 - 0s - 8ms/step - accuracy: 0.6768 - loss: 0.9537\n",
      "Epoch 6/33\n",
      "53/53 - 0s - 8ms/step - accuracy: 0.6812 - loss: 0.9318\n",
      "Epoch 7/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.6845 - loss: 0.9215\n",
      "Epoch 8/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.6914 - loss: 0.9079\n",
      "Epoch 9/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.6946 - loss: 0.8989\n",
      "Epoch 10/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.6991 - loss: 0.8913\n",
      "Epoch 11/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.6957 - loss: 0.8832\n",
      "Epoch 12/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.6986 - loss: 0.8798\n",
      "Epoch 13/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.7057 - loss: 0.8694\n",
      "Epoch 14/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.7045 - loss: 0.8663\n",
      "Epoch 15/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.7017 - loss: 0.8608\n",
      "Epoch 16/33\n",
      "53/53 - 1s - 11ms/step - accuracy: 0.7060 - loss: 0.8522\n",
      "Epoch 17/33\n",
      "53/53 - 0s - 8ms/step - accuracy: 0.7108 - loss: 0.8488\n",
      "Epoch 18/33\n",
      "53/53 - 0s - 8ms/step - accuracy: 0.7106 - loss: 0.8485\n",
      "Epoch 19/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.7113 - loss: 0.8453\n",
      "Epoch 20/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.7103 - loss: 0.8394\n",
      "Epoch 21/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.7123 - loss: 0.8427\n",
      "Epoch 22/33\n",
      "53/53 - 0s - 8ms/step - accuracy: 0.7168 - loss: 0.8332\n",
      "Epoch 23/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.7124 - loss: 0.8307\n",
      "Epoch 24/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.7148 - loss: 0.8262\n",
      "Epoch 25/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.7183 - loss: 0.8218\n",
      "Epoch 26/33\n",
      "53/53 - 0s - 8ms/step - accuracy: 0.7190 - loss: 0.8205\n",
      "Epoch 27/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.7182 - loss: 0.8191\n",
      "Epoch 28/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.7212 - loss: 0.8135\n",
      "Epoch 29/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.7194 - loss: 0.8179\n",
      "Epoch 30/33\n",
      "53/53 - 0s - 9ms/step - accuracy: 0.7223 - loss: 0.8081\n",
      "Epoch 31/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.7252 - loss: 0.8085\n",
      "Epoch 32/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.7245 - loss: 0.7982\n",
      "Epoch 33/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.7241 - loss: 0.7977\n",
      "14/14 - 0s - 5ms/step\n",
      "Epoch 1/33\n",
      "53/53 - 1s - 10ms/step - accuracy: 0.6075 - loss: 1.3631\n",
      "Epoch 2/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.6464 - loss: 1.0652\n",
      "Epoch 3/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.6555 - loss: 1.0078\n",
      "Epoch 4/33\n",
      "53/53 - 0s - 8ms/step - accuracy: 0.6699 - loss: 0.9674\n",
      "Epoch 5/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.6770 - loss: 0.9371\n",
      "Epoch 6/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.6776 - loss: 0.9251\n",
      "Epoch 7/33\n",
      "53/53 - 0s - 8ms/step - accuracy: 0.6811 - loss: 0.9080\n",
      "Epoch 8/33\n",
      "53/53 - 0s - 8ms/step - accuracy: 0.6865 - loss: 0.8996\n",
      "Epoch 9/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.6893 - loss: 0.8862\n",
      "Epoch 10/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.6936 - loss: 0.8793\n",
      "Epoch 11/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.6985 - loss: 0.8704\n",
      "Epoch 12/33\n",
      "53/53 - 0s - 8ms/step - accuracy: 0.7001 - loss: 0.8627\n",
      "Epoch 13/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.7042 - loss: 0.8560\n",
      "Epoch 14/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.7028 - loss: 0.8518\n",
      "Epoch 15/33\n",
      "53/53 - 0s - 8ms/step - accuracy: 0.7069 - loss: 0.8471\n",
      "Epoch 16/33\n",
      "53/53 - 0s - 9ms/step - accuracy: 0.7067 - loss: 0.8403\n",
      "Epoch 17/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.7039 - loss: 0.8436\n",
      "Epoch 18/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.7123 - loss: 0.8321\n",
      "Epoch 19/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.7105 - loss: 0.8318\n",
      "Epoch 20/33\n",
      "53/53 - 0s - 8ms/step - accuracy: 0.7106 - loss: 0.8292\n",
      "Epoch 21/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.7147 - loss: 0.8256\n",
      "Epoch 22/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.7155 - loss: 0.8187\n",
      "Epoch 23/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.7145 - loss: 0.8152\n",
      "Epoch 24/33\n",
      "53/53 - 0s - 8ms/step - accuracy: 0.7181 - loss: 0.8098\n",
      "Epoch 25/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.7150 - loss: 0.8151\n",
      "Epoch 26/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.7193 - loss: 0.8100\n",
      "Epoch 27/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.7166 - loss: 0.8079\n",
      "Epoch 28/33\n",
      "53/53 - 0s - 8ms/step - accuracy: 0.7219 - loss: 0.8071\n",
      "Epoch 29/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.7197 - loss: 0.8037\n",
      "Epoch 30/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.7208 - loss: 0.7975\n",
      "Epoch 31/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.7221 - loss: 0.7947\n",
      "Epoch 32/33\n",
      "53/53 - 0s - 8ms/step - accuracy: 0.7218 - loss: 0.7936\n",
      "Epoch 33/33\n",
      "53/53 - 0s - 7ms/step - accuracy: 0.7229 - loss: 0.7939\n",
      "14/14 - 0s - 5ms/step\n",
      "| \u001b[39m7        \u001b[39m | \u001b[39m0.7343   \u001b[39m | \u001b[39m0.0497   \u001b[39m | \u001b[39m263.1    \u001b[39m | \u001b[39m0.7069   \u001b[39m | \u001b[39m0.4458   \u001b[39m | \u001b[39m33.14    \u001b[39m | \u001b[39m1.148    \u001b[39m | \u001b[39m1.358    \u001b[39m | \u001b[39m1.116    \u001b[39m | \u001b[39m0.8632   \u001b[39m | \u001b[39m66.1     \u001b[39m | \u001b[39m0.3309   \u001b[39m | \u001b[39m0.4449   \u001b[39m |\n",
      "Epoch 1/37\n",
      "84/84 - 1s - 13ms/step - accuracy: 0.0157 - loss: 2.8565\n",
      "Epoch 2/37\n",
      "84/84 - 1s - 7ms/step - accuracy: 0.0179 - loss: 2.8380\n",
      "Epoch 3/37\n",
      "84/84 - 1s - 6ms/step - accuracy: 0.0204 - loss: 2.8224\n",
      "Epoch 4/37\n",
      "84/84 - 1s - 6ms/step - accuracy: 0.0254 - loss: 2.8008\n",
      "Epoch 5/37\n",
      "84/84 - 1s - 7ms/step - accuracy: 0.0309 - loss: 2.7815\n",
      "Epoch 6/37\n",
      "84/84 - 1s - 7ms/step - accuracy: 0.0377 - loss: 2.7613\n",
      "Epoch 7/37\n",
      "84/84 - 1s - 7ms/step - accuracy: 0.0413 - loss: 2.7378\n",
      "Epoch 8/37\n",
      "84/84 - 1s - 6ms/step - accuracy: 0.0526 - loss: 2.7169\n",
      "Epoch 9/37\n",
      "84/84 - 1s - 6ms/step - accuracy: 0.0638 - loss: 2.6965\n",
      "Epoch 10/37\n",
      "84/84 - 1s - 7ms/step - accuracy: 0.0768 - loss: 2.6738\n",
      "Epoch 11/37\n",
      "84/84 - 1s - 6ms/step - accuracy: 0.0898 - loss: 2.6526\n",
      "Epoch 12/37\n",
      "84/84 - 1s - 6ms/step - accuracy: 0.1084 - loss: 2.6282\n",
      "Epoch 13/37\n",
      "84/84 - 1s - 6ms/step - accuracy: 0.1265 - loss: 2.6042\n",
      "Epoch 14/37\n",
      "84/84 - 1s - 7ms/step - accuracy: 0.1524 - loss: 2.5812\n",
      "Epoch 15/37\n",
      "84/84 - 1s - 6ms/step - accuracy: 0.1751 - loss: 2.5573\n",
      "Epoch 16/37\n",
      "84/84 - 1s - 6ms/step - accuracy: 0.1987 - loss: 2.5349\n",
      "Epoch 17/37\n",
      "84/84 - 1s - 6ms/step - accuracy: 0.2303 - loss: 2.5116\n",
      "Epoch 18/37\n",
      "84/84 - 1s - 7ms/step - accuracy: 0.2603 - loss: 2.4880\n",
      "Epoch 19/37\n",
      "84/84 - 1s - 7ms/step - accuracy: 0.2838 - loss: 2.4639\n",
      "Epoch 20/37\n",
      "84/84 - 1s - 7ms/step - accuracy: 0.3181 - loss: 2.4387\n",
      "Epoch 21/37\n",
      "84/84 - 1s - 7ms/step - accuracy: 0.3400 - loss: 2.4168\n",
      "Epoch 22/37\n",
      "84/84 - 1s - 7ms/step - accuracy: 0.3741 - loss: 2.3918\n",
      "Epoch 23/37\n",
      "84/84 - 1s - 7ms/step - accuracy: 0.4008 - loss: 2.3651\n",
      "Epoch 24/37\n",
      "84/84 - 1s - 7ms/step - accuracy: 0.4274 - loss: 2.3426\n",
      "Epoch 25/37\n",
      "84/84 - 1s - 7ms/step - accuracy: 0.4447 - loss: 2.3183\n",
      "Epoch 26/37\n",
      "84/84 - 1s - 7ms/step - accuracy: 0.4731 - loss: 2.2926\n",
      "Epoch 27/37\n",
      "84/84 - 1s - 6ms/step - accuracy: 0.4877 - loss: 2.2709\n",
      "Epoch 28/37\n",
      "84/84 - 1s - 6ms/step - accuracy: 0.5077 - loss: 2.2439\n",
      "Epoch 29/37\n",
      "84/84 - 1s - 6ms/step - accuracy: 0.5218 - loss: 2.2212\n",
      "Epoch 30/37\n",
      "84/84 - 1s - 8ms/step - accuracy: 0.5359 - loss: 2.1961\n",
      "Epoch 31/37\n",
      "84/84 - 1s - 7ms/step - accuracy: 0.5460 - loss: 2.1731\n",
      "Epoch 32/37\n",
      "84/84 - 1s - 6ms/step - accuracy: 0.5613 - loss: 2.1490\n",
      "Epoch 33/37\n",
      "84/84 - 1s - 7ms/step - accuracy: 0.5724 - loss: 2.1247\n",
      "Epoch 34/37\n",
      "84/84 - 1s - 7ms/step - accuracy: 0.5820 - loss: 2.1013\n",
      "Epoch 35/37\n",
      "84/84 - 1s - 7ms/step - accuracy: 0.5844 - loss: 2.0780\n",
      "Epoch 36/37\n",
      "84/84 - 1s - 6ms/step - accuracy: 0.5882 - loss: 2.0543\n",
      "Epoch 37/37\n",
      "84/84 - 1s - 7ms/step - accuracy: 0.5965 - loss: 2.0286\n",
      "21/21 - 0s - 5ms/step\n",
      "Epoch 1/37\n",
      "84/84 - 1s - 12ms/step - accuracy: 0.0752 - loss: 2.6375\n",
      "Epoch 2/37\n",
      "84/84 - 1s - 7ms/step - accuracy: 0.0884 - loss: 2.6205\n",
      "Epoch 3/37\n",
      "84/84 - 1s - 6ms/step - accuracy: 0.0974 - loss: 2.6052\n",
      "Epoch 4/37\n",
      "84/84 - 1s - 9ms/step - accuracy: 0.1159 - loss: 2.5852\n",
      "Epoch 5/37\n",
      "84/84 - 1s - 7ms/step - accuracy: 0.1307 - loss: 2.5691\n",
      "Epoch 6/37\n",
      "84/84 - 1s - 7ms/step - accuracy: 0.1497 - loss: 2.5498\n",
      "Epoch 7/37\n",
      "84/84 - 1s - 7ms/step - accuracy: 0.1696 - loss: 2.5304\n",
      "Epoch 8/37\n",
      "84/84 - 1s - 7ms/step - accuracy: 0.1906 - loss: 2.5063\n",
      "Epoch 9/37\n",
      "84/84 - 1s - 7ms/step - accuracy: 0.2087 - loss: 2.4894\n",
      "Epoch 10/37\n",
      "84/84 - 1s - 7ms/step - accuracy: 0.2294 - loss: 2.4665\n",
      "Epoch 11/37\n",
      "84/84 - 1s - 7ms/step - accuracy: 0.2524 - loss: 2.4483\n",
      "Epoch 12/37\n",
      "84/84 - 1s - 7ms/step - accuracy: 0.2708 - loss: 2.4274\n",
      "Epoch 13/37\n",
      "84/84 - 1s - 7ms/step - accuracy: 0.2870 - loss: 2.4065\n",
      "Epoch 14/37\n",
      "84/84 - 1s - 6ms/step - accuracy: 0.3037 - loss: 2.3826\n",
      "Epoch 15/37\n",
      "84/84 - 1s - 7ms/step - accuracy: 0.3209 - loss: 2.3622\n",
      "Epoch 16/37\n",
      "84/84 - 1s - 6ms/step - accuracy: 0.3366 - loss: 2.3440\n",
      "Epoch 17/37\n",
      "84/84 - 1s - 6ms/step - accuracy: 0.3549 - loss: 2.3188\n",
      "Epoch 18/37\n",
      "84/84 - 1s - 6ms/step - accuracy: 0.3769 - loss: 2.2944\n",
      "Epoch 19/37\n",
      "84/84 - 1s - 7ms/step - accuracy: 0.3814 - loss: 2.2790\n",
      "Epoch 20/37\n",
      "84/84 - 1s - 7ms/step - accuracy: 0.4052 - loss: 2.2508\n",
      "Epoch 21/37\n",
      "84/84 - 1s - 7ms/step - accuracy: 0.4121 - loss: 2.2306\n",
      "Epoch 22/37\n",
      "84/84 - 1s - 6ms/step - accuracy: 0.4205 - loss: 2.2091\n",
      "Epoch 23/37\n",
      "84/84 - 1s - 7ms/step - accuracy: 0.4369 - loss: 2.1840\n",
      "Epoch 24/37\n",
      "84/84 - 1s - 7ms/step - accuracy: 0.4464 - loss: 2.1648\n",
      "Epoch 25/37\n",
      "84/84 - 1s - 7ms/step - accuracy: 0.4631 - loss: 2.1414\n",
      "Epoch 26/37\n",
      "84/84 - 1s - 8ms/step - accuracy: 0.4638 - loss: 2.1201\n",
      "Epoch 27/37\n",
      "84/84 - 1s - 7ms/step - accuracy: 0.4735 - loss: 2.0983\n",
      "Epoch 28/37\n",
      "84/84 - 1s - 7ms/step - accuracy: 0.4862 - loss: 2.0752\n",
      "Epoch 29/37\n",
      "84/84 - 1s - 7ms/step - accuracy: 0.4971 - loss: 2.0508\n",
      "Epoch 30/37\n",
      "84/84 - 1s - 7ms/step - accuracy: 0.5086 - loss: 2.0307\n",
      "Epoch 31/37\n",
      "84/84 - 1s - 7ms/step - accuracy: 0.5087 - loss: 2.0097\n",
      "Epoch 32/37\n",
      "84/84 - 1s - 8ms/step - accuracy: 0.5130 - loss: 1.9891\n",
      "Epoch 33/37\n",
      "84/84 - 1s - 7ms/step - accuracy: 0.5248 - loss: 1.9676\n",
      "Epoch 34/37\n",
      "84/84 - 1s - 7ms/step - accuracy: 0.5329 - loss: 1.9461\n",
      "Epoch 35/37\n",
      "84/84 - 1s - 7ms/step - accuracy: 0.5397 - loss: 1.9236\n",
      "Epoch 36/37\n",
      "84/84 - 1s - 7ms/step - accuracy: 0.5499 - loss: 1.9019\n",
      "Epoch 37/37\n",
      "84/84 - 1s - 8ms/step - accuracy: 0.5533 - loss: 1.8839\n",
      "21/21 - 0s - 7ms/step\n",
      "Epoch 1/37\n",
      "84/84 - 1s - 12ms/step - accuracy: 0.0418 - loss: 2.7399\n",
      "Epoch 2/37\n",
      "84/84 - 1s - 6ms/step - accuracy: 0.0497 - loss: 2.7194\n",
      "Epoch 3/37\n",
      "84/84 - 1s - 6ms/step - accuracy: 0.0595 - loss: 2.7027\n",
      "Epoch 4/37\n",
      "84/84 - 1s - 6ms/step - accuracy: 0.0668 - loss: 2.6819\n",
      "Epoch 5/37\n",
      "84/84 - 1s - 6ms/step - accuracy: 0.0842 - loss: 2.6605\n",
      "Epoch 6/37\n",
      "84/84 - 1s - 7ms/step - accuracy: 0.1012 - loss: 2.6387\n",
      "Epoch 7/37\n",
      "84/84 - 1s - 7ms/step - accuracy: 0.1190 - loss: 2.6175\n",
      "Epoch 8/37\n",
      "84/84 - 1s - 7ms/step - accuracy: 0.1429 - loss: 2.5939\n",
      "Epoch 9/37\n",
      "84/84 - 1s - 7ms/step - accuracy: 0.1663 - loss: 2.5701\n",
      "Epoch 10/37\n",
      "84/84 - 1s - 6ms/step - accuracy: 0.1919 - loss: 2.5493\n",
      "Epoch 11/37\n",
      "84/84 - 1s - 6ms/step - accuracy: 0.2272 - loss: 2.5226\n",
      "Epoch 12/37\n",
      "84/84 - 1s - 6ms/step - accuracy: 0.2605 - loss: 2.4955\n",
      "Epoch 13/37\n",
      "84/84 - 0s - 6ms/step - accuracy: 0.2895 - loss: 2.4728\n",
      "Epoch 14/37\n",
      "84/84 - 0s - 6ms/step - accuracy: 0.3266 - loss: 2.4472\n",
      "Epoch 15/37\n",
      "84/84 - 0s - 6ms/step - accuracy: 0.3682 - loss: 2.4213\n",
      "Epoch 16/37\n",
      "84/84 - 1s - 6ms/step - accuracy: 0.3981 - loss: 2.3966\n",
      "Epoch 17/37\n",
      "84/84 - 0s - 6ms/step - accuracy: 0.4278 - loss: 2.3696\n",
      "Epoch 18/37\n",
      "84/84 - 0s - 6ms/step - accuracy: 0.4615 - loss: 2.3447\n",
      "Epoch 19/37\n",
      "84/84 - 1s - 6ms/step - accuracy: 0.4892 - loss: 2.3155\n",
      "Epoch 20/37\n",
      "84/84 - 1s - 6ms/step - accuracy: 0.5125 - loss: 2.2918\n",
      "Epoch 21/37\n",
      "84/84 - 0s - 6ms/step - accuracy: 0.5306 - loss: 2.2670\n",
      "Epoch 22/37\n",
      "84/84 - 0s - 6ms/step - accuracy: 0.5504 - loss: 2.2395\n",
      "Epoch 23/37\n",
      "84/84 - 0s - 6ms/step - accuracy: 0.5641 - loss: 2.2136\n",
      "Epoch 24/37\n",
      "84/84 - 1s - 6ms/step - accuracy: 0.5810 - loss: 2.1854\n",
      "Epoch 25/37\n",
      "84/84 - 0s - 6ms/step - accuracy: 0.5906 - loss: 2.1606\n",
      "Epoch 26/37\n",
      "84/84 - 0s - 6ms/step - accuracy: 0.6017 - loss: 2.1337\n",
      "Epoch 27/37\n",
      "84/84 - 1s - 6ms/step - accuracy: 0.6086 - loss: 2.1071\n",
      "Epoch 28/37\n",
      "84/84 - 1s - 6ms/step - accuracy: 0.6147 - loss: 2.0799\n",
      "Epoch 29/37\n",
      "84/84 - 0s - 6ms/step - accuracy: 0.6249 - loss: 2.0524\n",
      "Epoch 30/37\n",
      "84/84 - 0s - 6ms/step - accuracy: 0.6301 - loss: 2.0253\n",
      "Epoch 31/37\n",
      "84/84 - 0s - 6ms/step - accuracy: 0.6308 - loss: 2.0010\n",
      "Epoch 32/37\n",
      "84/84 - 1s - 6ms/step - accuracy: 0.6368 - loss: 1.9740\n",
      "Epoch 33/37\n",
      "84/84 - 0s - 6ms/step - accuracy: 0.6399 - loss: 1.9486\n",
      "Epoch 34/37\n",
      "84/84 - 0s - 6ms/step - accuracy: 0.6372 - loss: 1.9229\n",
      "Epoch 35/37\n",
      "84/84 - 0s - 6ms/step - accuracy: 0.6414 - loss: 1.8990\n",
      "Epoch 36/37\n",
      "84/84 - 1s - 6ms/step - accuracy: 0.6438 - loss: 1.8725\n",
      "Epoch 37/37\n",
      "84/84 - 0s - 6ms/step - accuracy: 0.6420 - loss: 1.8485\n",
      "21/21 - 0s - 5ms/step\n",
      "Epoch 1/37\n",
      "84/84 - 1s - 12ms/step - accuracy: 0.2298 - loss: 2.5612\n",
      "Epoch 2/37\n",
      "84/84 - 1s - 7ms/step - accuracy: 0.2378 - loss: 2.5473\n",
      "Epoch 3/37\n",
      "84/84 - 1s - 7ms/step - accuracy: 0.2696 - loss: 2.5277\n",
      "Epoch 4/37\n",
      "84/84 - 1s - 6ms/step - accuracy: 0.2887 - loss: 2.5098\n",
      "Epoch 5/37\n",
      "84/84 - 1s - 6ms/step - accuracy: 0.3182 - loss: 2.4906\n",
      "Epoch 6/37\n",
      "84/84 - 1s - 6ms/step - accuracy: 0.3423 - loss: 2.4726\n",
      "Epoch 7/37\n",
      "84/84 - 0s - 6ms/step - accuracy: 0.3659 - loss: 2.4533\n",
      "Epoch 8/37\n",
      "84/84 - 1s - 6ms/step - accuracy: 0.3948 - loss: 2.4330\n",
      "Epoch 9/37\n",
      "84/84 - 0s - 6ms/step - accuracy: 0.4174 - loss: 2.4158\n",
      "Epoch 10/37\n",
      "84/84 - 1s - 6ms/step - accuracy: 0.4417 - loss: 2.3926\n",
      "Epoch 11/37\n",
      "84/84 - 1s - 7ms/step - accuracy: 0.4683 - loss: 2.3715\n",
      "Epoch 12/37\n",
      "84/84 - 0s - 6ms/step - accuracy: 0.4919 - loss: 2.3487\n",
      "Epoch 13/37\n",
      "84/84 - 1s - 7ms/step - accuracy: 0.5118 - loss: 2.3278\n",
      "Epoch 14/37\n",
      "84/84 - 1s - 6ms/step - accuracy: 0.5356 - loss: 2.3055\n",
      "Epoch 15/37\n",
      "84/84 - 0s - 6ms/step - accuracy: 0.5480 - loss: 2.2842\n",
      "Epoch 16/37\n",
      "84/84 - 0s - 6ms/step - accuracy: 0.5668 - loss: 2.2615\n",
      "Epoch 17/37\n",
      "84/84 - 1s - 6ms/step - accuracy: 0.5789 - loss: 2.2363\n",
      "Epoch 18/37\n",
      "84/84 - 1s - 6ms/step - accuracy: 0.5888 - loss: 2.2178\n",
      "Epoch 19/37\n",
      "84/84 - 0s - 6ms/step - accuracy: 0.5965 - loss: 2.1934\n",
      "Epoch 20/37\n",
      "84/84 - 1s - 6ms/step - accuracy: 0.6040 - loss: 2.1718\n",
      "Epoch 21/37\n",
      "84/84 - 0s - 6ms/step - accuracy: 0.6148 - loss: 2.1449\n",
      "Epoch 22/37\n",
      "84/84 - 0s - 6ms/step - accuracy: 0.6178 - loss: 2.1252\n",
      "Epoch 23/37\n",
      "84/84 - 1s - 6ms/step - accuracy: 0.6202 - loss: 2.1003\n",
      "Epoch 24/37\n",
      "84/84 - 0s - 6ms/step - accuracy: 0.6229 - loss: 2.0785\n",
      "Epoch 25/37\n",
      "84/84 - 0s - 6ms/step - accuracy: 0.6292 - loss: 2.0539\n",
      "Epoch 26/37\n",
      "84/84 - 1s - 7ms/step - accuracy: 0.6288 - loss: 2.0334\n",
      "Epoch 27/37\n",
      "84/84 - 0s - 6ms/step - accuracy: 0.6326 - loss: 2.0083\n",
      "Epoch 28/37\n",
      "84/84 - 0s - 6ms/step - accuracy: 0.6333 - loss: 1.9858\n",
      "Epoch 29/37\n",
      "84/84 - 1s - 6ms/step - accuracy: 0.6371 - loss: 1.9633\n",
      "Epoch 30/37\n",
      "84/84 - 0s - 6ms/step - accuracy: 0.6348 - loss: 1.9416\n",
      "Epoch 31/37\n",
      "84/84 - 0s - 6ms/step - accuracy: 0.6345 - loss: 1.9180\n",
      "Epoch 32/37\n",
      "84/84 - 1s - 6ms/step - accuracy: 0.6394 - loss: 1.8938\n",
      "Epoch 33/37\n",
      "84/84 - 1s - 6ms/step - accuracy: 0.6367 - loss: 1.8727\n",
      "Epoch 34/37\n",
      "84/84 - 1s - 6ms/step - accuracy: 0.6397 - loss: 1.8510\n",
      "Epoch 35/37\n",
      "84/84 - 1s - 6ms/step - accuracy: 0.6428 - loss: 1.8296\n",
      "Epoch 36/37\n",
      "84/84 - 1s - 6ms/step - accuracy: 0.6413 - loss: 1.8057\n",
      "Epoch 37/37\n",
      "84/84 - 0s - 6ms/step - accuracy: 0.6404 - loss: 1.7818\n",
      "21/21 - 0s - 5ms/step\n",
      "Epoch 1/37\n",
      "84/84 - 1s - 11ms/step - accuracy: 0.0196 - loss: 2.7925\n",
      "Epoch 2/37\n",
      "84/84 - 0s - 6ms/step - accuracy: 0.0234 - loss: 2.7740\n",
      "Epoch 3/37\n",
      "84/84 - 1s - 6ms/step - accuracy: 0.0283 - loss: 2.7574\n",
      "Epoch 4/37\n",
      "84/84 - 0s - 6ms/step - accuracy: 0.0298 - loss: 2.7391\n",
      "Epoch 5/37\n",
      "84/84 - 0s - 6ms/step - accuracy: 0.0336 - loss: 2.7230\n",
      "Epoch 6/37\n",
      "84/84 - 1s - 6ms/step - accuracy: 0.0393 - loss: 2.7024\n",
      "Epoch 7/37\n",
      "84/84 - 0s - 6ms/step - accuracy: 0.0476 - loss: 2.6829\n",
      "Epoch 8/37\n",
      "84/84 - 0s - 6ms/step - accuracy: 0.0556 - loss: 2.6617\n",
      "Epoch 9/37\n",
      "84/84 - 1s - 6ms/step - accuracy: 0.0660 - loss: 2.6414\n",
      "Epoch 10/37\n",
      "84/84 - 0s - 6ms/step - accuracy: 0.0789 - loss: 2.6207\n",
      "Epoch 11/37\n",
      "84/84 - 0s - 6ms/step - accuracy: 0.0999 - loss: 2.5959\n",
      "Epoch 12/37\n",
      "84/84 - 1s - 6ms/step - accuracy: 0.1149 - loss: 2.5749\n",
      "Epoch 13/37\n",
      "84/84 - 0s - 6ms/step - accuracy: 0.1355 - loss: 2.5520\n",
      "Epoch 14/37\n",
      "84/84 - 0s - 6ms/step - accuracy: 0.1624 - loss: 2.5319\n",
      "Epoch 15/37\n",
      "84/84 - 1s - 6ms/step - accuracy: 0.1845 - loss: 2.5078\n",
      "Epoch 16/37\n",
      "84/84 - 0s - 6ms/step - accuracy: 0.2159 - loss: 2.4849\n",
      "Epoch 17/37\n",
      "84/84 - 0s - 6ms/step - accuracy: 0.2474 - loss: 2.4613\n",
      "Epoch 18/37\n",
      "84/84 - 1s - 6ms/step - accuracy: 0.2778 - loss: 2.4386\n",
      "Epoch 19/37\n",
      "84/84 - 0s - 6ms/step - accuracy: 0.3134 - loss: 2.4147\n",
      "Epoch 20/37\n",
      "84/84 - 0s - 6ms/step - accuracy: 0.3418 - loss: 2.3937\n",
      "Epoch 21/37\n",
      "84/84 - 0s - 6ms/step - accuracy: 0.3716 - loss: 2.3664\n",
      "Epoch 22/37\n",
      "84/84 - 0s - 6ms/step - accuracy: 0.3991 - loss: 2.3451\n",
      "Epoch 23/37\n",
      "84/84 - 0s - 6ms/step - accuracy: 0.4323 - loss: 2.3192\n",
      "Epoch 24/37\n",
      "84/84 - 1s - 6ms/step - accuracy: 0.4525 - loss: 2.2951\n",
      "Epoch 25/37\n",
      "84/84 - 0s - 6ms/step - accuracy: 0.4734 - loss: 2.2727\n",
      "Epoch 26/37\n",
      "84/84 - 0s - 6ms/step - accuracy: 0.4882 - loss: 2.2486\n",
      "Epoch 27/37\n",
      "84/84 - 1s - 6ms/step - accuracy: 0.5084 - loss: 2.2254\n",
      "Epoch 28/37\n",
      "84/84 - 1s - 6ms/step - accuracy: 0.5240 - loss: 2.1961\n",
      "Epoch 29/37\n",
      "84/84 - 1s - 6ms/step - accuracy: 0.5342 - loss: 2.1752\n",
      "Epoch 30/37\n",
      "84/84 - 1s - 7ms/step - accuracy: 0.5418 - loss: 2.1505\n",
      "Epoch 31/37\n",
      "84/84 - 1s - 6ms/step - accuracy: 0.5514 - loss: 2.1267\n",
      "Epoch 32/37\n",
      "84/84 - 1s - 6ms/step - accuracy: 0.5616 - loss: 2.1030\n",
      "Epoch 33/37\n",
      "84/84 - 1s - 7ms/step - accuracy: 0.5681 - loss: 2.0781\n",
      "Epoch 34/37\n",
      "84/84 - 1s - 6ms/step - accuracy: 0.5737 - loss: 2.0556\n",
      "Epoch 35/37\n",
      "84/84 - 1s - 6ms/step - accuracy: 0.5877 - loss: 2.0290\n",
      "Epoch 36/37\n",
      "84/84 - 1s - 6ms/step - accuracy: 0.5790 - loss: 2.0104\n",
      "Epoch 37/37\n",
      "84/84 - 1s - 6ms/step - accuracy: 0.5860 - loss: 1.9834\n",
      "21/21 - 0s - 4ms/step\n",
      "| \u001b[39m8        \u001b[39m | \u001b[39mnan      \u001b[39m | \u001b[39m2.799    \u001b[39m | \u001b[39m165.0    \u001b[39m | \u001b[39m0.7296   \u001b[39m | \u001b[39m0.4275   \u001b[39m | \u001b[39m36.62    \u001b[39m | \u001b[39m1.944    \u001b[39m | \u001b[39m1.12     \u001b[39m | \u001b[39m1.713    \u001b[39m | \u001b[39m0.761    \u001b[39m | \u001b[39m60.51    \u001b[39m | \u001b[39m0.771    \u001b[39m | \u001b[39m3.457    \u001b[39m |\n",
      "Epoch 1/11\n",
      "75/75 - 1s - 8ms/step - accuracy: 0.6278 - loss: 1.2155\n",
      "Epoch 2/11\n",
      "75/75 - 0s - 3ms/step - accuracy: 0.6833 - loss: 0.9353\n",
      "Epoch 3/11\n",
      "75/75 - 0s - 3ms/step - accuracy: 0.7004 - loss: 0.8857\n",
      "Epoch 4/11\n",
      "75/75 - 0s - 3ms/step - accuracy: 0.7133 - loss: 0.8508\n",
      "Epoch 5/11\n",
      "75/75 - 0s - 3ms/step - accuracy: 0.7189 - loss: 0.8271\n",
      "Epoch 6/11\n",
      "75/75 - 0s - 3ms/step - accuracy: 0.7246 - loss: 0.8065\n",
      "Epoch 7/11\n",
      "75/75 - 0s - 3ms/step - accuracy: 0.7298 - loss: 0.7886\n",
      "Epoch 8/11\n",
      "75/75 - 0s - 3ms/step - accuracy: 0.7349 - loss: 0.7776\n",
      "Epoch 9/11\n",
      "75/75 - 0s - 3ms/step - accuracy: 0.7384 - loss: 0.7654\n",
      "Epoch 10/11\n",
      "75/75 - 0s - 3ms/step - accuracy: 0.7419 - loss: 0.7537\n",
      "Epoch 11/11\n",
      "75/75 - 0s - 3ms/step - accuracy: 0.7445 - loss: 0.7425\n",
      "19/19 - 0s - 3ms/step\n",
      "Epoch 1/11\n",
      "75/75 - 1s - 7ms/step - accuracy: 0.5732 - loss: 1.4616\n",
      "Epoch 2/11\n",
      "75/75 - 0s - 3ms/step - accuracy: 0.6678 - loss: 0.9453\n",
      "Epoch 3/11\n",
      "75/75 - 0s - 3ms/step - accuracy: 0.6878 - loss: 0.8902\n",
      "Epoch 4/11\n",
      "75/75 - 0s - 3ms/step - accuracy: 0.6994 - loss: 0.8552\n",
      "Epoch 5/11\n",
      "75/75 - 0s - 3ms/step - accuracy: 0.7087 - loss: 0.8286\n",
      "Epoch 6/11\n",
      "75/75 - 0s - 3ms/step - accuracy: 0.7160 - loss: 0.8083\n",
      "Epoch 7/11\n",
      "75/75 - 0s - 3ms/step - accuracy: 0.7221 - loss: 0.7940\n",
      "Epoch 8/11\n",
      "75/75 - 0s - 3ms/step - accuracy: 0.7278 - loss: 0.7783\n",
      "Epoch 9/11\n",
      "75/75 - 0s - 3ms/step - accuracy: 0.7295 - loss: 0.7645\n",
      "Epoch 10/11\n",
      "75/75 - 0s - 3ms/step - accuracy: 0.7323 - loss: 0.7534\n",
      "Epoch 11/11\n",
      "75/75 - 0s - 3ms/step - accuracy: 0.7345 - loss: 0.7486\n",
      "19/19 - 0s - 3ms/step\n",
      "Epoch 1/11\n",
      "75/75 - 1s - 7ms/step - accuracy: 0.6054 - loss: 1.2874\n",
      "Epoch 2/11\n",
      "75/75 - 0s - 3ms/step - accuracy: 0.6765 - loss: 0.9469\n",
      "Epoch 3/11\n",
      "75/75 - 0s - 3ms/step - accuracy: 0.6983 - loss: 0.8900\n",
      "Epoch 4/11\n",
      "75/75 - 0s - 3ms/step - accuracy: 0.7090 - loss: 0.8514\n",
      "Epoch 5/11\n",
      "75/75 - 0s - 3ms/step - accuracy: 0.7200 - loss: 0.8180\n",
      "Epoch 6/11\n",
      "75/75 - 0s - 3ms/step - accuracy: 0.7281 - loss: 0.7928\n",
      "Epoch 7/11\n",
      "75/75 - 0s - 3ms/step - accuracy: 0.7365 - loss: 0.7708\n",
      "Epoch 8/11\n",
      "75/75 - 0s - 3ms/step - accuracy: 0.7434 - loss: 0.7519\n",
      "Epoch 9/11\n",
      "75/75 - 0s - 3ms/step - accuracy: 0.7493 - loss: 0.7351\n",
      "Epoch 10/11\n",
      "75/75 - 0s - 3ms/step - accuracy: 0.7505 - loss: 0.7243\n",
      "Epoch 11/11\n",
      "75/75 - 0s - 3ms/step - accuracy: 0.7572 - loss: 0.7072\n",
      "19/19 - 0s - 3ms/step\n",
      "Epoch 1/11\n",
      "75/75 - 1s - 7ms/step - accuracy: 0.6041 - loss: 1.3604\n",
      "Epoch 2/11\n",
      "75/75 - 0s - 3ms/step - accuracy: 0.6742 - loss: 0.9630\n",
      "Epoch 3/11\n",
      "75/75 - 0s - 3ms/step - accuracy: 0.6916 - loss: 0.9047\n",
      "Epoch 4/11\n",
      "75/75 - 0s - 3ms/step - accuracy: 0.7023 - loss: 0.8692\n",
      "Epoch 5/11\n",
      "75/75 - 0s - 3ms/step - accuracy: 0.7110 - loss: 0.8436\n",
      "Epoch 6/11\n",
      "75/75 - 0s - 3ms/step - accuracy: 0.7198 - loss: 0.8207\n",
      "Epoch 7/11\n",
      "75/75 - 0s - 3ms/step - accuracy: 0.7249 - loss: 0.8016\n",
      "Epoch 8/11\n",
      "75/75 - 0s - 3ms/step - accuracy: 0.7306 - loss: 0.7847\n",
      "Epoch 9/11\n",
      "75/75 - 0s - 3ms/step - accuracy: 0.7337 - loss: 0.7715\n",
      "Epoch 10/11\n",
      "75/75 - 0s - 3ms/step - accuracy: 0.7402 - loss: 0.7577\n",
      "Epoch 11/11\n",
      "75/75 - 0s - 3ms/step - accuracy: 0.7448 - loss: 0.7449\n",
      "19/19 - 0s - 3ms/step\n",
      "Epoch 1/11\n",
      "75/75 - 1s - 7ms/step - accuracy: 0.6243 - loss: 1.2577\n",
      "Epoch 2/11\n",
      "75/75 - 0s - 3ms/step - accuracy: 0.6867 - loss: 0.9645\n",
      "Epoch 3/11\n",
      "75/75 - 0s - 3ms/step - accuracy: 0.6996 - loss: 0.9093\n",
      "Epoch 4/11\n",
      "75/75 - 0s - 3ms/step - accuracy: 0.7091 - loss: 0.8731\n",
      "Epoch 5/11\n",
      "75/75 - 0s - 3ms/step - accuracy: 0.7166 - loss: 0.8446\n",
      "Epoch 6/11\n",
      "75/75 - 0s - 3ms/step - accuracy: 0.7231 - loss: 0.8161\n",
      "Epoch 7/11\n",
      "75/75 - 0s - 3ms/step - accuracy: 0.7280 - loss: 0.7962\n",
      "Epoch 8/11\n",
      "75/75 - 0s - 3ms/step - accuracy: 0.7354 - loss: 0.7750\n",
      "Epoch 9/11\n",
      "75/75 - 0s - 3ms/step - accuracy: 0.7369 - loss: 0.7601\n",
      "Epoch 10/11\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.7431 - loss: 0.7448\n",
      "Epoch 11/11\n",
      "75/75 - 0s - 3ms/step - accuracy: 0.7450 - loss: 0.7337\n",
      "19/19 - 0s - 3ms/step\n",
      "| \u001b[39m9        \u001b[39m | \u001b[39m0.7416   \u001b[39m | \u001b[39m4.705    \u001b[39m | \u001b[39m185.5    \u001b[39m | \u001b[39m0.02542  \u001b[39m | \u001b[39m0.3216   \u001b[39m | \u001b[39m10.94    \u001b[39m | \u001b[39m2.273    \u001b[39m | \u001b[39m1.314    \u001b[39m | \u001b[39m1.509    \u001b[39m | \u001b[39m0.9077   \u001b[39m | \u001b[39m32.44    \u001b[39m | \u001b[39m0.4104   \u001b[39m | \u001b[39m5.289    \u001b[39m |\n",
      "Epoch 1/38\n",
      "120/120 - 1s - 5ms/step - accuracy: 0.4861 - loss: 1.8709\n",
      "Epoch 2/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6440 - loss: 1.2643\n",
      "Epoch 3/38\n",
      "120/120 - 0s - 3ms/step - accuracy: 0.6440 - loss: 1.1701\n",
      "Epoch 4/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6440 - loss: 1.1281\n",
      "Epoch 5/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6440 - loss: 1.1041\n",
      "Epoch 6/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6440 - loss: 1.0875\n",
      "Epoch 7/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6438 - loss: 1.0744\n",
      "Epoch 8/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6442 - loss: 1.0641\n",
      "Epoch 9/38\n",
      "120/120 - 0s - 3ms/step - accuracy: 0.6450 - loss: 1.0552\n",
      "Epoch 10/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6466 - loss: 1.0489\n",
      "Epoch 11/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6474 - loss: 1.0426\n",
      "Epoch 12/38\n",
      "120/120 - 0s - 3ms/step - accuracy: 0.6486 - loss: 1.0368\n",
      "Epoch 13/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6507 - loss: 1.0323\n",
      "Epoch 14/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6522 - loss: 1.0280\n",
      "Epoch 15/38\n",
      "120/120 - 0s - 3ms/step - accuracy: 0.6538 - loss: 1.0229\n",
      "Epoch 16/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6552 - loss: 1.0201\n",
      "Epoch 17/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6572 - loss: 1.0158\n",
      "Epoch 18/38\n",
      "120/120 - 0s - 3ms/step - accuracy: 0.6581 - loss: 1.0114\n",
      "Epoch 19/38\n",
      "120/120 - 0s - 3ms/step - accuracy: 0.6594 - loss: 1.0092\n",
      "Epoch 20/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6612 - loss: 1.0054\n",
      "Epoch 21/38\n",
      "120/120 - 0s - 3ms/step - accuracy: 0.6594 - loss: 1.0027\n",
      "Epoch 22/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6603 - loss: 0.9991\n",
      "Epoch 23/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6622 - loss: 0.9960\n",
      "Epoch 24/38\n",
      "120/120 - 0s - 3ms/step - accuracy: 0.6624 - loss: 0.9921\n",
      "Epoch 25/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6633 - loss: 0.9894\n",
      "Epoch 26/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6634 - loss: 0.9869\n",
      "Epoch 27/38\n",
      "120/120 - 0s - 3ms/step - accuracy: 0.6646 - loss: 0.9830\n",
      "Epoch 28/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6662 - loss: 0.9797\n",
      "Epoch 29/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6686 - loss: 0.9771\n",
      "Epoch 30/38\n",
      "120/120 - 0s - 3ms/step - accuracy: 0.6674 - loss: 0.9732\n",
      "Epoch 31/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6681 - loss: 0.9711\n",
      "Epoch 32/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6693 - loss: 0.9677\n",
      "Epoch 33/38\n",
      "120/120 - 0s - 3ms/step - accuracy: 0.6712 - loss: 0.9639\n",
      "Epoch 34/38\n",
      "120/120 - 0s - 3ms/step - accuracy: 0.6715 - loss: 0.9604\n",
      "Epoch 35/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6724 - loss: 0.9583\n",
      "Epoch 36/38\n",
      "120/120 - 0s - 3ms/step - accuracy: 0.6744 - loss: 0.9547\n",
      "Epoch 37/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6756 - loss: 0.9518\n",
      "Epoch 38/38\n",
      "120/120 - 0s - 3ms/step - accuracy: 0.6771 - loss: 0.9492\n",
      "30/30 - 0s - 3ms/step\n",
      "Epoch 1/38\n",
      "120/120 - 1s - 5ms/step - accuracy: 0.4530 - loss: 1.7432\n",
      "Epoch 2/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6440 - loss: 1.2555\n",
      "Epoch 3/38\n",
      "120/120 - 0s - 3ms/step - accuracy: 0.6440 - loss: 1.1930\n",
      "Epoch 4/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6440 - loss: 1.1638\n",
      "Epoch 5/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6440 - loss: 1.1439\n",
      "Epoch 6/38\n",
      "120/120 - 0s - 3ms/step - accuracy: 0.6440 - loss: 1.1285\n",
      "Epoch 7/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6440 - loss: 1.1152\n",
      "Epoch 8/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6440 - loss: 1.1039\n",
      "Epoch 9/38\n",
      "120/120 - 0s - 3ms/step - accuracy: 0.6440 - loss: 1.0939\n",
      "Epoch 10/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6440 - loss: 1.0852\n",
      "Epoch 11/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6440 - loss: 1.0775\n",
      "Epoch 12/38\n",
      "120/120 - 0s - 3ms/step - accuracy: 0.6440 - loss: 1.0706\n",
      "Epoch 13/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6440 - loss: 1.0647\n",
      "Epoch 14/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6440 - loss: 1.0596\n",
      "Epoch 15/38\n",
      "120/120 - 0s - 3ms/step - accuracy: 0.6440 - loss: 1.0548\n",
      "Epoch 16/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6440 - loss: 1.0507\n",
      "Epoch 17/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6439 - loss: 1.0474\n",
      "Epoch 18/38\n",
      "120/120 - 0s - 3ms/step - accuracy: 0.6437 - loss: 1.0442\n",
      "Epoch 19/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6438 - loss: 1.0408\n",
      "Epoch 20/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6440 - loss: 1.0380\n",
      "Epoch 21/38\n",
      "120/120 - 0s - 3ms/step - accuracy: 0.6438 - loss: 1.0350\n",
      "Epoch 22/38\n",
      "120/120 - 0s - 3ms/step - accuracy: 0.6435 - loss: 1.0323\n",
      "Epoch 23/38\n",
      "120/120 - 0s - 3ms/step - accuracy: 0.6440 - loss: 1.0299\n",
      "Epoch 24/38\n",
      "120/120 - 0s - 3ms/step - accuracy: 0.6434 - loss: 1.0280\n",
      "Epoch 25/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6434 - loss: 1.0251\n",
      "Epoch 26/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6435 - loss: 1.0234\n",
      "Epoch 27/38\n",
      "120/120 - 0s - 3ms/step - accuracy: 0.6435 - loss: 1.0206\n",
      "Epoch 28/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6438 - loss: 1.0183\n",
      "Epoch 29/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6440 - loss: 1.0153\n",
      "Epoch 30/38\n",
      "120/120 - 0s - 3ms/step - accuracy: 0.6434 - loss: 1.0140\n",
      "Epoch 31/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6433 - loss: 1.0114\n",
      "Epoch 32/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6436 - loss: 1.0091\n",
      "Epoch 33/38\n",
      "120/120 - 0s - 3ms/step - accuracy: 0.6442 - loss: 1.0072\n",
      "Epoch 34/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6439 - loss: 1.0047\n",
      "Epoch 35/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6443 - loss: 1.0021\n",
      "Epoch 36/38\n",
      "120/120 - 0s - 3ms/step - accuracy: 0.6441 - loss: 0.9990\n",
      "Epoch 37/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6441 - loss: 0.9971\n",
      "Epoch 38/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6444 - loss: 0.9948\n",
      "30/30 - 0s - 3ms/step\n",
      "Epoch 1/38\n",
      "120/120 - 1s - 5ms/step - accuracy: 0.6224 - loss: 1.3901\n",
      "Epoch 2/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6439 - loss: 1.1431\n",
      "Epoch 3/38\n",
      "120/120 - 0s - 3ms/step - accuracy: 0.6439 - loss: 1.1045\n",
      "Epoch 4/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6439 - loss: 1.0810\n",
      "Epoch 5/38\n",
      "120/120 - 0s - 3ms/step - accuracy: 0.6439 - loss: 1.0641\n",
      "Epoch 6/38\n",
      "120/120 - 0s - 3ms/step - accuracy: 0.6439 - loss: 1.0515\n",
      "Epoch 7/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6439 - loss: 1.0416\n",
      "Epoch 8/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6440 - loss: 1.0336\n",
      "Epoch 9/38\n",
      "120/120 - 0s - 3ms/step - accuracy: 0.6447 - loss: 1.0274\n",
      "Epoch 10/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6457 - loss: 1.0214\n",
      "Epoch 11/38\n",
      "120/120 - 0s - 3ms/step - accuracy: 0.6463 - loss: 1.0159\n",
      "Epoch 12/38\n",
      "120/120 - 0s - 3ms/step - accuracy: 0.6490 - loss: 1.0113\n",
      "Epoch 13/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6508 - loss: 1.0072\n",
      "Epoch 14/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6496 - loss: 1.0024\n",
      "Epoch 15/38\n",
      "120/120 - 0s - 3ms/step - accuracy: 0.6511 - loss: 0.9992\n",
      "Epoch 16/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6521 - loss: 0.9962\n",
      "Epoch 17/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6537 - loss: 0.9920\n",
      "Epoch 18/38\n",
      "120/120 - 0s - 3ms/step - accuracy: 0.6545 - loss: 0.9887\n",
      "Epoch 19/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6563 - loss: 0.9845\n",
      "Epoch 20/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6554 - loss: 0.9822\n",
      "Epoch 21/38\n",
      "120/120 - 0s - 3ms/step - accuracy: 0.6581 - loss: 0.9775\n",
      "Epoch 22/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6577 - loss: 0.9740\n",
      "Epoch 23/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6588 - loss: 0.9702\n",
      "Epoch 24/38\n",
      "120/120 - 0s - 3ms/step - accuracy: 0.6603 - loss: 0.9664\n",
      "Epoch 25/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6611 - loss: 0.9633\n",
      "Epoch 26/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6608 - loss: 0.9608\n",
      "Epoch 27/38\n",
      "120/120 - 0s - 3ms/step - accuracy: 0.6622 - loss: 0.9563\n",
      "Epoch 28/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6623 - loss: 0.9526\n",
      "Epoch 29/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6645 - loss: 0.9484\n",
      "Epoch 30/38\n",
      "120/120 - 0s - 3ms/step - accuracy: 0.6668 - loss: 0.9444\n",
      "Epoch 31/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6684 - loss: 0.9410\n",
      "Epoch 32/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6700 - loss: 0.9382\n",
      "Epoch 33/38\n",
      "120/120 - 0s - 3ms/step - accuracy: 0.6697 - loss: 0.9343\n",
      "Epoch 34/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6719 - loss: 0.9306\n",
      "Epoch 35/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6748 - loss: 0.9265\n",
      "Epoch 36/38\n",
      "120/120 - 0s - 3ms/step - accuracy: 0.6751 - loss: 0.9242\n",
      "Epoch 37/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6777 - loss: 0.9199\n",
      "Epoch 38/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6799 - loss: 0.9158\n",
      "30/30 - 0s - 4ms/step\n",
      "Epoch 1/38\n",
      "120/120 - 1s - 5ms/step - accuracy: 0.3895 - loss: 2.1965\n",
      "Epoch 2/38\n",
      "120/120 - 0s - 3ms/step - accuracy: 0.6440 - loss: 1.2940\n",
      "Epoch 3/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6440 - loss: 1.1895\n",
      "Epoch 4/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6440 - loss: 1.1534\n",
      "Epoch 5/38\n",
      "120/120 - 0s - 3ms/step - accuracy: 0.6440 - loss: 1.1314\n",
      "Epoch 6/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6441 - loss: 1.1151\n",
      "Epoch 7/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6452 - loss: 1.1024\n",
      "Epoch 8/38\n",
      "120/120 - 0s - 3ms/step - accuracy: 0.6466 - loss: 1.0913\n",
      "Epoch 9/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6484 - loss: 1.0813\n",
      "Epoch 10/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6515 - loss: 1.0732\n",
      "Epoch 11/38\n",
      "120/120 - 0s - 4ms/step - accuracy: 0.6527 - loss: 1.0656\n",
      "Epoch 12/38\n",
      "120/120 - 0s - 3ms/step - accuracy: 0.6541 - loss: 1.0592\n",
      "Epoch 13/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6572 - loss: 1.0535\n",
      "Epoch 14/38\n",
      "120/120 - 0s - 3ms/step - accuracy: 0.6586 - loss: 1.0469\n",
      "Epoch 15/38\n",
      "120/120 - 0s - 3ms/step - accuracy: 0.6593 - loss: 1.0421\n",
      "Epoch 16/38\n",
      "120/120 - 0s - 3ms/step - accuracy: 0.6614 - loss: 1.0366\n",
      "Epoch 17/38\n",
      "120/120 - 0s - 3ms/step - accuracy: 0.6611 - loss: 1.0316\n",
      "Epoch 18/38\n",
      "120/120 - 0s - 3ms/step - accuracy: 0.6622 - loss: 1.0273\n",
      "Epoch 19/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6630 - loss: 1.0220\n",
      "Epoch 20/38\n",
      "120/120 - 0s - 3ms/step - accuracy: 0.6645 - loss: 1.0171\n",
      "Epoch 21/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6661 - loss: 1.0124\n",
      "Epoch 22/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6670 - loss: 1.0074\n",
      "Epoch 23/38\n",
      "120/120 - 0s - 4ms/step - accuracy: 0.6691 - loss: 1.0026\n",
      "Epoch 24/38\n",
      "120/120 - 0s - 3ms/step - accuracy: 0.6704 - loss: 0.9982\n",
      "Epoch 25/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6702 - loss: 0.9932\n",
      "Epoch 26/38\n",
      "120/120 - 0s - 3ms/step - accuracy: 0.6722 - loss: 0.9885\n",
      "Epoch 27/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6731 - loss: 0.9835\n",
      "Epoch 28/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6752 - loss: 0.9783\n",
      "Epoch 29/38\n",
      "120/120 - 0s - 3ms/step - accuracy: 0.6755 - loss: 0.9733\n",
      "Epoch 30/38\n",
      "120/120 - 0s - 3ms/step - accuracy: 0.6773 - loss: 0.9682\n",
      "Epoch 31/38\n",
      "120/120 - 0s - 3ms/step - accuracy: 0.6757 - loss: 0.9631\n",
      "Epoch 32/38\n",
      "120/120 - 0s - 3ms/step - accuracy: 0.6787 - loss: 0.9568\n",
      "Epoch 33/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6791 - loss: 0.9509\n",
      "Epoch 34/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6804 - loss: 0.9454\n",
      "Epoch 35/38\n",
      "120/120 - 0s - 3ms/step - accuracy: 0.6810 - loss: 0.9399\n",
      "Epoch 36/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6828 - loss: 0.9338\n",
      "Epoch 37/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6837 - loss: 0.9281\n",
      "Epoch 38/38\n",
      "120/120 - 0s - 3ms/step - accuracy: 0.6842 - loss: 0.9222\n",
      "30/30 - 0s - 6ms/step\n",
      "Epoch 1/38\n",
      "120/120 - 1s - 6ms/step - accuracy: 0.2956 - loss: 2.4425\n",
      "Epoch 2/38\n",
      "120/120 - 0s - 3ms/step - accuracy: 0.6436 - loss: 1.2926\n",
      "Epoch 3/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6438 - loss: 1.1848\n",
      "Epoch 4/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6438 - loss: 1.1494\n",
      "Epoch 5/38\n",
      "120/120 - 0s - 3ms/step - accuracy: 0.6439 - loss: 1.1290\n",
      "Epoch 6/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6439 - loss: 1.1144\n",
      "Epoch 7/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6439 - loss: 1.1030\n",
      "Epoch 8/38\n",
      "120/120 - 0s - 3ms/step - accuracy: 0.6439 - loss: 1.0940\n",
      "Epoch 9/38\n",
      "120/120 - 0s - 3ms/step - accuracy: 0.6439 - loss: 1.0859\n",
      "Epoch 10/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6439 - loss: 1.0790\n",
      "Epoch 11/38\n",
      "120/120 - 0s - 3ms/step - accuracy: 0.6439 - loss: 1.0737\n",
      "Epoch 12/38\n",
      "120/120 - 0s - 3ms/step - accuracy: 0.6439 - loss: 1.0686\n",
      "Epoch 13/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6439 - loss: 1.0641\n",
      "Epoch 14/38\n",
      "120/120 - 0s - 3ms/step - accuracy: 0.6439 - loss: 1.0597\n",
      "Epoch 15/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6439 - loss: 1.0550\n",
      "Epoch 16/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6440 - loss: 1.0521\n",
      "Epoch 17/38\n",
      "120/120 - 0s - 4ms/step - accuracy: 0.6442 - loss: 1.0488\n",
      "Epoch 18/38\n",
      "120/120 - 0s - 3ms/step - accuracy: 0.6446 - loss: 1.0456\n",
      "Epoch 19/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6455 - loss: 1.0430\n",
      "Epoch 20/38\n",
      "120/120 - 0s - 3ms/step - accuracy: 0.6463 - loss: 1.0399\n",
      "Epoch 21/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6477 - loss: 1.0378\n",
      "Epoch 22/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6497 - loss: 1.0352\n",
      "Epoch 23/38\n",
      "120/120 - 0s - 3ms/step - accuracy: 0.6506 - loss: 1.0323\n",
      "Epoch 24/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6528 - loss: 1.0297\n",
      "Epoch 25/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6580 - loss: 1.0271\n",
      "Epoch 26/38\n",
      "120/120 - 0s - 3ms/step - accuracy: 0.6566 - loss: 1.0249\n",
      "Epoch 27/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6598 - loss: 1.0225\n",
      "Epoch 28/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6598 - loss: 1.0206\n",
      "Epoch 29/38\n",
      "120/120 - 0s - 3ms/step - accuracy: 0.6624 - loss: 1.0181\n",
      "Epoch 30/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6628 - loss: 1.0159\n",
      "Epoch 31/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6661 - loss: 1.0139\n",
      "Epoch 32/38\n",
      "120/120 - 0s - 3ms/step - accuracy: 0.6653 - loss: 1.0104\n",
      "Epoch 33/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6675 - loss: 1.0079\n",
      "Epoch 34/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6689 - loss: 1.0058\n",
      "Epoch 35/38\n",
      "120/120 - 0s - 3ms/step - accuracy: 0.6702 - loss: 1.0044\n",
      "Epoch 36/38\n",
      "120/120 - 0s - 3ms/step - accuracy: 0.6706 - loss: 1.0011\n",
      "Epoch 37/38\n",
      "120/120 - 0s - 2ms/step - accuracy: 0.6718 - loss: 0.9991\n",
      "Epoch 38/38\n",
      "120/120 - 0s - 3ms/step - accuracy: 0.6736 - loss: 0.9962\n",
      "30/30 - 0s - 3ms/step\n",
      "| \u001b[39m10       \u001b[39m | \u001b[39m0.6725   \u001b[39m | \u001b[39m2.059    \u001b[39m | \u001b[39m115.4    \u001b[39m | \u001b[39m0.2898   \u001b[39m | \u001b[39m0.3322   \u001b[39m | \u001b[39m37.89    \u001b[39m | \u001b[39m2.616    \u001b[39m | \u001b[39m1.633    \u001b[39m | \u001b[39m1.871    \u001b[39m | \u001b[39m0.8039   \u001b[39m | \u001b[39m26.79    \u001b[39m | \u001b[39m0.8926   \u001b[39m | \u001b[39m3.775    \u001b[39m |\n",
      "Epoch 1/17\n",
      "50/50 - 1s - 15ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 2/17\n",
      "50/50 - 0s - 9ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 3/17\n",
      "50/50 - 0s - 8ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 4/17\n",
      "50/50 - 0s - 8ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 5/17\n",
      "50/50 - 0s - 9ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 6/17\n",
      "50/50 - 0s - 8ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 7/17\n",
      "50/50 - 0s - 8ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 8/17\n",
      "50/50 - 0s - 9ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 9/17\n",
      "50/50 - 0s - 9ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 10/17\n",
      "50/50 - 0s - 10ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 11/17\n",
      "50/50 - 0s - 9ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 12/17\n",
      "50/50 - 0s - 8ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 13/17\n",
      "50/50 - 0s - 9ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 14/17\n",
      "50/50 - 1s - 10ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 15/17\n",
      "50/50 - 0s - 9ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 16/17\n",
      "50/50 - 0s - 8ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 17/17\n",
      "50/50 - 0s - 9ms/step - accuracy: 0.6440 - loss: nan\n",
      "13/13 - 0s - 7ms/step\n",
      "Epoch 1/17\n",
      "50/50 - 1s - 14ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 2/17\n",
      "50/50 - 0s - 9ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 3/17\n",
      "50/50 - 0s - 8ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 4/17\n",
      "50/50 - 0s - 8ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 5/17\n",
      "50/50 - 0s - 9ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 6/17\n",
      "50/50 - 0s - 8ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 7/17\n",
      "50/50 - 0s - 8ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 8/17\n",
      "50/50 - 0s - 9ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 9/17\n",
      "50/50 - 0s - 8ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 10/17\n",
      "50/50 - 0s - 8ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 11/17\n",
      "50/50 - 0s - 9ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 12/17\n",
      "50/50 - 0s - 9ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 13/17\n",
      "50/50 - 0s - 8ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 14/17\n",
      "50/50 - 0s - 9ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 15/17\n",
      "50/50 - 0s - 8ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 16/17\n",
      "50/50 - 0s - 9ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 17/17\n",
      "50/50 - 0s - 9ms/step - accuracy: 0.6440 - loss: nan\n",
      "13/13 - 0s - 7ms/step\n",
      "Epoch 1/17\n",
      "50/50 - 1s - 14ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 2/17\n",
      "50/50 - 0s - 9ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 3/17\n",
      "50/50 - 0s - 8ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 4/17\n",
      "50/50 - 0s - 8ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 5/17\n",
      "50/50 - 0s - 9ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 6/17\n",
      "50/50 - 0s - 8ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 7/17\n",
      "50/50 - 0s - 8ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 8/17\n",
      "50/50 - 0s - 9ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 9/17\n",
      "50/50 - 0s - 8ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 10/17\n",
      "50/50 - 1s - 12ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 11/17\n",
      "50/50 - 0s - 8ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 12/17\n",
      "50/50 - 0s - 8ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 13/17\n",
      "50/50 - 0s - 9ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 14/17\n",
      "50/50 - 0s - 8ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 15/17\n",
      "50/50 - 0s - 8ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 16/17\n",
      "50/50 - 0s - 9ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 17/17\n",
      "50/50 - 0s - 8ms/step - accuracy: 0.6439 - loss: nan\n",
      "13/13 - 0s - 7ms/step\n",
      "Epoch 1/17\n",
      "50/50 - 1s - 15ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 2/17\n",
      "50/50 - 0s - 9ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 3/17\n",
      "50/50 - 0s - 9ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 4/17\n",
      "50/50 - 0s - 9ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 5/17\n",
      "50/50 - 0s - 9ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 6/17\n",
      "50/50 - 0s - 8ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 7/17\n",
      "50/50 - 0s - 9ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 8/17\n",
      "50/50 - 0s - 8ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 9/17\n",
      "50/50 - 0s - 8ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 10/17\n",
      "50/50 - 1s - 11ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 11/17\n",
      "50/50 - 1s - 10ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 12/17\n",
      "50/50 - 0s - 8ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 13/17\n",
      "50/50 - 0s - 9ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 14/17\n",
      "50/50 - 0s - 8ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 15/17\n",
      "50/50 - 0s - 9ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 16/17\n",
      "50/50 - 0s - 10ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 17/17\n",
      "50/50 - 0s - 8ms/step - accuracy: 0.6440 - loss: nan\n",
      "13/13 - 0s - 7ms/step\n",
      "Epoch 1/17\n",
      "50/50 - 1s - 16ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 2/17\n",
      "50/50 - 0s - 8ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 3/17\n",
      "50/50 - 0s - 8ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 4/17\n",
      "50/50 - 0s - 10ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 5/17\n",
      "50/50 - 0s - 9ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 6/17\n",
      "50/50 - 0s - 8ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 7/17\n",
      "50/50 - 0s - 9ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 8/17\n",
      "50/50 - 0s - 8ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 9/17\n",
      "50/50 - 0s - 8ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 10/17\n",
      "50/50 - 0s - 9ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 11/17\n",
      "50/50 - 0s - 8ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 12/17\n",
      "50/50 - 0s - 8ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 13/17\n",
      "50/50 - 0s - 10ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 14/17\n",
      "50/50 - 0s - 9ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 15/17\n",
      "50/50 - 0s - 8ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 16/17\n",
      "50/50 - 0s - 9ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 17/17\n",
      "50/50 - 0s - 8ms/step - accuracy: 0.6439 - loss: nan\n",
      "13/13 - 0s - 7ms/step\n",
      "| \u001b[39m11       \u001b[39m | \u001b[39m0.644    \u001b[39m | \u001b[39m7.267    \u001b[39m | \u001b[39m279.2    \u001b[39m | \u001b[39m0.318    \u001b[39m | \u001b[39m0.322    \u001b[39m | \u001b[39m16.84    \u001b[39m | \u001b[39m1.854    \u001b[39m | \u001b[39m1.818    \u001b[39m | \u001b[39m1.861    \u001b[39m | \u001b[39m0.007945 \u001b[39m | \u001b[39m55.97    \u001b[39m | \u001b[39m0.4174   \u001b[39m | \u001b[39m1.555    \u001b[39m |\n",
      "Epoch 1/26\n",
      "82/82 - 1s - 7ms/step - accuracy: 0.6283 - loss: 1.2504\n",
      "Epoch 2/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.6440 - loss: 1.1552\n",
      "Epoch 3/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.6440 - loss: 1.1055\n",
      "Epoch 4/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.6396 - loss: 1.0541\n",
      "Epoch 5/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.6381 - loss: 1.0311\n",
      "Epoch 6/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.6367 - loss: 1.0129\n",
      "Epoch 7/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.6388 - loss: 0.9965\n",
      "Epoch 8/26\n",
      "82/82 - 0s - 2ms/step - accuracy: 0.6384 - loss: 0.9813\n",
      "Epoch 9/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.6424 - loss: 0.9669\n",
      "Epoch 10/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.6438 - loss: 0.9516\n",
      "Epoch 11/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.6484 - loss: 0.9334\n",
      "Epoch 12/26\n",
      "82/82 - 0s - 2ms/step - accuracy: 0.6537 - loss: 0.9178\n",
      "Epoch 13/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.6621 - loss: 0.9046\n",
      "Epoch 14/26\n",
      "82/82 - 0s - 2ms/step - accuracy: 0.6728 - loss: 0.8907\n",
      "Epoch 15/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.6796 - loss: 0.8752\n",
      "Epoch 16/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.6893 - loss: 0.8612\n",
      "Epoch 17/26\n",
      "82/82 - 0s - 2ms/step - accuracy: 0.6963 - loss: 0.8454\n",
      "Epoch 18/26\n",
      "82/82 - 0s - 2ms/step - accuracy: 0.6982 - loss: 0.8324\n",
      "Epoch 19/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.7029 - loss: 0.8169\n",
      "Epoch 20/26\n",
      "82/82 - 0s - 2ms/step - accuracy: 0.7099 - loss: 0.7992\n",
      "Epoch 21/26\n",
      "82/82 - 0s - 2ms/step - accuracy: 0.7123 - loss: 0.7862\n",
      "Epoch 22/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.7144 - loss: 0.7720\n",
      "Epoch 23/26\n",
      "82/82 - 0s - 2ms/step - accuracy: 0.7203 - loss: 0.7575\n",
      "Epoch 24/26\n",
      "82/82 - 0s - 2ms/step - accuracy: 0.7269 - loss: 0.7475\n",
      "Epoch 25/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.7272 - loss: 0.7393\n",
      "Epoch 26/26\n",
      "82/82 - 0s - 2ms/step - accuracy: 0.7318 - loss: 0.7272\n",
      "21/21 - 0s - 3ms/step\n",
      "Epoch 1/26\n",
      "82/82 - 1s - 6ms/step - accuracy: 0.6343 - loss: 1.2135\n",
      "Epoch 2/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.6440 - loss: 1.1572\n",
      "Epoch 3/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.6440 - loss: 1.1187\n",
      "Epoch 4/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.6413 - loss: 1.0634\n",
      "Epoch 5/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.6409 - loss: 1.0337\n",
      "Epoch 6/26\n",
      "82/82 - 0s - 2ms/step - accuracy: 0.6369 - loss: 1.0173\n",
      "Epoch 7/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.6385 - loss: 1.0024\n",
      "Epoch 8/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.6387 - loss: 0.9869\n",
      "Epoch 9/26\n",
      "82/82 - 0s - 2ms/step - accuracy: 0.6354 - loss: 0.9706\n",
      "Epoch 10/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.6404 - loss: 0.9484\n",
      "Epoch 11/26\n",
      "82/82 - 0s - 2ms/step - accuracy: 0.6457 - loss: 0.9303\n",
      "Epoch 12/26\n",
      "82/82 - 0s - 2ms/step - accuracy: 0.6598 - loss: 0.9118\n",
      "Epoch 13/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.6703 - loss: 0.8910\n",
      "Epoch 14/26\n",
      "82/82 - 0s - 2ms/step - accuracy: 0.6796 - loss: 0.8745\n",
      "Epoch 15/26\n",
      "82/82 - 0s - 2ms/step - accuracy: 0.6884 - loss: 0.8558\n",
      "Epoch 16/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.6949 - loss: 0.8326\n",
      "Epoch 17/26\n",
      "82/82 - 0s - 2ms/step - accuracy: 0.7056 - loss: 0.8109\n",
      "Epoch 18/26\n",
      "82/82 - 0s - 2ms/step - accuracy: 0.7099 - loss: 0.7909\n",
      "Epoch 19/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.7140 - loss: 0.7756\n",
      "Epoch 20/26\n",
      "82/82 - 0s - 2ms/step - accuracy: 0.7239 - loss: 0.7619\n",
      "Epoch 21/26\n",
      "82/82 - 0s - 2ms/step - accuracy: 0.7246 - loss: 0.7488\n",
      "Epoch 22/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.7288 - loss: 0.7338\n",
      "Epoch 23/26\n",
      "82/82 - 0s - 2ms/step - accuracy: 0.7319 - loss: 0.7254\n",
      "Epoch 24/26\n",
      "82/82 - 0s - 2ms/step - accuracy: 0.7357 - loss: 0.7154\n",
      "Epoch 25/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.7385 - loss: 0.7082\n",
      "Epoch 26/26\n",
      "82/82 - 0s - 2ms/step - accuracy: 0.7428 - loss: 0.6987\n",
      "21/21 - 0s - 3ms/step\n",
      "Epoch 1/26\n",
      "82/82 - 1s - 6ms/step - accuracy: 0.6130 - loss: 1.2739\n",
      "Epoch 2/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.6439 - loss: 1.1284\n",
      "Epoch 3/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.6411 - loss: 1.0637\n",
      "Epoch 4/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.6362 - loss: 1.0369\n",
      "Epoch 5/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.6354 - loss: 1.0226\n",
      "Epoch 6/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.6367 - loss: 1.0037\n",
      "Epoch 7/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.6401 - loss: 0.9889\n",
      "Epoch 8/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.6423 - loss: 0.9738\n",
      "Epoch 9/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.6470 - loss: 0.9562\n",
      "Epoch 10/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.6468 - loss: 0.9424\n",
      "Epoch 11/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.6508 - loss: 0.9304\n",
      "Epoch 12/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.6521 - loss: 0.9158\n",
      "Epoch 13/26\n",
      "82/82 - 0s - 2ms/step - accuracy: 0.6638 - loss: 0.9017\n",
      "Epoch 14/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.6712 - loss: 0.8915\n",
      "Epoch 15/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.6781 - loss: 0.8754\n",
      "Epoch 16/26\n",
      "82/82 - 0s - 2ms/step - accuracy: 0.6855 - loss: 0.8627\n",
      "Epoch 17/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.6888 - loss: 0.8543\n",
      "Epoch 18/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.6991 - loss: 0.8371\n",
      "Epoch 19/26\n",
      "82/82 - 0s - 2ms/step - accuracy: 0.7007 - loss: 0.8280\n",
      "Epoch 20/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.7090 - loss: 0.8149\n",
      "Epoch 21/26\n",
      "82/82 - 0s - 2ms/step - accuracy: 0.7108 - loss: 0.8029\n",
      "Epoch 22/26\n",
      "82/82 - 0s - 2ms/step - accuracy: 0.7142 - loss: 0.7871\n",
      "Epoch 23/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.7200 - loss: 0.7753\n",
      "Epoch 24/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.7216 - loss: 0.7599\n",
      "Epoch 25/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.7262 - loss: 0.7491\n",
      "Epoch 26/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.7274 - loss: 0.7416\n",
      "21/21 - 0s - 3ms/step\n",
      "Epoch 1/26\n",
      "82/82 - 0s - 6ms/step - accuracy: 0.6293 - loss: 1.2206\n",
      "Epoch 2/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.6440 - loss: 1.1386\n",
      "Epoch 3/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.6425 - loss: 1.0706\n",
      "Epoch 4/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.6420 - loss: 1.0319\n",
      "Epoch 5/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.6380 - loss: 1.0107\n",
      "Epoch 6/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.6407 - loss: 0.9932\n",
      "Epoch 7/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.6460 - loss: 0.9716\n",
      "Epoch 8/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.6473 - loss: 0.9565\n",
      "Epoch 9/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.6464 - loss: 0.9411\n",
      "Epoch 10/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.6535 - loss: 0.9239\n",
      "Epoch 11/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.6626 - loss: 0.9061\n",
      "Epoch 12/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.6687 - loss: 0.8921\n",
      "Epoch 13/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.6798 - loss: 0.8730\n",
      "Epoch 14/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.6890 - loss: 0.8612\n",
      "Epoch 15/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.6999 - loss: 0.8463\n",
      "Epoch 16/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.7082 - loss: 0.8302\n",
      "Epoch 17/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.7131 - loss: 0.8196\n",
      "Epoch 18/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.7189 - loss: 0.8068\n",
      "Epoch 19/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.7241 - loss: 0.7964\n",
      "Epoch 20/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.7277 - loss: 0.7851\n",
      "Epoch 21/26\n",
      "82/82 - 0s - 2ms/step - accuracy: 0.7322 - loss: 0.7740\n",
      "Epoch 22/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.7354 - loss: 0.7673\n",
      "Epoch 23/26\n",
      "82/82 - 0s - 2ms/step - accuracy: 0.7412 - loss: 0.7553\n",
      "Epoch 24/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.7424 - loss: 0.7485\n",
      "Epoch 25/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.7459 - loss: 0.7359\n",
      "Epoch 26/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.7484 - loss: 0.7309\n",
      "21/21 - 0s - 3ms/step\n",
      "Epoch 1/26\n",
      "82/82 - 1s - 9ms/step - accuracy: 0.6382 - loss: 1.1948\n",
      "Epoch 2/26\n",
      "82/82 - 0s - 4ms/step - accuracy: 0.6439 - loss: 1.1360\n",
      "Epoch 3/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.6444 - loss: 1.0758\n",
      "Epoch 4/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.6354 - loss: 1.0470\n",
      "Epoch 5/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.6373 - loss: 1.0286\n",
      "Epoch 6/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.6357 - loss: 1.0135\n",
      "Epoch 7/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.6397 - loss: 0.9986\n",
      "Epoch 8/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.6405 - loss: 0.9835\n",
      "Epoch 9/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.6420 - loss: 0.9695\n",
      "Epoch 10/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.6488 - loss: 0.9561\n",
      "Epoch 11/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.6496 - loss: 0.9445\n",
      "Epoch 12/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.6548 - loss: 0.9266\n",
      "Epoch 13/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.6583 - loss: 0.9147\n",
      "Epoch 14/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.6686 - loss: 0.8998\n",
      "Epoch 15/26\n",
      "82/82 - 0s - 2ms/step - accuracy: 0.6785 - loss: 0.8821\n",
      "Epoch 16/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.6879 - loss: 0.8696\n",
      "Epoch 17/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.6914 - loss: 0.8587\n",
      "Epoch 18/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.7025 - loss: 0.8443\n",
      "Epoch 19/26\n",
      "82/82 - 0s - 2ms/step - accuracy: 0.7046 - loss: 0.8356\n",
      "Epoch 20/26\n",
      "82/82 - 0s - 4ms/step - accuracy: 0.7145 - loss: 0.8223\n",
      "Epoch 21/26\n",
      "82/82 - 0s - 2ms/step - accuracy: 0.7186 - loss: 0.8100\n",
      "Epoch 22/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.7244 - loss: 0.7951\n",
      "Epoch 23/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.7277 - loss: 0.7854\n",
      "Epoch 24/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.7286 - loss: 0.7729\n",
      "Epoch 25/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.7331 - loss: 0.7626\n",
      "Epoch 26/26\n",
      "82/82 - 0s - 3ms/step - accuracy: 0.7348 - loss: 0.7510\n",
      "21/21 - 0s - 3ms/step\n",
      "| \u001b[39m12       \u001b[39m | \u001b[39m0.7474   \u001b[39m | \u001b[39m1.079    \u001b[39m | \u001b[39m167.5    \u001b[39m | \u001b[39m0.9429   \u001b[39m | \u001b[39m0.3646   \u001b[39m | \u001b[39m25.56    \u001b[39m | \u001b[39m2.406    \u001b[39m | \u001b[39m1.364    \u001b[39m | \u001b[39m1.972    \u001b[39m | \u001b[39m0.9625   \u001b[39m | \u001b[39m32.66    \u001b[39m | \u001b[39m0.4972   \u001b[39m | \u001b[39m2.106    \u001b[39m |\n",
      "Epoch 1/12\n",
      "129/129 - 1s - 7ms/step - accuracy: 0.6754 - loss: 0.9903\n",
      "Epoch 2/12\n",
      "129/129 - 1s - 5ms/step - accuracy: 0.7522 - loss: 0.7375\n",
      "Epoch 3/12\n",
      "129/129 - 1s - 5ms/step - accuracy: 0.7694 - loss: 0.6712\n",
      "Epoch 4/12\n",
      "129/129 - 1s - 5ms/step - accuracy: 0.7820 - loss: 0.6248\n",
      "Epoch 5/12\n",
      "129/129 - 1s - 5ms/step - accuracy: 0.7969 - loss: 0.5842\n",
      "Epoch 6/12\n",
      "129/129 - 1s - 5ms/step - accuracy: 0.8043 - loss: 0.5606\n",
      "Epoch 7/12\n",
      "129/129 - 1s - 5ms/step - accuracy: 0.8115 - loss: 0.5370\n",
      "Epoch 8/12\n",
      "129/129 - 1s - 5ms/step - accuracy: 0.8202 - loss: 0.5067\n",
      "Epoch 9/12\n",
      "129/129 - 1s - 5ms/step - accuracy: 0.8302 - loss: 0.4846\n",
      "Epoch 10/12\n",
      "129/129 - 1s - 5ms/step - accuracy: 0.8383 - loss: 0.4635\n",
      "Epoch 11/12\n",
      "129/129 - 1s - 5ms/step - accuracy: 0.8416 - loss: 0.4487\n",
      "Epoch 12/12\n",
      "129/129 - 1s - 5ms/step - accuracy: 0.8506 - loss: 0.4283\n",
      "33/33 - 0s - 3ms/step\n",
      "Epoch 1/12\n",
      "129/129 - 1s - 6ms/step - accuracy: 0.6677 - loss: 1.0108\n",
      "Epoch 2/12\n",
      "129/129 - 1s - 5ms/step - accuracy: 0.7313 - loss: 0.7597\n",
      "Epoch 3/12\n",
      "129/129 - 1s - 5ms/step - accuracy: 0.7633 - loss: 0.6736\n",
      "Epoch 4/12\n",
      "129/129 - 1s - 5ms/step - accuracy: 0.7794 - loss: 0.6186\n",
      "Epoch 5/12\n",
      "129/129 - 1s - 5ms/step - accuracy: 0.7929 - loss: 0.5784\n",
      "Epoch 6/12\n",
      "129/129 - 1s - 5ms/step - accuracy: 0.8086 - loss: 0.5490\n",
      "Epoch 7/12\n",
      "129/129 - 1s - 5ms/step - accuracy: 0.8130 - loss: 0.5248\n",
      "Epoch 8/12\n",
      "129/129 - 1s - 5ms/step - accuracy: 0.8232 - loss: 0.5001\n",
      "Epoch 9/12\n",
      "129/129 - 1s - 5ms/step - accuracy: 0.8306 - loss: 0.4789\n",
      "Epoch 10/12\n",
      "129/129 - 1s - 5ms/step - accuracy: 0.8398 - loss: 0.4578\n",
      "Epoch 11/12\n",
      "129/129 - 1s - 5ms/step - accuracy: 0.8398 - loss: 0.4440\n",
      "Epoch 12/12\n",
      "129/129 - 1s - 5ms/step - accuracy: 0.8498 - loss: 0.4240\n",
      "33/33 - 0s - 3ms/step\n",
      "Epoch 1/12\n",
      "129/129 - 1s - 7ms/step - accuracy: 0.6753 - loss: 1.0000\n",
      "Epoch 2/12\n",
      "129/129 - 1s - 5ms/step - accuracy: 0.7395 - loss: 0.7618\n",
      "Epoch 3/12\n",
      "129/129 - 1s - 5ms/step - accuracy: 0.7656 - loss: 0.6827\n",
      "Epoch 4/12\n",
      "129/129 - 1s - 5ms/step - accuracy: 0.7803 - loss: 0.6352\n",
      "Epoch 5/12\n",
      "129/129 - 1s - 5ms/step - accuracy: 0.7912 - loss: 0.5942\n",
      "Epoch 6/12\n",
      "129/129 - 1s - 5ms/step - accuracy: 0.8058 - loss: 0.5654\n",
      "Epoch 7/12\n",
      "129/129 - 1s - 5ms/step - accuracy: 0.8131 - loss: 0.5383\n",
      "Epoch 8/12\n",
      "129/129 - 1s - 5ms/step - accuracy: 0.8257 - loss: 0.5084\n",
      "Epoch 9/12\n",
      "129/129 - 1s - 5ms/step - accuracy: 0.8312 - loss: 0.4882\n",
      "Epoch 10/12\n",
      "129/129 - 1s - 5ms/step - accuracy: 0.8346 - loss: 0.4762\n",
      "Epoch 11/12\n",
      "129/129 - 1s - 5ms/step - accuracy: 0.8447 - loss: 0.4537\n",
      "Epoch 12/12\n",
      "129/129 - 1s - 5ms/step - accuracy: 0.8474 - loss: 0.4375\n",
      "33/33 - 0s - 3ms/step\n",
      "Epoch 1/12\n",
      "129/129 - 1s - 7ms/step - accuracy: 0.6682 - loss: 1.0235\n",
      "Epoch 2/12\n",
      "129/129 - 1s - 5ms/step - accuracy: 0.7432 - loss: 0.7419\n",
      "Epoch 3/12\n",
      "129/129 - 1s - 4ms/step - accuracy: 0.7691 - loss: 0.6578\n",
      "Epoch 4/12\n",
      "129/129 - 1s - 5ms/step - accuracy: 0.7838 - loss: 0.6109\n",
      "Epoch 5/12\n",
      "129/129 - 1s - 4ms/step - accuracy: 0.7962 - loss: 0.5766\n",
      "Epoch 6/12\n",
      "129/129 - 1s - 5ms/step - accuracy: 0.8080 - loss: 0.5451\n",
      "Epoch 7/12\n",
      "129/129 - 1s - 5ms/step - accuracy: 0.8172 - loss: 0.5207\n",
      "Epoch 8/12\n",
      "129/129 - 1s - 5ms/step - accuracy: 0.8233 - loss: 0.5014\n",
      "Epoch 9/12\n",
      "129/129 - 1s - 4ms/step - accuracy: 0.8282 - loss: 0.4829\n",
      "Epoch 10/12\n",
      "129/129 - 1s - 5ms/step - accuracy: 0.8418 - loss: 0.4581\n",
      "Epoch 11/12\n",
      "129/129 - 1s - 4ms/step - accuracy: 0.8447 - loss: 0.4435\n",
      "Epoch 12/12\n",
      "129/129 - 1s - 5ms/step - accuracy: 0.8519 - loss: 0.4234\n",
      "33/33 - 0s - 3ms/step\n",
      "Epoch 1/12\n",
      "129/129 - 1s - 6ms/step - accuracy: 0.6773 - loss: 1.0093\n",
      "Epoch 2/12\n",
      "129/129 - 1s - 5ms/step - accuracy: 0.7402 - loss: 0.7544\n",
      "Epoch 3/12\n",
      "129/129 - 1s - 5ms/step - accuracy: 0.7635 - loss: 0.6745\n",
      "Epoch 4/12\n",
      "129/129 - 1s - 5ms/step - accuracy: 0.7836 - loss: 0.6249\n",
      "Epoch 5/12\n",
      "129/129 - 1s - 5ms/step - accuracy: 0.7951 - loss: 0.5862\n",
      "Epoch 6/12\n",
      "129/129 - 1s - 5ms/step - accuracy: 0.8050 - loss: 0.5586\n",
      "Epoch 7/12\n",
      "129/129 - 1s - 5ms/step - accuracy: 0.8115 - loss: 0.5366\n",
      "Epoch 8/12\n",
      "129/129 - 1s - 5ms/step - accuracy: 0.8211 - loss: 0.5127\n",
      "Epoch 9/12\n",
      "129/129 - 1s - 4ms/step - accuracy: 0.8292 - loss: 0.4911\n",
      "Epoch 10/12\n",
      "129/129 - 1s - 5ms/step - accuracy: 0.8304 - loss: 0.4777\n",
      "Epoch 11/12\n",
      "129/129 - 1s - 5ms/step - accuracy: 0.8367 - loss: 0.4591\n",
      "Epoch 12/12\n",
      "129/129 - 1s - 5ms/step - accuracy: 0.8424 - loss: 0.4467\n",
      "33/33 - 0s - 3ms/step\n",
      "| \u001b[39m13       \u001b[39m | \u001b[39m0.8227   \u001b[39m | \u001b[39m2.564    \u001b[39m | \u001b[39m107.4    \u001b[39m | \u001b[39m0.6096   \u001b[39m | \u001b[39m0.4005   \u001b[39m | \u001b[39m11.54    \u001b[39m | \u001b[39m1.557    \u001b[39m | \u001b[39m1.908    \u001b[39m | \u001b[39m1.24     \u001b[39m | \u001b[39m0.1457   \u001b[39m | \u001b[39m54.05    \u001b[39m | \u001b[39m0.9857   \u001b[39m | \u001b[39m1.694    \u001b[39m |\n",
      "Epoch 1/21\n",
      "55/55 - 2s - 27ms/step - accuracy: 0.6602 - loss: 1.0311\n",
      "Epoch 2/21\n",
      "55/55 - 1s - 17ms/step - accuracy: 0.7411 - loss: 0.7597\n",
      "Epoch 3/21\n",
      "55/55 - 1s - 16ms/step - accuracy: 0.7648 - loss: 0.6769\n",
      "Epoch 4/21\n",
      "55/55 - 1s - 17ms/step - accuracy: 0.7830 - loss: 0.6226\n",
      "Epoch 5/21\n",
      "55/55 - 1s - 16ms/step - accuracy: 0.7926 - loss: 0.5867\n",
      "Epoch 6/21\n",
      "55/55 - 1s - 18ms/step - accuracy: 0.8062 - loss: 0.5461\n",
      "Epoch 7/21\n",
      "55/55 - 1s - 16ms/step - accuracy: 0.8085 - loss: 0.5271\n",
      "Epoch 8/21\n",
      "55/55 - 1s - 16ms/step - accuracy: 0.8261 - loss: 0.4874\n",
      "Epoch 9/21\n",
      "55/55 - 1s - 16ms/step - accuracy: 0.8336 - loss: 0.4636\n",
      "Epoch 10/21\n",
      "55/55 - 1s - 16ms/step - accuracy: 0.8415 - loss: 0.4367\n",
      "Epoch 11/21\n",
      "55/55 - 1s - 16ms/step - accuracy: 0.8506 - loss: 0.4163\n",
      "Epoch 12/21\n",
      "55/55 - 1s - 16ms/step - accuracy: 0.8572 - loss: 0.3942\n",
      "Epoch 13/21\n",
      "55/55 - 1s - 16ms/step - accuracy: 0.8598 - loss: 0.3744\n",
      "Epoch 14/21\n",
      "55/55 - 1s - 16ms/step - accuracy: 0.8701 - loss: 0.3529\n",
      "Epoch 15/21\n",
      "55/55 - 1s - 16ms/step - accuracy: 0.8755 - loss: 0.3381\n",
      "Epoch 16/21\n",
      "55/55 - 1s - 17ms/step - accuracy: 0.8862 - loss: 0.3132\n",
      "Epoch 17/21\n",
      "55/55 - 1s - 16ms/step - accuracy: 0.8935 - loss: 0.2884\n",
      "Epoch 18/21\n",
      "55/55 - 1s - 18ms/step - accuracy: 0.8886 - loss: 0.3048\n",
      "Epoch 19/21\n",
      "55/55 - 1s - 16ms/step - accuracy: 0.9043 - loss: 0.2667\n",
      "Epoch 20/21\n",
      "55/55 - 1s - 17ms/step - accuracy: 0.9044 - loss: 0.2635\n",
      "Epoch 21/21\n",
      "55/55 - 1s - 17ms/step - accuracy: 0.9103 - loss: 0.2485\n",
      "14/14 - 0s - 10ms/step\n",
      "Epoch 1/21\n",
      "55/55 - 1s - 25ms/step - accuracy: 0.6716 - loss: 1.0005\n",
      "Epoch 2/21\n",
      "55/55 - 1s - 17ms/step - accuracy: 0.7496 - loss: 0.7401\n",
      "Epoch 3/21\n",
      "55/55 - 1s - 16ms/step - accuracy: 0.7742 - loss: 0.6578\n",
      "Epoch 4/21\n",
      "55/55 - 1s - 17ms/step - accuracy: 0.7898 - loss: 0.6084\n",
      "Epoch 5/21\n",
      "55/55 - 1s - 17ms/step - accuracy: 0.7963 - loss: 0.5718\n",
      "Epoch 6/21\n",
      "55/55 - 1s - 17ms/step - accuracy: 0.8037 - loss: 0.5410\n",
      "Epoch 7/21\n",
      "55/55 - 1s - 16ms/step - accuracy: 0.8099 - loss: 0.5136\n",
      "Epoch 8/21\n",
      "55/55 - 1s - 16ms/step - accuracy: 0.8221 - loss: 0.4886\n",
      "Epoch 9/21\n",
      "55/55 - 1s - 16ms/step - accuracy: 0.8294 - loss: 0.4601\n",
      "Epoch 10/21\n",
      "55/55 - 1s - 17ms/step - accuracy: 0.8363 - loss: 0.4427\n",
      "Epoch 11/21\n",
      "55/55 - 1s - 16ms/step - accuracy: 0.8442 - loss: 0.4156\n",
      "Epoch 12/21\n",
      "55/55 - 1s - 17ms/step - accuracy: 0.8476 - loss: 0.4089\n",
      "Epoch 13/21\n",
      "55/55 - 1s - 16ms/step - accuracy: 0.8589 - loss: 0.3766\n",
      "Epoch 14/21\n",
      "55/55 - 1s - 17ms/step - accuracy: 0.8701 - loss: 0.3554\n",
      "Epoch 15/21\n",
      "55/55 - 1s - 16ms/step - accuracy: 0.8766 - loss: 0.3292\n",
      "Epoch 16/21\n",
      "55/55 - 1s - 16ms/step - accuracy: 0.8744 - loss: 0.3365\n",
      "Epoch 17/21\n",
      "55/55 - 1s - 16ms/step - accuracy: 0.8847 - loss: 0.3035\n",
      "Epoch 18/21\n",
      "55/55 - 1s - 17ms/step - accuracy: 0.8822 - loss: 0.3094\n",
      "Epoch 19/21\n",
      "55/55 - 1s - 16ms/step - accuracy: 0.8963 - loss: 0.2790\n",
      "Epoch 20/21\n",
      "55/55 - 1s - 17ms/step - accuracy: 0.9031 - loss: 0.2615\n",
      "Epoch 21/21\n",
      "55/55 - 1s - 16ms/step - accuracy: 0.9105 - loss: 0.2397\n",
      "14/14 - 0s - 10ms/step\n",
      "Epoch 1/21\n",
      "55/55 - 1s - 24ms/step - accuracy: 0.6517 - loss: 1.0957\n",
      "Epoch 2/21\n",
      "55/55 - 1s - 16ms/step - accuracy: 0.7439 - loss: 0.7558\n",
      "Epoch 3/21\n",
      "55/55 - 1s - 16ms/step - accuracy: 0.7709 - loss: 0.6726\n",
      "Epoch 4/21\n",
      "55/55 - 1s - 16ms/step - accuracy: 0.7855 - loss: 0.6260\n",
      "Epoch 5/21\n",
      "55/55 - 1s - 16ms/step - accuracy: 0.7953 - loss: 0.5825\n",
      "Epoch 6/21\n",
      "55/55 - 1s - 19ms/step - accuracy: 0.8021 - loss: 0.5562\n",
      "Epoch 7/21\n",
      "55/55 - 1s - 16ms/step - accuracy: 0.8168 - loss: 0.5191\n",
      "Epoch 8/21\n",
      "55/55 - 1s - 17ms/step - accuracy: 0.8245 - loss: 0.4915\n",
      "Epoch 9/21\n",
      "55/55 - 1s - 16ms/step - accuracy: 0.8322 - loss: 0.4682\n",
      "Epoch 10/21\n",
      "55/55 - 1s - 17ms/step - accuracy: 0.8401 - loss: 0.4442\n",
      "Epoch 11/21\n",
      "55/55 - 1s - 16ms/step - accuracy: 0.8458 - loss: 0.4231\n",
      "Epoch 12/21\n",
      "55/55 - 1s - 17ms/step - accuracy: 0.8548 - loss: 0.3983\n",
      "Epoch 13/21\n",
      "55/55 - 1s - 16ms/step - accuracy: 0.8558 - loss: 0.3897\n",
      "Epoch 14/21\n",
      "55/55 - 1s - 18ms/step - accuracy: 0.8675 - loss: 0.3591\n",
      "Epoch 15/21\n",
      "55/55 - 1s - 16ms/step - accuracy: 0.8679 - loss: 0.3570\n",
      "Epoch 16/21\n",
      "55/55 - 1s - 17ms/step - accuracy: 0.8790 - loss: 0.3332\n",
      "Epoch 17/21\n",
      "55/55 - 1s - 16ms/step - accuracy: 0.8747 - loss: 0.3327\n",
      "Epoch 18/21\n",
      "55/55 - 1s - 17ms/step - accuracy: 0.8850 - loss: 0.3086\n",
      "Epoch 19/21\n",
      "55/55 - 1s - 16ms/step - accuracy: 0.8905 - loss: 0.2916\n",
      "Epoch 20/21\n",
      "55/55 - 1s - 17ms/step - accuracy: 0.8951 - loss: 0.2863\n",
      "Epoch 21/21\n",
      "55/55 - 1s - 16ms/step - accuracy: 0.8962 - loss: 0.2710\n",
      "14/14 - 0s - 10ms/step\n",
      "Epoch 1/21\n",
      "55/55 - 2s - 38ms/step - accuracy: 0.6610 - loss: 1.0106\n",
      "Epoch 2/21\n",
      "55/55 - 1s - 18ms/step - accuracy: 0.7430 - loss: 0.7387\n",
      "Epoch 3/21\n",
      "55/55 - 1s - 17ms/step - accuracy: 0.7764 - loss: 0.6513\n",
      "Epoch 4/21\n",
      "55/55 - 1s - 19ms/step - accuracy: 0.7846 - loss: 0.6107\n",
      "Epoch 5/21\n",
      "55/55 - 1s - 17ms/step - accuracy: 0.8006 - loss: 0.5696\n",
      "Epoch 6/21\n",
      "55/55 - 1s - 17ms/step - accuracy: 0.8044 - loss: 0.5418\n",
      "Epoch 7/21\n",
      "55/55 - 1s - 16ms/step - accuracy: 0.8165 - loss: 0.5080\n",
      "Epoch 8/21\n",
      "55/55 - 1s - 17ms/step - accuracy: 0.8250 - loss: 0.4850\n",
      "Epoch 9/21\n",
      "55/55 - 1s - 16ms/step - accuracy: 0.8381 - loss: 0.4431\n",
      "Epoch 10/21\n",
      "55/55 - 1s - 16ms/step - accuracy: 0.8464 - loss: 0.4180\n",
      "Epoch 11/21\n",
      "55/55 - 1s - 16ms/step - accuracy: 0.8588 - loss: 0.3889\n",
      "Epoch 12/21\n",
      "55/55 - 1s - 17ms/step - accuracy: 0.8593 - loss: 0.3754\n",
      "Epoch 13/21\n",
      "55/55 - 1s - 16ms/step - accuracy: 0.8735 - loss: 0.3441\n",
      "Epoch 14/21\n",
      "55/55 - 1s - 16ms/step - accuracy: 0.8755 - loss: 0.3326\n",
      "Epoch 15/21\n",
      "55/55 - 1s - 16ms/step - accuracy: 0.8847 - loss: 0.3053\n",
      "Epoch 16/21\n",
      "55/55 - 1s - 17ms/step - accuracy: 0.8879 - loss: 0.3026\n",
      "Epoch 17/21\n",
      "55/55 - 1s - 16ms/step - accuracy: 0.8980 - loss: 0.2781\n",
      "Epoch 18/21\n",
      "55/55 - 1s - 16ms/step - accuracy: 0.9058 - loss: 0.2581\n",
      "Epoch 19/21\n",
      "55/55 - 1s - 16ms/step - accuracy: 0.9051 - loss: 0.2526\n",
      "Epoch 20/21\n",
      "55/55 - 1s - 16ms/step - accuracy: 0.9126 - loss: 0.2397\n",
      "Epoch 21/21\n",
      "55/55 - 1s - 16ms/step - accuracy: 0.9190 - loss: 0.2245\n",
      "14/14 - 0s - 10ms/step\n",
      "Epoch 1/21\n",
      "55/55 - 1s - 26ms/step - accuracy: 0.6948 - loss: 0.9336\n",
      "Epoch 2/21\n",
      "55/55 - 1s - 16ms/step - accuracy: 0.7572 - loss: 0.7108\n",
      "Epoch 3/21\n",
      "55/55 - 1s - 16ms/step - accuracy: 0.7700 - loss: 0.6535\n",
      "Epoch 4/21\n",
      "55/55 - 1s - 17ms/step - accuracy: 0.7864 - loss: 0.5996\n",
      "Epoch 5/21\n",
      "55/55 - 1s - 16ms/step - accuracy: 0.8007 - loss: 0.5575\n",
      "Epoch 6/21\n",
      "55/55 - 1s - 17ms/step - accuracy: 0.8098 - loss: 0.5250\n",
      "Epoch 7/21\n",
      "55/55 - 1s - 16ms/step - accuracy: 0.8187 - loss: 0.4996\n",
      "Epoch 8/21\n",
      "55/55 - 1s - 17ms/step - accuracy: 0.8245 - loss: 0.4782\n",
      "Epoch 9/21\n",
      "55/55 - 1s - 16ms/step - accuracy: 0.8372 - loss: 0.4466\n",
      "Epoch 10/21\n",
      "55/55 - 1s - 16ms/step - accuracy: 0.8441 - loss: 0.4273\n",
      "Epoch 11/21\n",
      "55/55 - 1s - 17ms/step - accuracy: 0.8547 - loss: 0.4025\n",
      "Epoch 12/21\n",
      "55/55 - 1s - 17ms/step - accuracy: 0.8617 - loss: 0.3806\n",
      "Epoch 13/21\n",
      "55/55 - 1s - 17ms/step - accuracy: 0.8576 - loss: 0.3800\n",
      "Epoch 14/21\n",
      "55/55 - 1s - 16ms/step - accuracy: 0.8641 - loss: 0.3671\n",
      "Epoch 15/21\n",
      "55/55 - 1s - 16ms/step - accuracy: 0.8757 - loss: 0.3317\n",
      "Epoch 16/21\n",
      "55/55 - 1s - 17ms/step - accuracy: 0.8856 - loss: 0.3096\n",
      "Epoch 17/21\n",
      "55/55 - 1s - 16ms/step - accuracy: 0.8850 - loss: 0.3062\n",
      "Epoch 18/21\n",
      "55/55 - 1s - 17ms/step - accuracy: 0.8950 - loss: 0.2825\n",
      "Epoch 19/21\n",
      "55/55 - 1s - 17ms/step - accuracy: 0.9036 - loss: 0.2653\n",
      "Epoch 20/21\n",
      "55/55 - 1s - 16ms/step - accuracy: 0.8955 - loss: 0.2789\n",
      "Epoch 21/21\n",
      "55/55 - 1s - 16ms/step - accuracy: 0.9060 - loss: 0.2496\n",
      "14/14 - 0s - 10ms/step\n",
      "| \u001b[39m14       \u001b[39m | \u001b[39m0.8738   \u001b[39m | \u001b[39m6.049    \u001b[39m | \u001b[39m252.3    \u001b[39m | \u001b[39m0.2376   \u001b[39m | \u001b[39m0.4456   \u001b[39m | \u001b[39m21.03    \u001b[39m | \u001b[39m2.265    \u001b[39m | \u001b[39m1.634    \u001b[39m | \u001b[39m1.536    \u001b[39m | \u001b[39m0.0912   \u001b[39m | \u001b[39m85.18    \u001b[39m | \u001b[39m0.3208   \u001b[39m | \u001b[39m1.306    \u001b[39m |\n",
      "Epoch 1/25\n",
      "64/64 - 1s - 14ms/step - accuracy: 0.6080 - loss: 1.1906\n",
      "Epoch 2/25\n",
      "64/64 - 0s - 7ms/step - accuracy: 0.6858 - loss: 0.8824\n",
      "Epoch 3/25\n",
      "64/64 - 0s - 6ms/step - accuracy: 0.7112 - loss: 0.8101\n",
      "Epoch 4/25\n",
      "64/64 - 0s - 6ms/step - accuracy: 0.7311 - loss: 0.7511\n",
      "Epoch 5/25\n",
      "64/64 - 0s - 5ms/step - accuracy: 0.7467 - loss: 0.6985\n",
      "Epoch 6/25\n",
      "64/64 - 0s - 6ms/step - accuracy: 0.7699 - loss: 0.6447\n",
      "Epoch 7/25\n",
      "64/64 - 0s - 5ms/step - accuracy: 0.7810 - loss: 0.6007\n",
      "Epoch 8/25\n",
      "64/64 - 0s - 6ms/step - accuracy: 0.7965 - loss: 0.5631\n",
      "Epoch 9/25\n",
      "64/64 - 0s - 5ms/step - accuracy: 0.8080 - loss: 0.5333\n",
      "Epoch 10/25\n",
      "64/64 - 0s - 6ms/step - accuracy: 0.8206 - loss: 0.4971\n",
      "Epoch 11/25\n",
      "64/64 - 0s - 5ms/step - accuracy: 0.8313 - loss: 0.4707\n",
      "Epoch 12/25\n",
      "64/64 - 0s - 6ms/step - accuracy: 0.8473 - loss: 0.4347\n",
      "Epoch 13/25\n",
      "64/64 - 0s - 5ms/step - accuracy: 0.8536 - loss: 0.4153\n",
      "Epoch 14/25\n",
      "64/64 - 0s - 6ms/step - accuracy: 0.8611 - loss: 0.4005\n",
      "Epoch 15/25\n",
      "64/64 - 0s - 5ms/step - accuracy: 0.8701 - loss: 0.3778\n",
      "Epoch 16/25\n",
      "64/64 - 0s - 6ms/step - accuracy: 0.8752 - loss: 0.3565\n",
      "Epoch 17/25\n",
      "64/64 - 0s - 5ms/step - accuracy: 0.8855 - loss: 0.3429\n",
      "Epoch 18/25\n",
      "64/64 - 0s - 6ms/step - accuracy: 0.8835 - loss: 0.3409\n",
      "Epoch 19/25\n",
      "64/64 - 0s - 5ms/step - accuracy: 0.8872 - loss: 0.3237\n",
      "Epoch 20/25\n",
      "64/64 - 0s - 6ms/step - accuracy: 0.8913 - loss: 0.3265\n",
      "Epoch 21/25\n",
      "64/64 - 0s - 5ms/step - accuracy: 0.9014 - loss: 0.2920\n",
      "Epoch 22/25\n",
      "64/64 - 0s - 6ms/step - accuracy: 0.9006 - loss: 0.2802\n",
      "Epoch 23/25\n",
      "64/64 - 0s - 5ms/step - accuracy: 0.9113 - loss: 0.2583\n",
      "Epoch 24/25\n",
      "64/64 - 0s - 6ms/step - accuracy: 0.9103 - loss: 0.2574\n",
      "Epoch 25/25\n",
      "64/64 - 0s - 5ms/step - accuracy: 0.9121 - loss: 0.2573\n",
      "16/16 - 0s - 5ms/step\n",
      "Epoch 1/25\n",
      "64/64 - 1s - 13ms/step - accuracy: 0.6344 - loss: 1.1817\n",
      "Epoch 2/25\n",
      "64/64 - 0s - 6ms/step - accuracy: 0.6895 - loss: 0.9053\n",
      "Epoch 3/25\n",
      "64/64 - 0s - 6ms/step - accuracy: 0.7178 - loss: 0.8072\n",
      "Epoch 4/25\n",
      "64/64 - 0s - 6ms/step - accuracy: 0.7353 - loss: 0.7450\n",
      "Epoch 5/25\n",
      "64/64 - 0s - 5ms/step - accuracy: 0.7539 - loss: 0.6969\n",
      "Epoch 6/25\n",
      "64/64 - 0s - 6ms/step - accuracy: 0.7724 - loss: 0.6466\n",
      "Epoch 7/25\n",
      "64/64 - 0s - 5ms/step - accuracy: 0.7871 - loss: 0.5980\n",
      "Epoch 8/25\n",
      "64/64 - 0s - 6ms/step - accuracy: 0.7987 - loss: 0.5666\n",
      "Epoch 9/25\n",
      "64/64 - 0s - 5ms/step - accuracy: 0.8135 - loss: 0.5244\n",
      "Epoch 10/25\n",
      "64/64 - 0s - 6ms/step - accuracy: 0.8261 - loss: 0.4930\n",
      "Epoch 11/25\n",
      "64/64 - 0s - 5ms/step - accuracy: 0.8343 - loss: 0.4687\n",
      "Epoch 12/25\n",
      "64/64 - 0s - 5ms/step - accuracy: 0.8446 - loss: 0.4439\n",
      "Epoch 13/25\n",
      "64/64 - 0s - 5ms/step - accuracy: 0.8523 - loss: 0.4221\n",
      "Epoch 14/25\n",
      "64/64 - 0s - 5ms/step - accuracy: 0.8555 - loss: 0.4122\n",
      "Epoch 15/25\n",
      "64/64 - 0s - 5ms/step - accuracy: 0.8649 - loss: 0.3914\n",
      "Epoch 16/25\n",
      "64/64 - 0s - 6ms/step - accuracy: 0.8677 - loss: 0.3845\n",
      "Epoch 17/25\n",
      "64/64 - 0s - 5ms/step - accuracy: 0.8741 - loss: 0.3774\n",
      "Epoch 18/25\n",
      "64/64 - 0s - 5ms/step - accuracy: 0.8804 - loss: 0.3492\n",
      "Epoch 19/25\n",
      "64/64 - 0s - 5ms/step - accuracy: 0.8852 - loss: 0.3533\n",
      "Epoch 20/25\n",
      "64/64 - 0s - 5ms/step - accuracy: 0.8850 - loss: 0.3336\n",
      "Epoch 21/25\n",
      "64/64 - 0s - 5ms/step - accuracy: 0.8911 - loss: 0.3263\n",
      "Epoch 22/25\n",
      "64/64 - 0s - 6ms/step - accuracy: 0.8880 - loss: 0.3301\n",
      "Epoch 23/25\n",
      "64/64 - 0s - 5ms/step - accuracy: 0.8920 - loss: 0.3209\n",
      "Epoch 24/25\n",
      "64/64 - 0s - 6ms/step - accuracy: 0.8979 - loss: 0.3070\n",
      "Epoch 25/25\n",
      "64/64 - 0s - 5ms/step - accuracy: 0.8940 - loss: 0.3161\n",
      "16/16 - 0s - 5ms/step\n",
      "Epoch 1/25\n",
      "64/64 - 1s - 13ms/step - accuracy: 0.6080 - loss: 1.1869\n",
      "Epoch 2/25\n",
      "64/64 - 0s - 5ms/step - accuracy: 0.6902 - loss: 0.8642\n",
      "Epoch 3/25\n",
      "64/64 - 0s - 5ms/step - accuracy: 0.7161 - loss: 0.7987\n",
      "Epoch 4/25\n",
      "64/64 - 0s - 5ms/step - accuracy: 0.7312 - loss: 0.7539\n",
      "Epoch 5/25\n",
      "64/64 - 0s - 5ms/step - accuracy: 0.7460 - loss: 0.7107\n",
      "Epoch 6/25\n",
      "64/64 - 0s - 6ms/step - accuracy: 0.7697 - loss: 0.6466\n",
      "Epoch 7/25\n",
      "64/64 - 0s - 5ms/step - accuracy: 0.7924 - loss: 0.5751\n",
      "Epoch 8/25\n",
      "64/64 - 0s - 6ms/step - accuracy: 0.8173 - loss: 0.5147\n",
      "Epoch 9/25\n",
      "64/64 - 0s - 5ms/step - accuracy: 0.8319 - loss: 0.4774\n",
      "Epoch 10/25\n",
      "64/64 - 0s - 5ms/step - accuracy: 0.8428 - loss: 0.4443\n",
      "Epoch 11/25\n",
      "64/64 - 0s - 5ms/step - accuracy: 0.8577 - loss: 0.4108\n",
      "Epoch 12/25\n",
      "64/64 - 0s - 5ms/step - accuracy: 0.8686 - loss: 0.3802\n",
      "Epoch 13/25\n",
      "64/64 - 0s - 5ms/step - accuracy: 0.8787 - loss: 0.3557\n",
      "Epoch 14/25\n",
      "64/64 - 0s - 5ms/step - accuracy: 0.8876 - loss: 0.3299\n",
      "Epoch 15/25\n",
      "64/64 - 0s - 5ms/step - accuracy: 0.8915 - loss: 0.3137\n",
      "Epoch 16/25\n",
      "64/64 - 0s - 6ms/step - accuracy: 0.9013 - loss: 0.2913\n",
      "Epoch 17/25\n",
      "64/64 - 0s - 5ms/step - accuracy: 0.8923 - loss: 0.3167\n",
      "Epoch 18/25\n",
      "64/64 - 0s - 5ms/step - accuracy: 0.9068 - loss: 0.2723\n",
      "Epoch 19/25\n",
      "64/64 - 0s - 5ms/step - accuracy: 0.9089 - loss: 0.2683\n",
      "Epoch 20/25\n",
      "64/64 - 0s - 5ms/step - accuracy: 0.9178 - loss: 0.2433\n",
      "Epoch 21/25\n",
      "64/64 - 0s - 5ms/step - accuracy: 0.9128 - loss: 0.2561\n",
      "Epoch 22/25\n",
      "64/64 - 0s - 6ms/step - accuracy: 0.9092 - loss: 0.2679\n",
      "Epoch 23/25\n",
      "64/64 - 0s - 5ms/step - accuracy: 0.9252 - loss: 0.2215\n",
      "Epoch 24/25\n",
      "64/64 - 0s - 5ms/step - accuracy: 0.9259 - loss: 0.2117\n",
      "Epoch 25/25\n",
      "64/64 - 0s - 5ms/step - accuracy: 0.9290 - loss: 0.2154\n",
      "16/16 - 0s - 5ms/step\n",
      "Epoch 1/25\n",
      "64/64 - 1s - 13ms/step - accuracy: 0.6085 - loss: 1.2160\n",
      "Epoch 2/25\n",
      "64/64 - 0s - 6ms/step - accuracy: 0.6821 - loss: 0.9018\n",
      "Epoch 3/25\n",
      "64/64 - 0s - 6ms/step - accuracy: 0.7160 - loss: 0.8051\n",
      "Epoch 4/25\n",
      "64/64 - 0s - 6ms/step - accuracy: 0.7316 - loss: 0.7570\n",
      "Epoch 5/25\n",
      "64/64 - 0s - 5ms/step - accuracy: 0.7436 - loss: 0.7154\n",
      "Epoch 6/25\n",
      "64/64 - 0s - 5ms/step - accuracy: 0.7634 - loss: 0.6683\n",
      "Epoch 7/25\n",
      "64/64 - 0s - 5ms/step - accuracy: 0.7769 - loss: 0.6266\n",
      "Epoch 8/25\n",
      "64/64 - 0s - 5ms/step - accuracy: 0.7890 - loss: 0.5800\n",
      "Epoch 9/25\n",
      "64/64 - 0s - 5ms/step - accuracy: 0.8039 - loss: 0.5497\n",
      "Epoch 10/25\n",
      "64/64 - 0s - 5ms/step - accuracy: 0.8203 - loss: 0.5094\n",
      "Epoch 11/25\n",
      "64/64 - 0s - 5ms/step - accuracy: 0.8229 - loss: 0.4976\n",
      "Epoch 12/25\n",
      "64/64 - 0s - 6ms/step - accuracy: 0.8294 - loss: 0.4740\n",
      "Epoch 13/25\n",
      "64/64 - 0s - 5ms/step - accuracy: 0.8437 - loss: 0.4417\n",
      "Epoch 14/25\n",
      "64/64 - 0s - 6ms/step - accuracy: 0.8454 - loss: 0.4324\n",
      "Epoch 15/25\n",
      "64/64 - 0s - 5ms/step - accuracy: 0.8561 - loss: 0.4130\n",
      "Epoch 16/25\n",
      "64/64 - 0s - 5ms/step - accuracy: 0.8625 - loss: 0.3955\n",
      "Epoch 17/25\n",
      "64/64 - 0s - 5ms/step - accuracy: 0.8644 - loss: 0.3949\n",
      "Epoch 18/25\n",
      "64/64 - 0s - 5ms/step - accuracy: 0.8667 - loss: 0.3911\n",
      "Epoch 19/25\n",
      "64/64 - 0s - 5ms/step - accuracy: 0.8749 - loss: 0.3611\n",
      "Epoch 20/25\n",
      "64/64 - 0s - 5ms/step - accuracy: 0.8789 - loss: 0.3583\n",
      "Epoch 21/25\n",
      "64/64 - 0s - 5ms/step - accuracy: 0.8824 - loss: 0.3431\n",
      "Epoch 22/25\n",
      "64/64 - 0s - 5ms/step - accuracy: 0.8896 - loss: 0.3279\n",
      "Epoch 23/25\n",
      "64/64 - 0s - 5ms/step - accuracy: 0.8877 - loss: 0.3282\n",
      "Epoch 24/25\n",
      "64/64 - 0s - 6ms/step - accuracy: 0.8908 - loss: 0.3138\n",
      "Epoch 25/25\n",
      "64/64 - 0s - 5ms/step - accuracy: 0.8929 - loss: 0.3149\n",
      "16/16 - 0s - 5ms/step\n",
      "Epoch 1/25\n",
      "64/64 - 1s - 13ms/step - accuracy: 0.6257 - loss: 1.1748\n",
      "Epoch 2/25\n",
      "64/64 - 0s - 5ms/step - accuracy: 0.6891 - loss: 0.8911\n",
      "Epoch 3/25\n",
      "64/64 - 0s - 5ms/step - accuracy: 0.7140 - loss: 0.8217\n",
      "Epoch 4/25\n",
      "64/64 - 0s - 5ms/step - accuracy: 0.7359 - loss: 0.7649\n",
      "Epoch 5/25\n",
      "64/64 - 0s - 5ms/step - accuracy: 0.7471 - loss: 0.7191\n",
      "Epoch 6/25\n",
      "64/64 - 0s - 6ms/step - accuracy: 0.7650 - loss: 0.6674\n",
      "Epoch 7/25\n",
      "64/64 - 0s - 5ms/step - accuracy: 0.7835 - loss: 0.6192\n",
      "Epoch 8/25\n",
      "64/64 - 0s - 5ms/step - accuracy: 0.7976 - loss: 0.5770\n",
      "Epoch 9/25\n",
      "64/64 - 0s - 5ms/step - accuracy: 0.8091 - loss: 0.5387\n",
      "Epoch 10/25\n",
      "64/64 - 0s - 6ms/step - accuracy: 0.8154 - loss: 0.5143\n",
      "Epoch 11/25\n",
      "64/64 - 0s - 5ms/step - accuracy: 0.8286 - loss: 0.4770\n",
      "Epoch 12/25\n",
      "64/64 - 0s - 5ms/step - accuracy: 0.8407 - loss: 0.4528\n",
      "Epoch 13/25\n",
      "64/64 - 0s - 5ms/step - accuracy: 0.8537 - loss: 0.4284\n",
      "Epoch 14/25\n",
      "64/64 - 0s - 5ms/step - accuracy: 0.8563 - loss: 0.4118\n",
      "Epoch 15/25\n",
      "64/64 - 0s - 5ms/step - accuracy: 0.8602 - loss: 0.3994\n",
      "Epoch 16/25\n",
      "64/64 - 0s - 6ms/step - accuracy: 0.8699 - loss: 0.3815\n",
      "Epoch 17/25\n",
      "64/64 - 0s - 5ms/step - accuracy: 0.8731 - loss: 0.3712\n",
      "Epoch 18/25\n",
      "64/64 - 0s - 5ms/step - accuracy: 0.8813 - loss: 0.3522\n",
      "Epoch 19/25\n",
      "64/64 - 0s - 5ms/step - accuracy: 0.8853 - loss: 0.3331\n",
      "Epoch 20/25\n",
      "64/64 - 0s - 6ms/step - accuracy: 0.8951 - loss: 0.3088\n",
      "Epoch 21/25\n",
      "64/64 - 0s - 5ms/step - accuracy: 0.8935 - loss: 0.3117\n",
      "Epoch 22/25\n",
      "64/64 - 0s - 6ms/step - accuracy: 0.9012 - loss: 0.2843\n",
      "Epoch 23/25\n",
      "64/64 - 0s - 6ms/step - accuracy: 0.9046 - loss: 0.2800\n",
      "Epoch 24/25\n",
      "64/64 - 0s - 6ms/step - accuracy: 0.9132 - loss: 0.2600\n",
      "Epoch 25/25\n",
      "64/64 - 0s - 5ms/step - accuracy: 0.9111 - loss: 0.2700\n",
      "16/16 - 0s - 5ms/step\n",
      "| \u001b[39m15       \u001b[39m | \u001b[39m0.9152   \u001b[39m | \u001b[39m0.367    \u001b[39m | \u001b[39m218.2    \u001b[39m | \u001b[39m0.6776   \u001b[39m | \u001b[39m0.3033   \u001b[39m | \u001b[39m25.36    \u001b[39m | \u001b[39m1.453    \u001b[39m | \u001b[39m1.645    \u001b[39m | \u001b[39m1.174    \u001b[39m | \u001b[39m0.6912   \u001b[39m | \u001b[39m44.81    \u001b[39m | \u001b[39m0.9367   \u001b[39m | \u001b[39m0.9626   \u001b[39m |\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input y contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.12/site-packages/bayes_opt/bayesian_optimization.py:308\u001b[0m, in \u001b[0;36mBayesianOptimization.maximize\u001b[0;34m(self, init_points, n_iter)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 308\u001b[0m     x_probe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_queue\u001b[38;5;241m.\u001b[39mpopleft()\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m:\n",
      "\u001b[0;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Run Bayesian Optimization \u001b[39;00m\n\u001b[1;32m     16\u001b[0m nn_opt \u001b[38;5;241m=\u001b[39m BayesianOptimization(bay_area, params, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m nn_opt\u001b[38;5;241m.\u001b[39mmaximize(init_points\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m, n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m) \n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSearch took \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m minutes\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m ((time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m60\u001b[39m))\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.12/site-packages/bayes_opt/bayesian_optimization.py:310\u001b[0m, in \u001b[0;36mBayesianOptimization.maximize\u001b[0;34m(self, init_points, n_iter)\u001b[0m\n\u001b[1;32m    308\u001b[0m     x_probe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_queue\u001b[38;5;241m.\u001b[39mpopleft()\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m:\n\u001b[0;32m--> 310\u001b[0m     x_probe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuggest()\n\u001b[1;32m    311\u001b[0m     iteration \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprobe(x_probe, lazy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.12/site-packages/bayes_opt/bayesian_optimization.py:254\u001b[0m, in \u001b[0;36mBayesianOptimization.suggest\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_space\u001b[38;5;241m.\u001b[39marray_to_params(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_space\u001b[38;5;241m.\u001b[39mrandom_sample())\n\u001b[1;32m    253\u001b[0m \u001b[38;5;66;03m# Finding argmax of the acquisition function.\u001b[39;00m\n\u001b[0;32m--> 254\u001b[0m suggestion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_acquisition_function\u001b[38;5;241m.\u001b[39msuggest(gp\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gp, target_space\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_space, fit_gp\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_space\u001b[38;5;241m.\u001b[39marray_to_params(suggestion)\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.12/site-packages/bayes_opt/acquisition.py:414\u001b[0m, in \u001b[0;36mUpperConfidenceBound.suggest\u001b[0;34m(self, gp, target_space, n_random, n_l_bfgs_b, fit_gp)\u001b[0m\n\u001b[1;32m    409\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    410\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived constraints, but acquisition function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    411\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not support constrained optimization.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    412\u001b[0m     )\n\u001b[1;32m    413\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ConstraintNotSupportedError(msg)\n\u001b[0;32m--> 414\u001b[0m x_max \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39msuggest(\n\u001b[1;32m    415\u001b[0m     gp\u001b[38;5;241m=\u001b[39mgp, target_space\u001b[38;5;241m=\u001b[39mtarget_space, n_random\u001b[38;5;241m=\u001b[39mn_random, n_l_bfgs_b\u001b[38;5;241m=\u001b[39mn_l_bfgs_b, fit_gp\u001b[38;5;241m=\u001b[39mfit_gp\n\u001b[1;32m    416\u001b[0m )\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecay_exploration()\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x_max\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.12/site-packages/bayes_opt/acquisition.py:127\u001b[0m, in \u001b[0;36mAcquisitionFunction.suggest\u001b[0;34m(self, gp, target_space, n_random, n_l_bfgs_b, fit_gp)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mi \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fit_gp:\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_gp(gp\u001b[38;5;241m=\u001b[39mgp, target_space\u001b[38;5;241m=\u001b[39mtarget_space)\n\u001b[1;32m    129\u001b[0m acq \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_acq(gp\u001b[38;5;241m=\u001b[39mgp, constraint\u001b[38;5;241m=\u001b[39mtarget_space\u001b[38;5;241m.\u001b[39mconstraint)\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_acq_min(acq, target_space\u001b[38;5;241m.\u001b[39mbounds, n_random\u001b[38;5;241m=\u001b[39mn_random, n_l_bfgs_b\u001b[38;5;241m=\u001b[39mn_l_bfgs_b)\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.12/site-packages/bayes_opt/acquisition.py:81\u001b[0m, in \u001b[0;36mAcquisitionFunction._fit_gp\u001b[0;34m(self, gp, target_space)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[1;32m     80\u001b[0m     warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 81\u001b[0m     gp\u001b[38;5;241m.\u001b[39mfit(target_space\u001b[38;5;241m.\u001b[39mparams, target_space\u001b[38;5;241m.\u001b[39mtarget)\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m target_space\u001b[38;5;241m.\u001b[39mconstraint \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     83\u001b[0m         target_space\u001b[38;5;241m.\u001b[39mconstraint\u001b[38;5;241m.\u001b[39mfit(target_space\u001b[38;5;241m.\u001b[39mparams, target_space\u001b[38;5;241m.\u001b[39m_constraint_values)\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.12/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.12/site-packages/sklearn/gaussian_process/_gpr.py:251\u001b[0m, in \u001b[0;36mGaussianProcessRegressor.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    250\u001b[0m     dtype, ensure_2d \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[1;32m    252\u001b[0m     X,\n\u001b[1;32m    253\u001b[0m     y,\n\u001b[1;32m    254\u001b[0m     multi_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    255\u001b[0m     y_numeric\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    256\u001b[0m     ensure_2d\u001b[38;5;241m=\u001b[39mensure_2d,\n\u001b[1;32m    257\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m    258\u001b[0m )\n\u001b[1;32m    260\u001b[0m n_targets_seen \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_targets \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m n_targets_seen \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_targets:\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.12/site-packages/sklearn/base.py:650\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    648\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m    649\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 650\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[1;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.12/site-packages/sklearn/utils/validation.py:1279\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1259\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1260\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1261\u001b[0m     )\n\u001b[1;32m   1263\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[1;32m   1264\u001b[0m     X,\n\u001b[1;32m   1265\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1276\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1277\u001b[0m )\n\u001b[0;32m-> 1279\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[1;32m   1281\u001b[0m check_consistent_length(X, y)\n\u001b[1;32m   1283\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.12/site-packages/sklearn/utils/validation.py:1289\u001b[0m, in \u001b[0;36m_check_y\u001b[0;34m(y, multi_output, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1287\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Isolated part of check_X_y dedicated to y validation\"\"\"\u001b[39;00m\n\u001b[1;32m   1288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m multi_output:\n\u001b[0;32m-> 1289\u001b[0m     y \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[1;32m   1290\u001b[0m         y,\n\u001b[1;32m   1291\u001b[0m         accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1292\u001b[0m         force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   1293\u001b[0m         ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1294\u001b[0m         dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1295\u001b[0m         input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1296\u001b[0m         estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[1;32m   1297\u001b[0m     )\n\u001b[1;32m   1298\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1299\u001b[0m     estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.12/site-packages/sklearn/utils/validation.py:1049\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1043\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1044\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1045\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m   1046\u001b[0m     )\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[0;32m-> 1049\u001b[0m     _assert_all_finite(\n\u001b[1;32m   1050\u001b[0m         array,\n\u001b[1;32m   1051\u001b[0m         input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[1;32m   1052\u001b[0m         estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[1;32m   1053\u001b[0m         allow_nan\u001b[38;5;241m=\u001b[39mforce_all_finite \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1054\u001b[0m     )\n\u001b[1;32m   1056\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[1;32m   1057\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[1;32m   1058\u001b[0m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.12/site-packages/sklearn/utils/validation.py:126\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 126\u001b[0m _assert_all_finite_element_wise(\n\u001b[1;32m    127\u001b[0m     X,\n\u001b[1;32m    128\u001b[0m     xp\u001b[38;5;241m=\u001b[39mxp,\n\u001b[1;32m    129\u001b[0m     allow_nan\u001b[38;5;241m=\u001b[39mallow_nan,\n\u001b[1;32m    130\u001b[0m     msg_dtype\u001b[38;5;241m=\u001b[39mmsg_dtype,\n\u001b[1;32m    131\u001b[0m     estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[1;32m    132\u001b[0m     input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[1;32m    133\u001b[0m )\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.12/site-packages/sklearn/utils/validation.py:175\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    161\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    162\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    163\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    174\u001b[0m     )\n\u001b[0;32m--> 175\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input y contains NaN."
     ]
    }
   ],
   "source": [
    "start = time.time() \n",
    "params ={ \n",
    "    'neurons': (10, 100),\n",
    "    'kernel': (1, 3),\n",
    "    'activation':(0, 9),\n",
    "    'optimizer':(0,7),\n",
    "    'learning_rate':(0.001, 1),\n",
    "    'batch_size': (100, 300),\n",
    "    'epochs':(10, 40),\n",
    "    'layers1':(1,2),\n",
    "    'layers2':(1,2),\n",
    "    'normalization':(0,1),\n",
    "    'dropout':(0,1),\n",
    "    'dropout_rate':(0.3,0.5)}\n",
    "# Run Bayesian Optimization \n",
    "nn_opt = BayesianOptimization(bay_area, params, random_state=42)\n",
    "nn_opt.maximize(init_points=15, n_iter=4) \n",
    "print('Search took %s minutes' % ((time.time() - start)/60))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bbb32085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'softsign',\n",
       " 'batch_size': 165,\n",
       " 'dropout': 0.7296061783380641,\n",
       " 'dropout_rate': 0.4275114942710426,\n",
       " 'epochs': 37,\n",
       " 'kernel': 1.9444298503238986,\n",
       " 'layers1': 1,\n",
       " 'layers2': 2,\n",
       " 'learning_rate': 0.7610242635682806,\n",
       " 'neurons': 61,\n",
       " 'normalization': 0.770967179954561,\n",
       " 'optimizer': <keras.src.optimizers.adadelta.Adadelta at 0x163581790>}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimum = nn_opt.max['params']\n",
    "learning_rate = optimum['learning_rate']\n",
    "\n",
    "activationL = ['relu', 'sigmoid', 'softplus', 'softsign', 'tanh', 'selu', 'elu', 'exponential', LeakyReLU, 'relu']\n",
    "optimum['activation'] = activationL[round(optimum['activation'])]\n",
    "\n",
    "optimum['batch_size'] = round(optimum['batch_size'])\n",
    "optimum['epochs'] = round(optimum['epochs'])\n",
    "optimum['layers1'] = round(optimum['layers1'])\n",
    "optimum['layers2'] = round(optimum['layers2'])\n",
    "optimum['neurons'] = round(optimum['neurons'])\n",
    "\n",
    "optimizerL = ['Adam', 'SGD', 'RMSprop', 'Adadelta', 'Adagrad', 'Adamax', 'Nadam', 'Ftrl', 'Adam']\n",
    "optimizerD = {\n",
    "    'Adam': Adam(learning_rate=learning_rate),\n",
    "    'SGD': SGD(learning_rate=learning_rate),\n",
    "    'RMSprop': RMSprop(learning_rate=learning_rate),\n",
    "    'Adadelta': Adadelta(learning_rate=learning_rate),\n",
    "    'Adagrad': Adagrad(learning_rate=learning_rate),\n",
    "    'Adamax': Adamax(learning_rate=learning_rate),\n",
    "    'Nadam': Nadam(learning_rate=learning_rate),\n",
    "    'Ftrl': Ftrl(learning_rate=learning_rate)\n",
    "}\n",
    "optimum['optimizer'] = optimizerD[optimizerL[round(optimum['optimizer'])]]\n",
    "optimum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679580f2",
   "metadata": {},
   "source": [
    "# Running CNN with Optimized Search Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "469273a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model with optimized hyperparameters\n",
    "\n",
    "epochs = 37\n",
    "batch_size = 165\n",
    "\n",
    "timesteps = len(X_train[0])\n",
    "input_dim = len(X_train[0][0])\n",
    "n_classes = 15\n",
    "\n",
    "layers1 = 1\n",
    "layers2 = 2\n",
    "activation = 'softsign'\n",
    "kernel = int(round(1.9444298503238986))  # Rounded kernel size for Conv1D\n",
    "neurons = 61\n",
    "normalization = 0.770967179954561\n",
    "dropout = 0.7296061783380641\n",
    "dropout_rate = 0.4275114942710426\n",
    "optimizer = Adadelta(learning_rate=0.7610242635682806)  # Instantiate RMSprop with learning rate\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(neurons, kernel_size=kernel, activation=activation, input_shape=(timesteps, input_dim)))\n",
    "\n",
    "if normalization > 0.5:\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "for i in range(layers1):\n",
    "    model.add(Dense(neurons, activation=activation))\n",
    "\n",
    "if dropout > 0.5:\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "for i in range(layers2):\n",
    "    model.add(Dense(neurons, activation=activation))\n",
    "\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(n_classes, activation='softmax')) \n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f83e5dcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_75\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_75\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\"> Layer (type)                    </span><span style=\"font-weight: bold\"> Output Shape           </span><span style=\"font-weight: bold\">       Param # </span>\n",
       "\n",
       " conv1d_75 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,159</span> \n",
       "\n",
       " batch_normalization_30           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span> \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                   \n",
       "\n",
       " dense_310 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,782</span> \n",
       "\n",
       " dropout_45 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dense_311 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,782</span> \n",
       "\n",
       " dense_312 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,782</span> \n",
       "\n",
       " max_pooling1d_75 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>)                       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " flatten_75 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">427</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dense_313 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">6,420</span> \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       " conv1d_75 (\u001b[38;5;33mConv1D\u001b[0m)               (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m61\u001b[0m)                  \u001b[38;5;34m1,159\u001b[0m \n",
       "\n",
       " batch_normalization_30           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m61\u001b[0m)                    \u001b[38;5;34m244\u001b[0m \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                   \n",
       "\n",
       " dense_310 (\u001b[38;5;33mDense\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m61\u001b[0m)                  \u001b[38;5;34m3,782\u001b[0m \n",
       "\n",
       " dropout_45 (\u001b[38;5;33mDropout\u001b[0m)             (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m61\u001b[0m)                      \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dense_311 (\u001b[38;5;33mDense\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m61\u001b[0m)                  \u001b[38;5;34m3,782\u001b[0m \n",
       "\n",
       " dense_312 (\u001b[38;5;33mDense\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m61\u001b[0m)                  \u001b[38;5;34m3,782\u001b[0m \n",
       "\n",
       " max_pooling1d_75 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m61\u001b[0m)                       \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " flatten_75 (\u001b[38;5;33mFlatten\u001b[0m)             (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m427\u001b[0m)                         \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dense_313 (\u001b[38;5;33mDense\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)                      \u001b[38;5;34m6,420\u001b[0m \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,169</span> (74.88 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m19,169\u001b[0m (74.88 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,047</span> (74.40 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m19,047\u001b[0m (74.40 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">122</span> (488.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m122\u001b[0m (488.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "06a426d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the y_test set back into a one-hot configuration\n",
    "\n",
    "y_train_one_hot = to_categorical(y_train, num_classes=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "579f167d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (17212, 15, 9)\n",
      "y_train_one_hot shape: (17212, 15)\n"
     ]
    }
   ],
   "source": [
    "# Check shapes\n",
    "\n",
    "print(f'X_train shape: {X_train.shape}')\n",
    "print(f'y_train_one_hot shape: {y_train_one_hot.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "29e2a1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with categorical_crossentropy\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0479aee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/37\n",
      "105/105 - 1s - 11ms/step - accuracy: 0.6658 - loss: 1.1019\n",
      "Epoch 2/37\n",
      "105/105 - 1s - 6ms/step - accuracy: 0.7350 - loss: 0.7896\n",
      "Epoch 3/37\n",
      "105/105 - 1s - 6ms/step - accuracy: 0.7587 - loss: 0.7099\n",
      "Epoch 4/37\n",
      "105/105 - 1s - 6ms/step - accuracy: 0.7779 - loss: 0.6497\n",
      "Epoch 5/37\n",
      "105/105 - 1s - 6ms/step - accuracy: 0.7957 - loss: 0.5925\n",
      "Epoch 6/37\n",
      "105/105 - 1s - 6ms/step - accuracy: 0.8099 - loss: 0.5451\n",
      "Epoch 7/37\n",
      "105/105 - 1s - 6ms/step - accuracy: 0.8177 - loss: 0.5141\n",
      "Epoch 8/37\n",
      "105/105 - 1s - 6ms/step - accuracy: 0.8322 - loss: 0.4809\n",
      "Epoch 9/37\n",
      "105/105 - 1s - 6ms/step - accuracy: 0.8416 - loss: 0.4606\n",
      "Epoch 10/37\n",
      "105/105 - 1s - 6ms/step - accuracy: 0.8459 - loss: 0.4363\n",
      "Epoch 11/37\n",
      "105/105 - 1s - 6ms/step - accuracy: 0.8534 - loss: 0.4200\n",
      "Epoch 12/37\n",
      "105/105 - 1s - 6ms/step - accuracy: 0.8633 - loss: 0.3963\n",
      "Epoch 13/37\n",
      "105/105 - 1s - 6ms/step - accuracy: 0.8702 - loss: 0.3810\n",
      "Epoch 14/37\n",
      "105/105 - 1s - 6ms/step - accuracy: 0.8754 - loss: 0.3662\n",
      "Epoch 15/37\n",
      "105/105 - 1s - 6ms/step - accuracy: 0.8803 - loss: 0.3493\n",
      "Epoch 16/37\n",
      "105/105 - 1s - 6ms/step - accuracy: 0.8833 - loss: 0.3365\n",
      "Epoch 17/37\n",
      "105/105 - 1s - 6ms/step - accuracy: 0.8900 - loss: 0.3234\n",
      "Epoch 18/37\n",
      "105/105 - 1s - 6ms/step - accuracy: 0.8887 - loss: 0.3223\n",
      "Epoch 19/37\n",
      "105/105 - 1s - 6ms/step - accuracy: 0.8976 - loss: 0.3051\n",
      "Epoch 20/37\n",
      "105/105 - 1s - 6ms/step - accuracy: 0.8951 - loss: 0.3012\n",
      "Epoch 21/37\n",
      "105/105 - 1s - 6ms/step - accuracy: 0.9001 - loss: 0.2911\n",
      "Epoch 22/37\n",
      "105/105 - 1s - 6ms/step - accuracy: 0.9012 - loss: 0.2836\n",
      "Epoch 23/37\n",
      "105/105 - 1s - 6ms/step - accuracy: 0.9068 - loss: 0.2710\n",
      "Epoch 24/37\n",
      "105/105 - 1s - 6ms/step - accuracy: 0.9080 - loss: 0.2712\n",
      "Epoch 25/37\n",
      "105/105 - 1s - 6ms/step - accuracy: 0.9114 - loss: 0.2602\n",
      "Epoch 26/37\n",
      "105/105 - 1s - 6ms/step - accuracy: 0.9131 - loss: 0.2565\n",
      "Epoch 27/37\n",
      "105/105 - 1s - 6ms/step - accuracy: 0.9105 - loss: 0.2613\n",
      "Epoch 28/37\n",
      "105/105 - 1s - 6ms/step - accuracy: 0.9183 - loss: 0.2403\n",
      "Epoch 29/37\n",
      "105/105 - 1s - 6ms/step - accuracy: 0.9178 - loss: 0.2401\n",
      "Epoch 30/37\n",
      "105/105 - 1s - 6ms/step - accuracy: 0.9162 - loss: 0.2446\n",
      "Epoch 31/37\n",
      "105/105 - 1s - 6ms/step - accuracy: 0.9199 - loss: 0.2346\n",
      "Epoch 32/37\n",
      "105/105 - 1s - 6ms/step - accuracy: 0.9191 - loss: 0.2301\n",
      "Epoch 33/37\n",
      "105/105 - 1s - 6ms/step - accuracy: 0.9231 - loss: 0.2252\n",
      "Epoch 34/37\n",
      "105/105 - 1s - 6ms/step - accuracy: 0.9253 - loss: 0.2199\n",
      "Epoch 35/37\n",
      "105/105 - 1s - 6ms/step - accuracy: 0.9278 - loss: 0.2112\n",
      "Epoch 36/37\n",
      "105/105 - 1s - 6ms/step - accuracy: 0.9276 - loss: 0.2160\n",
      "Epoch 37/37\n",
      "105/105 - 1s - 6ms/step - accuracy: 0.9300 - loss: 0.2085\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x356281d30>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model to the data\n",
    "\n",
    "model.fit(X_train, y_train_one_hot, batch_size=batch_size, epochs=epochs, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeab4853",
   "metadata": {},
   "source": [
    "# Creating Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2d221445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define list of stations names\n",
    "\n",
    "stations = {\n",
    "0: 'BASEL',\n",
    "1: 'BELGRADE',\n",
    "2: 'BUDAPEST',\n",
    "3: 'DEBILT',\n",
    "4: 'DUSSELDORF',\n",
    "5: 'HEATHROW',\n",
    "6: 'KASSEL',\n",
    "7: 'LJUBLJANA',\n",
    "8: 'MAASTRICHT',\n",
    "9: 'MADRID',\n",
    "10: 'MUNCHENB',\n",
    "11: 'OSLO',\n",
    "12: 'SONNBLICK',\n",
    "13: 'STOCKHOLM',\n",
    "14: 'VALENTIA'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "34460ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(y_true, y_pred, stations):\n",
    "    # Check if y_true and y_pred are one-hot encoded or already class indices\n",
    "    if y_true.ndim == 1:\n",
    "        y_true_labels = y_true\n",
    "    else:\n",
    "        y_true_labels = np.argmax(y_true, axis=1)\n",
    "    \n",
    "    if y_pred.ndim == 1:\n",
    "        y_pred_labels = y_pred\n",
    "    else:\n",
    "        y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "        \n",
    "    # Map numeric labels to activity names\n",
    "    y_true_series = pd.Series([stations[y] for y in y_true_labels])\n",
    "    y_pred_series = pd.Series([stations[y] for y in y_pred_labels])\n",
    "    \n",
    "    return pd.crosstab(y_true_series, y_pred_series, rownames=['True'], colnames=['Pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f18d11b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m180/180\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 704us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0e999feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred        BASEL  BELGRADE  BUDAPEST  DEBILT  DUSSELDORF  HEATHROW  KASSEL  \\\n",
      "True                                                                          \n",
      "BASEL        3582        67         9       3           2         4       0   \n",
      "BELGRADE      114       965         2       0           0         2       0   \n",
      "BUDAPEST       20        36       140       4           0         1       0   \n",
      "DEBILT          8         7        24      40           1         2       0   \n",
      "DUSSELDORF      5         2         3       1           6         9       0   \n",
      "HEATHROW        8         3         3       1           2        55       0   \n",
      "KASSEL          1         2         1       0           0         1       3   \n",
      "LJUBLJANA       9         2         2       0           0         1       0   \n",
      "MAASTRICHT      5         0         0       0           0         2       0   \n",
      "MADRID         52        12        10       0           0         1       1   \n",
      "MUNCHENB        7         0         0       0           0         0       0   \n",
      "OSLO            3         0         0       0           0         0       0   \n",
      "STOCKHOLM       2         0         0       0           0         0       0   \n",
      "VALENTIA        1         0         0       0           0         0       0   \n",
      "\n",
      "Pred        LJUBLJANA  MAASTRICHT  MADRID  MUNCHENB  OSLO  \n",
      "True                                                       \n",
      "BASEL               2           1      12         0     0  \n",
      "BELGRADE            4           0       5         0     0  \n",
      "BUDAPEST            4           0       9         0     0  \n",
      "DEBILT              0           0       0         0     0  \n",
      "DUSSELDORF          0           0       3         0     0  \n",
      "HEATHROW            0           0      10         0     0  \n",
      "KASSEL              2           1       0         0     0  \n",
      "LJUBLJANA          33           0      13         0     1  \n",
      "MAASTRICHT          0           1       1         0     0  \n",
      "MADRID              2           0     380         0     0  \n",
      "MUNCHENB            0           0       0         1     0  \n",
      "OSLO                0           0       0         0     2  \n",
      "STOCKHOLM           0           0       0         1     1  \n",
      "VALENTIA            0           0       0         0     0  \n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred, stations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "50ad5e8a-1483-4070-b095-843c91703a41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def confusion_matrix(y_true, y_pred, stations):\n",
    "    # Check if y_true and y_pred are one-hot encoded or already class indices\n",
    "    if y_true.ndim == 1:\n",
    "        y_true_labels = y_true\n",
    "    else:\n",
    "        y_true_labels = np.argmax(y_true, axis=1)\n",
    "    \n",
    "    if y_pred.ndim == 1:\n",
    "        y_pred_labels = y_pred\n",
    "    else:\n",
    "        y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "        \n",
    "    # Map numeric labels to activity names\n",
    "    y_true_series = pd.Series([stations[y] for y in y_true_labels])\n",
    "    y_pred_series = pd.Series([stations[y] for y in y_pred_labels])\n",
    "    \n",
    "    # Create the confusion matrix\n",
    "    cm = pd.crosstab(y_true_series, y_pred_series, rownames=['True'], colnames=['Pred'])\n",
    "    \n",
    "    return cm\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, stations):\n",
    "    cm = confusion_matrix(y_true, y_pred, stations)\n",
    "    \n",
    "    plt.figure(figsize=(10,7))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix Heatmap')\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "y_true = np.array([0, 1, 2, 1, 0, 1, 2, 0, 2, 1])  # Example labels\n",
    "y_pred = np.array([0, 2, 2, 1, 0, 1, 1, 0, 2, 1])  # Example predictions\n",
    "stations = ['Kassel', 'Berlin', 'Kassel', 'Kassel', 'Berlin', 'Kassel', 'Berlin', 'Kassel', 'Berlin', 'Berlin']  # Example station data\n",
    "\n",
    "# Generate the heatmap for all stations\n",
    "plot_confusion_matrix(y_true, y_pred, stations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc0f08a-4b58-4a25-887a-8745ed704028",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
